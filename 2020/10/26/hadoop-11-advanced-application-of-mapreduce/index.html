<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>MapReduce的高级应用 | 余思博客</title><meta name="description" content="MapReduce的高级应用"><meta name="keywords" content="hadoop"><meta name="author" content="余思"><meta name="copyright" content="余思"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="MapReduce的高级应用"><meta name="twitter:description" content="MapReduce的高级应用"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><meta property="og:type" content="article"><meta property="og:title" content="MapReduce的高级应用"><meta property="og:url" content="http://envyzhan.top/2020/10/26/hadoop-11-advanced-application-of-mapreduce/"><meta property="og:site_name" content="余思博客"><meta property="og:description" content="MapReduce的高级应用"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="http://envyzhan.top/2020/10/26/hadoop-11-advanced-application-of-mapreduce/"><link rel="prev" title="YARN入门" href="http://envyzhan.top/2020/10/27/hadoop-12-yarn-basic/"><link rel="next" title="MapReduce其他内容" href="http://envyzhan.top/2020/10/23/hadoop-10-other-content-partitioner-and-recordreader/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js" defer></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"cookieDomain":"https://envythink.cn/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: {"languages":{"author":"作者: 余思","link":"链接: http://envyzhan.top/2020/10/26/hadoop-11-advanced-application-of-mapreduce/","source":"来源: 余思博客","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  ClickShowText: undefined,
  medium_zoom: true,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><canvas class="fireworks"></canvas><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">余思博客</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-html5" aria-hidden="true"></i><span> 前端</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/categories/html/"><i class="fa-fw fa fa-cog"></i><span> HTML/CSS</span></a></li><li><a class="site-page" href="/categories/javascript/"><i class="fa-fw fa fa-cogs"></i><span> JavaScript</span></a></li><li><a class="site-page" href="/categories/vuejs/"><i class="fa-fw fa fa-certificate"></i><span> Vue.js</span></a></li></ul></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> Java</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/categories/java/"><i class="fa-fw fa fa-book"></i><span> Java</span></a></li><li><a class="site-page" href="/categories/ssm/"><i class="fa-fw fa fa-cube"></i><span> SSM</span></a></li><li><a class="site-page" href="/categories/springboot/"><i class="fa-fw fa fa-cubes"></i><span> SpringBoot</span></a></li><li><a class="site-page" href="/categories/springcloud/"><i class="fa-fw fa fa-cloud"></i><span> SpringCloud</span></a></li><li><a class="site-page" href="/categories/springsecurity/"><i class="fa-fw fa fa-bullseye"></i><span> SpringSecurity</span></a></li></ul></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 运维</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/categories/pythonbase/"><i class="fa-fw fa fa-book"></i><span> Python</span></a></li><li><a class="site-page" href="/categories/go/"><i class="fa-fw fa fa-google-plus"></i><span> Golang</span></a></li><li><a class="site-page" href="/categories/devops/"><i class="fa-fw fa fa-road"></i><span> DevOps</span></a></li></ul></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 中间件</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/categories/mysql/"><i class="fa-fw fa fa-database"></i><span> MySQL</span></a></li><li><a class="site-page" href="/categories/nginx/"><i class="fa-fw fa fa-location-arrow"></i><span> Nginx</span></a></li><li><a class="site-page" href="/categories/redis/"><i class="fa-fw fa fa-random"></i><span> Redis</span></a></li></ul></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-bell" aria-hidden="true"></i><span> 其他</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/categories/datastructs/"><i class="fa-fw fa fa-plug"></i><span> 数据结构</span></a></li><li><a class="site-page" href="/categories/algorithm/"><i class="fa-fw fa fa-plane"></i><span> 算法建模</span></a></li><li><a class="site-page" href="/categories/tools/"><i class="fa-fw fa fa-hourglass"></i><span> 实用工具</span></a></li></ul></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-address-book" aria-hidden="true"></i><span> 生活</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/categories/onenote/"><i class="fa-fw fa fa-laptop"></i><span> 个人随笔</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-comment"></i><span> 留言</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></span><span class="pull_right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">213</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">16</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">15</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-html5" aria-hidden="true"></i><span> 前端</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/categories/html/"><i class="fa-fw fa fa-cog"></i><span> HTML/CSS</span></a></li><li><a class="site-page" href="/categories/javascript/"><i class="fa-fw fa fa-cogs"></i><span> JavaScript</span></a></li><li><a class="site-page" href="/categories/vuejs/"><i class="fa-fw fa fa-certificate"></i><span> Vue.js</span></a></li></ul></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> Java</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/categories/java/"><i class="fa-fw fa fa-book"></i><span> Java</span></a></li><li><a class="site-page" href="/categories/ssm/"><i class="fa-fw fa fa-cube"></i><span> SSM</span></a></li><li><a class="site-page" href="/categories/springboot/"><i class="fa-fw fa fa-cubes"></i><span> SpringBoot</span></a></li><li><a class="site-page" href="/categories/springcloud/"><i class="fa-fw fa fa-cloud"></i><span> SpringCloud</span></a></li><li><a class="site-page" href="/categories/springsecurity/"><i class="fa-fw fa fa-bullseye"></i><span> SpringSecurity</span></a></li></ul></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 运维</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/categories/pythonbase/"><i class="fa-fw fa fa-book"></i><span> Python</span></a></li><li><a class="site-page" href="/categories/go/"><i class="fa-fw fa fa-google-plus"></i><span> Golang</span></a></li><li><a class="site-page" href="/categories/devops/"><i class="fa-fw fa fa-road"></i><span> DevOps</span></a></li></ul></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 中间件</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/categories/mysql/"><i class="fa-fw fa fa-database"></i><span> MySQL</span></a></li><li><a class="site-page" href="/categories/nginx/"><i class="fa-fw fa fa-location-arrow"></i><span> Nginx</span></a></li><li><a class="site-page" href="/categories/redis/"><i class="fa-fw fa fa-random"></i><span> Redis</span></a></li></ul></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-bell" aria-hidden="true"></i><span> 其他</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/categories/datastructs/"><i class="fa-fw fa fa-plug"></i><span> 数据结构</span></a></li><li><a class="site-page" href="/categories/algorithm/"><i class="fa-fw fa fa-plane"></i><span> 算法建模</span></a></li><li><a class="site-page" href="/categories/tools/"><i class="fa-fw fa fa-hourglass"></i><span> 实用工具</span></a></li></ul></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-address-book" aria-hidden="true"></i><span> 生活</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/categories/onenote/"><i class="fa-fw fa fa-laptop"></i><span> 个人随笔</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-comment"></i><span> 留言</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#写在前面"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">写在前面</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#MapReduce实现join操作"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">MapReduce实现join操作</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#join操作概述"><span class="toc_mobile_items-number">2.0.1.</span> <span class="toc_mobile_items-text">join操作概述</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#需求分析"><span class="toc_mobile_items-number">2.0.2.</span> <span class="toc_mobile_items-text">需求分析</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Map端join的实现原理"><span class="toc_mobile_items-number">2.0.3.</span> <span class="toc_mobile_items-text">Map端join的实现原理</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Map端join的代码实现"><span class="toc_mobile_items-number">2.0.4.</span> <span class="toc_mobile_items-text">Map端join的代码实现</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#运行作业"><span class="toc_mobile_items-number">2.0.5.</span> <span class="toc_mobile_items-text">运行作业</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#MapReduce实现排序操作"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">MapReduce实现排序操作</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#需求分析-1"><span class="toc_mobile_items-number">3.0.1.</span> <span class="toc_mobile_items-text">需求分析</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#MapReduce排序的实现原理"><span class="toc_mobile_items-number">3.0.2.</span> <span class="toc_mobile_items-text">MapReduce排序的实现原理</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#MapReduce排序的代码实现"><span class="toc_mobile_items-number">3.0.3.</span> <span class="toc_mobile_items-text">MapReduce排序的代码实现</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#运行作业-1"><span class="toc_mobile_items-number">3.0.4.</span> <span class="toc_mobile_items-text">运行作业</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#MapReduce实现二次排序操作"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">MapReduce实现二次排序操作</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#二次排序概述"><span class="toc_mobile_items-number">4.0.1.</span> <span class="toc_mobile_items-text">二次排序概述</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#需求分析-2"><span class="toc_mobile_items-number">4.0.2.</span> <span class="toc_mobile_items-text">需求分析</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#MapReduce二次排序的实现原理"><span class="toc_mobile_items-number">4.0.3.</span> <span class="toc_mobile_items-text">MapReduce二次排序的实现原理</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#MapReduce二次排序的代码实现"><span class="toc_mobile_items-number">4.0.4.</span> <span class="toc_mobile_items-text">MapReduce二次排序的代码实现</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#运行作业-2"><span class="toc_mobile_items-number">4.0.5.</span> <span class="toc_mobile_items-text">运行作业</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#使用MapReduce合并小文件"><span class="toc_mobile_items-number">5.</span> <span class="toc_mobile_items-text">使用MapReduce合并小文件</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#概述"><span class="toc_mobile_items-number">5.0.1.</span> <span class="toc_mobile_items-text">概述</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#需求"><span class="toc_mobile_items-number">5.0.2.</span> <span class="toc_mobile_items-text">需求</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#合并小文件的代码实现"><span class="toc_mobile_items-number">5.0.3.</span> <span class="toc_mobile_items-text">合并小文件的代码实现</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#运行作业-3"><span class="toc_mobile_items-number">5.0.4.</span> <span class="toc_mobile_items-text">运行作业</span></a></li></ol></li></ol></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#写在前面"><span class="toc-number">1.</span> <span class="toc-text">写在前面</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MapReduce实现join操作"><span class="toc-number">2.</span> <span class="toc-text">MapReduce实现join操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#join操作概述"><span class="toc-number">2.0.1.</span> <span class="toc-text">join操作概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#需求分析"><span class="toc-number">2.0.2.</span> <span class="toc-text">需求分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Map端join的实现原理"><span class="toc-number">2.0.3.</span> <span class="toc-text">Map端join的实现原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Map端join的代码实现"><span class="toc-number">2.0.4.</span> <span class="toc-text">Map端join的代码实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#运行作业"><span class="toc-number">2.0.5.</span> <span class="toc-text">运行作业</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MapReduce实现排序操作"><span class="toc-number">3.</span> <span class="toc-text">MapReduce实现排序操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#需求分析-1"><span class="toc-number">3.0.1.</span> <span class="toc-text">需求分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce排序的实现原理"><span class="toc-number">3.0.2.</span> <span class="toc-text">MapReduce排序的实现原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce排序的代码实现"><span class="toc-number">3.0.3.</span> <span class="toc-text">MapReduce排序的代码实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#运行作业-1"><span class="toc-number">3.0.4.</span> <span class="toc-text">运行作业</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MapReduce实现二次排序操作"><span class="toc-number">4.</span> <span class="toc-text">MapReduce实现二次排序操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#二次排序概述"><span class="toc-number">4.0.1.</span> <span class="toc-text">二次排序概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#需求分析-2"><span class="toc-number">4.0.2.</span> <span class="toc-text">需求分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce二次排序的实现原理"><span class="toc-number">4.0.3.</span> <span class="toc-text">MapReduce二次排序的实现原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce二次排序的代码实现"><span class="toc-number">4.0.4.</span> <span class="toc-text">MapReduce二次排序的代码实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#运行作业-2"><span class="toc-number">4.0.5.</span> <span class="toc-text">运行作业</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#使用MapReduce合并小文件"><span class="toc-number">5.</span> <span class="toc-text">使用MapReduce合并小文件</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#概述"><span class="toc-number">5.0.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#需求"><span class="toc-number">5.0.2.</span> <span class="toc-text">需求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#合并小文件的代码实现"><span class="toc-number">5.0.3.</span> <span class="toc-text">合并小文件的代码实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#运行作业-3"><span class="toc-number">5.0.4.</span> <span class="toc-text">运行作业</span></a></li></ol></li></ol></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png)"><div id="post-info"><div id="post-title"><div class="posttitle">MapReduce的高级应用</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-10-26</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></span><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon fa-fw" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">897</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon fa-fw" aria-hidden="true"></i><span>阅读时长: 3 分钟</span><div class="post-meta-pv-cv"><span class="post-meta__separator">|</span><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span><span class="post-meta__separator">|</span><i class="fa fa-comments-o post-meta__icon fa-fw" aria-hidden="true"></i><span>评论数:</span><a href="/2020/10/26/hadoop-11-advanced-application-of-mapreduce/#post-comment"><span class="gitalk-comment-count comment-count"></span></a></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><html><head></head><body><h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>前面学习的都是MapReduce较为基本的操作，接下来学习一些MapReduce的高级应用，主要包括使用MapReduce完成join操作、排序操作、二次排序操作和小文件合并操作，这些应用在实际工作中非常有帮助。</p>
<h1 id="MapReduce实现join操作"><a href="#MapReduce实现join操作" class="headerlink" title="MapReduce实现join操作"></a>MapReduce实现join操作</h1><h3 id="join操作概述"><a href="#join操作概述" class="headerlink" title="join操作概述"></a>join操作概述</h3><p>如果你之前熟悉数据库，那么肯定知道使用SQL语法实现join操作是非常简单的，但是在大数据场景下使用MapReduce编程模型来实现类似的join操作其实是比较困难的。通常在实际工作中，我们都是借助于Hive、Spark SQL等框架来实现join，既然这里是学习，那么对于MapReduce实现join操作的原理还是有必要学习一下，它对于理解join操作的底层是有非常大的帮助。接下来开始学习，如何使用MapReduce API来实现join操作。</p>
<h3 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h3><p>假设现在有如下两个txt文件，里面的内容如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">//emp.txt数据</span><br><span class="line">519,smith,clerk,8920,1990-10-01,880.00,20</span><br><span class="line">536,alien,salesman,8945,1992-09-11,1600.00,30</span><br><span class="line">558,ward,salesman,8945,1992-09-22,1380.00,30</span><br><span class="line">596,jones,manager,8968,1992-12-19,3682.00,20</span><br><span class="line"></span><br><span class="line">//dept.txt数据</span><br><span class="line">10,accounting,new york</span><br><span class="line">20,research,dallas</span><br><span class="line">30,sales,chicago</span><br><span class="line">40,operations,boston</span><br></pre></td></tr></tbody></table></figure></div>
<p>其中emp.txt中各列的含义为empno、ename、ejob、enumber、ebirthday、emoney、deptno。而dept.txt中各列的含义为deptno、dname和city。</p>
<p>将下来有如下一条SQL语句：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select e.empno,e.ename,d.deptno,d.dname from emp e join dept d on e.deptno=d.deptno;</span><br></pre></td></tr></tbody></table></figure></div>
<p>可以看到这个SQL语句中只使用了empno、ename、deptno、dname 等4个属性，因此可以定义一个Employee，然后再加一个flag属性，当它值为1标识dept，为0则是emp。<br>我们希望能使用MapReduce来实现上述SQL的功能。</p>
<h3 id="Map端join的实现原理"><a href="#Map端join的实现原理" class="headerlink" title="Map端join的实现原理"></a>Map端join的实现原理</h3><p>接下来学习MapReduce Map端的join的实现原理，如下所示：<br>（1）Map端读取所有的文件，并在输出的内容中加上标识，用于表示数据是从哪个文件里来的。<br>（2）在Reduce处理函数中，按照（1）中的标识来对数据进行处理；<br>（3）之后根据Key，使用join来求出结果并进行输出。</p>
<h3 id="Map端join的代码实现"><a href="#Map端join的代码实现" class="headerlink" title="Map端join的代码实现"></a>Map端join的代码实现</h3><p>（1）定义一个员工类。新建一个reducejoin包，并在该包内新建一个<code>Employee</code>类，其中的代码如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line">public class Employee implements WritableComparable {</span><br><span class="line">    private String empNo = "";</span><br><span class="line">    private String empName = "";</span><br><span class="line">    private String deptNo = "";</span><br><span class="line">    private String deptName = "";</span><br><span class="line">    //用于区分是员工还是部门</span><br><span class="line">    private int flag = 0;</span><br><span class="line"></span><br><span class="line">    public Employee() {</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public Employee(String empNo, String empName, String deptNo, String deptName, int flag) {</span><br><span class="line">        this.empNo = empNo;</span><br><span class="line">        this.empName = empName;</span><br><span class="line">        this.deptNo = deptNo;</span><br><span class="line">        this.deptName = deptName;</span><br><span class="line">        this.flag = flag;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 这个方法后续使用非常方便</span><br><span class="line">     * */</span><br><span class="line">    public Employee(Employee employee){</span><br><span class="line">        this.empNo = employee.empNo;</span><br><span class="line">        this.empName = employee.empName;</span><br><span class="line">        this.deptNo = employee.deptNo;</span><br><span class="line">        this.deptName = employee.deptName;</span><br><span class="line">        this.flag = employee.flag;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public String getEmpNo() {</span><br><span class="line">        return empNo;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public void setEmpNo(String empNo) {</span><br><span class="line">        this.empNo = empNo;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public String getEmpName() {</span><br><span class="line">        return empName;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public void setEmpName(String empName) {</span><br><span class="line">        this.empName = empName;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public String getDeptNo() {</span><br><span class="line">        return deptNo;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public void setDeptNo(String deptNo) {</span><br><span class="line">        this.deptNo = deptNo;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public String getDeptName() {</span><br><span class="line">        return deptName;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public void setDeptName(String deptName) {</span><br><span class="line">        this.deptName = deptName;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public int getFlag() {</span><br><span class="line">        return flag;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public void setFlag(int flag) {</span><br><span class="line">        this.flag = flag;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public String toString() {</span><br><span class="line">        return "Employee{" +</span><br><span class="line">                "empNo='" + empNo + '\'' +</span><br><span class="line">                ", empName='" + empName + '\'' +</span><br><span class="line">                ", deptNo='" + deptNo + '\'' +</span><br><span class="line">                ", deptName='" + deptName + '\'' +</span><br><span class="line">                ", flag=" + flag +</span><br><span class="line">                '}';</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void readFields(DataInput dataInput) throws IOException {</span><br><span class="line">        this.empNo = dataInput.readUTF();</span><br><span class="line">        this.empName = dataInput.readUTF();</span><br><span class="line">        this.deptNo = dataInput.readUTF();</span><br><span class="line">        this.deptName = dataInput.readUTF();</span><br><span class="line">        this.flag = dataInput.readInt();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void write(DataOutput dataOutput) throws IOException {</span><br><span class="line">        dataOutput.writeUTF(this.empNo);</span><br><span class="line">        dataOutput.writeUTF(this.empName);</span><br><span class="line">        dataOutput.writeUTF(this.deptNo);</span><br><span class="line">        dataOutput.writeUTF(this.deptName);</span><br><span class="line">        dataOutput.writeInt(this.flag);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    //不进行排序</span><br><span class="line">    @Override</span><br><span class="line">    public int compareTo(Object o) {</span><br><span class="line">        return 0;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div>
<p>（2）自定义一个Mapper类。在reducejoin包内新建一个<code>MyMapper</code>类，其中的代码如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">public class MyMapper extends Mapper<longwritable, text,longwritable,employee> {</longwritable,></span><br><span class="line">    @Override</span><br><span class="line">    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {</span><br><span class="line">        String[] valArray = value.toString().split(",");</span><br><span class="line">        System.out.println("valArray.length="+valArray.length + " valArray[0]="+valArray[0]);</span><br><span class="line"></span><br><span class="line">        if(valArray.length<=3){</span><br><span class="line">            //根据每行依据逗号分隔后形成的数组的长度来判断是emp还是dept</span><br><span class="line">            //小于或者等于3为dept</span><br><span class="line">            Employee dept = new Employee();</span><br><span class="line">            dept.setDeptNo(valArray[0]);</span><br><span class="line">            dept.setDeptName(valArray[1]);</span><br><span class="line">            //dept的flag的值为1</span><br><span class="line">            dept.setFlag(1);</span><br><span class="line">            context.write(new LongWritable(Long.parseLong(valArray[0])),dept);</span><br><span class="line">        }else{</span><br><span class="line">            //反正则说明为emp</span><br><span class="line">            Employee employee = new Employee();</span><br><span class="line">            employee.setEmpNo(valArray[0]);</span><br><span class="line">            employee.setEmpName(valArray[1]);</span><br><span class="line">            employee.setDeptNo(valArray[6]);</span><br><span class="line">            //emp的flag的值为0</span><br><span class="line">            //emp的部门deptName需要通过deptNo从dept中获取</span><br><span class="line">            employee.setFlag(0);</span><br><span class="line">            context.write(new LongWritable(Long.parseLong(valArray[0])),employee);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div>
<p>（3）自定义一个Reducer类。在reducejoin包内新建一个<code>MyReducer</code>类，其中的代码如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">public class MyReducer extends Reducer<longwritable,employee, nullwritable, text> {</longwritable,employee,></span><br><span class="line">    @Override</span><br><span class="line">    protected void reduce(LongWritable key, Iterable<employee> values, Context context) throws IOException, InterruptedException {</employee></span><br><span class="line">        //员工与部门之间存在多对一的关系</span><br><span class="line">        Employee dept = null;</span><br><span class="line">        List<employee> employeeList = new ArrayList<>();</employee></span><br><span class="line"></span><br><span class="line">        for(Employee value:values){</span><br><span class="line">            if(value.getFlag()==0){</span><br><span class="line">                //emp的flag的值为0，故此为emp</span><br><span class="line">                Employee employee = new Employee(value);</span><br><span class="line">                employeeList.add(employee);</span><br><span class="line">            }else{</span><br><span class="line">                //dept的flag的值为1，故此为dept</span><br><span class="line">                dept = new Employee(value);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        if(dept!=null){</span><br><span class="line">            for(Employee employee:employeeList){</span><br><span class="line">                employee.setDeptName(dept.getDeptName());</span><br><span class="line">                context.write(NullWritable.get(),new Text(employee.toString()));</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div>
<p>（4）自定义一个驱动类。在reducejoin包内新建一个<code>MyReduceJoinApp</code>类，其中的代码如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">public class MyReduceJoinApp {</span><br><span class="line">    public static void main(String[] args) throws URISyntaxException, IOException, ClassNotFoundException, InterruptedException {</span><br><span class="line">        String INPUT_PATH = "hdfs://master:9000/inputjoin";</span><br><span class="line">        String OUTPUT_PATH = "hdfs://master:9000/outputjoin";</span><br><span class="line"></span><br><span class="line">        Configuration configuration= new Configuration();</span><br><span class="line">        final FileSystem fileSystem = FileSystem.get(new URI(INPUT_PATH), configuration);</span><br><span class="line">        if(fileSystem.exists(new Path(OUTPUT_PATH))){</span><br><span class="line">            fileSystem.delete(new Path(OUTPUT_PATH),true);</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        Job job = Job.getInstance(configuration,"MyReduceJoinApp");</span><br><span class="line"></span><br><span class="line">        //运行Jar类</span><br><span class="line">        job.setJarByClass(MyReduceJoinApp.class);</span><br><span class="line"></span><br><span class="line">        //设置自定义Mapper类和map函数输出数据的Key和Value的类型</span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line">        job.setMapOutputKeyClass(LongWritable.class);</span><br><span class="line">        job.setMapOutputValueClass(Employee.class);</span><br><span class="line"></span><br><span class="line">        //Shuffle把数据从Map端拷贝到Reduce端</span><br><span class="line">        //指定Reducer类和输出Key、Value的类型</span><br><span class="line">        job.setReducerClass(MyReducer.class);</span><br><span class="line">        //设置输出结果的key/value的类型，也就是最终存储在HDFS上结果文件的key/value的类型</span><br><span class="line">        job.setOutputKeyClass(NullWritable.class);</span><br><span class="line">        job.setOutputValueClass(Employee.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        //设置输入/输出格式</span><br><span class="line">        FileInputFormat.addInputPath(job,new Path(INPUT_PATH));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, new Path(OUTPUT_PATH));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        //提交job</span><br><span class="line">        //如果job运行成功，那么程序就会正常退出</span><br><span class="line">        System.exit(job.waitForCompletion(true)?0:1);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div>
<h3 id="运行作业"><a href="#运行作业" class="headerlink" title="运行作业"></a>运行作业</h3><p>接下来将提交该作业至集群中运行，操作过程如下所示：<br>（1）在本地Windows机器上使用<code>mvn clean package -DskipTests</code>命令或者直接在IDEA中使用maven插件进行清理打包，之后就可以生成<code>envy-mapreduce-1.0-SNAPSHOT.jar</code>包，为了和之前的代码进行区分，这里将其重命名为<code>envy-mapreduce-reducejoin-1.0-SNAPSHOT.jar</code>；<br>（2）将（1）中的jar包上传至虚拟机<code>/home/hadoop/lib</code>目录下；<br>（3）在虚拟机<code>/home/hadoop</code>目录中新建一个emp.txt的测试文件，其中的内容如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">519,smith,clerk,8920,1990-10-01,880.00,20</span><br><span class="line">536,alien,salesman,8945,1992-09-11,1600.00,30</span><br><span class="line">558,ward,salesman,8945,1992-09-22,1380.00,30</span><br><span class="line">596,jones,manager,8968,1992-12-19,3682.00,20</span><br></pre></td></tr></tbody></table></figure></div>
<p>接着再新建另一个dept.txt的测试文件，其中的内容如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">10,accounting,new york</span><br><span class="line">20,research,dallas</span><br><span class="line">30,sales,chicago</span><br><span class="line">40,operations,boston</span><br></pre></td></tr></tbody></table></figure></div>
<p>之后在HDFS根目录下新建<code>inputjoin</code>目录（这个目录就必须与你设置的<code>INPUT_PATH</code>保持一致，前面的<code>hdfs://master:9000</code>表示主机），之后将这两个文件上传至该目录：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -mkdir /inputjoin</span><br><span class="line">[root@master sbin]# hadoop fs -put /home/hadoop/emp.txt /inputjoin</span><br><span class="line">[root@master sbin]# hadoop fs -put /home/hadoop/dept.txt /inputjoin</span><br></pre></td></tr></tbody></table></figure></div>
<p>之后确认文件上传HDFS中：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -ls -R /inputjoin</span><br><span class="line">-rw-r--r--   1 root supergroup         80 2020-06-13 21:58 /inputjoin/dept.txt</span><br><span class="line">-rw-r--r--   1 root supergroup        178 2020-06-13 21:56 /inputjoin/emp.txt</span><br></pre></td></tr></tbody></table></figure></div>
<p>（4）提交MapReduce作业到集群中运行：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop jar /home/hadoop/lib/envy-mapreduce-reducejoin-1.0-SNAPSHOT.jar com.envy.envymapreduce.reducejoin.MyReduceJoinApp</span><br></pre></td></tr></tbody></table></figure></div>
<p>执行流程如下所示：</p>
<p><a href="https://upload-images.jianshu.io/upload_images/8964398-baabb442a47fbf1f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" target="_blank" rel="noopener" data-fancybox="group" data-caption class="fancybox"><img alt data-src="https://upload-images.jianshu.io/upload_images/8964398-baabb442a47fbf1f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload mediumZoom" title></a></p>
<p>（5）查看作业输出结果，如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master lib]# hadoop fs -ls /outputjoin</span><br><span class="line">Found 5 items</span><br><span class="line">-rw-r--r--   1 root supergroup          0 2020-06-13 22:00 /outputjoin/_SUCCESS</span><br><span class="line">-rw-r--r--   1 root supergroup          0 2020-06-13 22:00 /outputjoin/part-r-00000</span><br></pre></td></tr></tbody></table></figure></div>
<p>之后查看一下各个文件的内容，如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@master lib]# hadoop fs -text /outputjoin/*</span><br><span class="line">Employee{empNo='519', empName='smith', deptNo='20', deptName='research', flag=0}</span><br><span class="line">Employee{empNo='596', empName='jones', deptNo='20', deptName='research0', flag=0}</span><br><span class="line">Employee{empNo='536', empName='alien', deptNo='30', deptName='sales', flag=0}</span><br><span class="line">Employee{empNo='558', empName='ward', deptNo='30', deptName='sales', flag=0}</span><br></pre></td></tr></tbody></table></figure></div>
<h1 id="MapReduce实现排序操作"><a href="#MapReduce实现排序操作" class="headerlink" title="MapReduce实现排序操作"></a>MapReduce实现排序操作</h1><h3 id="需求分析-1"><a href="#需求分析-1" class="headerlink" title="需求分析"></a>需求分析</h3><p>现在要求对输入文件中的数据进行排序，其中输入文件中的每行内容均为一个数字，即一个数据。要求在每行输出两个间隔的数字，其中第一个数字代表原始数据在原始数据集中的排位，第二个数字则代表原始数据。</p>
<h3 id="MapReduce排序的实现原理"><a href="#MapReduce排序的实现原理" class="headerlink" title="MapReduce排序的实现原理"></a>MapReduce排序的实现原理</h3><p>MapReduce默认支持排序，如果Key为封装int的IntWritable类型，那么MapReduce将会按照数字大小来对Key进行排序。如果Key为封装String的Text类型，那么MapReduce将会按照字典顺序来对字符串进行排序。</p>
<p>因此开发者可以使用MapReduce中内置的排序功能来实现上述需求，但在此之前需要了解默认排序的规则，即按照Key值进行排序。</p>
<p>那么上例，我们就应该使用封装int的IntWritable类型，也就是在map中将读入的数据转化成IntWritable类型，之后将其作为Key值（此时的Value值随意）；reduce在拿到<code><key,value-list></key,value-list></code>之后，将输入的Key作为Value进行输出，并根据<code>Value-list</code>中元素的个数来决定输出的次数。也就是说输出的Key其实是一个全局变量，它用于统计Key的当前位次信息。</p>
<h3 id="MapReduce排序的代码实现"><a href="#MapReduce排序的代码实现" class="headerlink" title="MapReduce排序的代码实现"></a>MapReduce排序的代码实现</h3><p>新建一个sort包，并在里面新建一个<code>SortApp</code>类，其中的代码如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">public class SortApp {</span><br><span class="line">    /**</span><br><span class="line">     * 接口中泛型KEYIN, VALUEIN, KEYOUT, VALUEOUT</span><br><span class="line">     * */</span><br><span class="line">    public static class MyMapper extends Mapper<longwritable, text, intwritable,intwritable>{</longwritable,></span><br><span class="line"></span><br><span class="line">        private static IntWritable data = new IntWritable();</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {</span><br><span class="line">           String line = value.toString();</span><br><span class="line">           data.set(Integer.parseInt(line));</span><br><span class="line">           context.write(data,new IntWritable(1));</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 接口中泛型KEYIN, VALUEIN, KEYOUT, VALUEOUT</span><br><span class="line">     * */</span><br><span class="line">    public static class MyReducer extends Reducer<intwritable, intwritable, intwritable,intwritable> {</intwritable,></span><br><span class="line"></span><br><span class="line">        private static IntWritable data = new IntWritable(1);</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void reduce(IntWritable key, Iterable<intwritable> values, Context context) throws IOException, InterruptedException {</intwritable></span><br><span class="line">            //此处的key其实就是mapper中的data，即原始数据</span><br><span class="line">            for(IntWritable value:values){</span><br><span class="line">                context.write(data,key);</span><br><span class="line">                data = new IntWritable(data.get()+1);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws URISyntaxException, IOException, ClassNotFoundException, InterruptedException {</span><br><span class="line">        String INPUT_PATH = "hdfs://master:9000/inputsort";</span><br><span class="line">        String OUTPUT_PATH = "hdfs://master:9000/outputsort";</span><br><span class="line"></span><br><span class="line">        Configuration configuration= new Configuration();</span><br><span class="line">        final FileSystem fileSystem = FileSystem.get(new URI(INPUT_PATH), configuration);</span><br><span class="line">        if(fileSystem.exists(new Path(OUTPUT_PATH))){</span><br><span class="line">            fileSystem.delete(new Path(OUTPUT_PATH),true);</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        Job job = Job.getInstance(configuration,"SortApp");</span><br><span class="line"></span><br><span class="line">        //运行Jar类</span><br><span class="line">        job.setJarByClass(SortApp.class);</span><br><span class="line"></span><br><span class="line">        //设置自定义Mapper类和map函数输出数据的Key和Value的类型</span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line">        job.setMapOutputKeyClass(IntWritable.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        //Shuffle把数据从Map端拷贝到Reduce端</span><br><span class="line">        //指定Reducer类和输出Key、Value的类型</span><br><span class="line">        job.setReducerClass(MyReducer.class);</span><br><span class="line">        //设置输出结果的key/value的类型，也就是最终存储在HDFS上结果文件的key/value的类型</span><br><span class="line">        job.setOutputKeyClass(IntWritable.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line">        </span><br><span class="line">        //设置输入/输出格式</span><br><span class="line">        FileInputFormat.addInputPath(job,new Path(INPUT_PATH));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, new Path(OUTPUT_PATH));</span><br><span class="line">        </span><br><span class="line">        //提交job</span><br><span class="line">        //如果job运行成功，那么程序就会正常退出</span><br><span class="line">        System.exit(job.waitForCompletion(true)?0:1);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div>
<h3 id="运行作业-1"><a href="#运行作业-1" class="headerlink" title="运行作业"></a>运行作业</h3><p>接下来将提交该作业至集群中运行，操作过程如下所示：<br>（1）在本地Windows机器上使用<code>mvn clean package -DskipTests</code>命令或者直接在IDEA中使用maven插件进行清理打包，之后就可以生成<code>envy-mapreduce-1.0-SNAPSHOT.jar</code>包，为了和之前的代码进行区分，这里将其重命名为<code>envy-mapreduce-sort-1.0-SNAPSHOT.jar</code>；<br>（2）将（1）中的jar包上传至虚拟机<code>/home/hadoop/lib</code>目录下；<br>（3）在虚拟机<code>/home/hadoop</code>目录中新建一个sort.txt的测试文件，其中的内容如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1</span><br><span class="line">4</span><br><span class="line">3</span><br><span class="line">6</span><br><span class="line">8</span><br><span class="line">5</span><br><span class="line">2</span><br><span class="line">9</span><br><span class="line">7</span><br></pre></td></tr></tbody></table></figure></div>
<p>之后在HDFS根目录下新建<code>inputsort</code>目录（这个目录就必须与你设置的<code>INPUT_PATH</code>保持一致，前面的<code>hdfs://master:9000</code>表示主机），之后将这个文件上传至该目录：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -mkdir /inputsort</span><br><span class="line">[root@master sbin]# hadoop fs -put /home/hadoop/sort.txt /inputsort</span><br></pre></td></tr></tbody></table></figure></div>
<p>之后确认文件上传HDFS中：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -ls -R /inputsort</span><br><span class="line">-rw-r--r--   1 root supergroup         80 2020-06-13 21:58 /inputsort/sort.txt</span><br></pre></td></tr></tbody></table></figure></div>
<p>（4）提交MapReduce作业到集群中运行：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop jar /home/hadoop/lib/envy-mapreduce-sort-1.0-SNAPSHOT.jar com.envy.envymapreduce.sort.SortApp</span><br></pre></td></tr></tbody></table></figure></div>
<p>执行流程如下所示：</p>
<p><a href="https://upload-images.jianshu.io/upload_images/8964398-78ef2e9c3a3ec276.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" target="_blank" rel="noopener" data-fancybox="group" data-caption class="fancybox"><img alt data-src="https://upload-images.jianshu.io/upload_images/8964398-78ef2e9c3a3ec276.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload mediumZoom" title></a></p>
<p>（5）查看作业输出结果，如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master lib]# hadoop fs -ls /outputsort</span><br><span class="line">Found 2 items</span><br><span class="line">-rw-r--r--   1 root supergroup          0 2020-06-16 16:19 /outputsort/_SUCCESS</span><br><span class="line">-rw-r--r--   1 root supergroup         36 2020-06-16 16:19 /outputsort/part-r-00000</span><br></pre></td></tr></tbody></table></figure></div>
<p>之后查看一下各个文件的内容，如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@master hadoop]# hadoop fs -text /outputsort/*</span><br><span class="line">1	1</span><br><span class="line">2	2</span><br><span class="line">3	3</span><br><span class="line">4	4</span><br><span class="line">5	5</span><br><span class="line">6	6</span><br><span class="line">7	7</span><br><span class="line">8	8</span><br><span class="line">9	9</span><br></pre></td></tr></tbody></table></figure></div>
<h1 id="MapReduce实现二次排序操作"><a href="#MapReduce实现二次排序操作" class="headerlink" title="MapReduce实现二次排序操作"></a>MapReduce实现二次排序操作</h1><h3 id="二次排序概述"><a href="#二次排序概述" class="headerlink" title="二次排序概述"></a>二次排序概述</h3><p>默认情况下，Map输出的结果会对Key进行默认的排序，但是有时候在对Key进行排序的同时，还需要对Value进行排序，这就是常说的二次排序。</p>
<h3 id="需求分析-2"><a href="#需求分析-2" class="headerlink" title="需求分析"></a>需求分析</h3><p>现在要求对输入文件中的数据进行二次排序，如下所示的每行两列，列与列之间采用逗号进行分割，要求输出结果先按照第一列的值进行升序排序，如果第一列的值相等，那么就按照第二列的值进行升序排序。下面就是经过二次排序后的内容：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">30 10</span><br><span class="line">30 20</span><br><span class="line">30 30</span><br><span class="line">30 40</span><br><span class="line"></span><br><span class="line">40 5</span><br><span class="line">40 10</span><br><span class="line">40 20</span><br><span class="line">40 30</span><br><span class="line"></span><br><span class="line">50 10</span><br><span class="line">50 20</span><br><span class="line">50 50</span><br><span class="line">50 60</span><br></pre></td></tr></tbody></table></figure></div>
<h3 id="MapReduce二次排序的实现原理"><a href="#MapReduce二次排序的实现原理" class="headerlink" title="MapReduce二次排序的实现原理"></a>MapReduce二次排序的实现原理</h3><p>（1）Mapper任务会接收输入分片，然后不断调用map函数，进而对记录进行处理，处理完成后，将其转换为新的<code><key,value></key,value></code>输出。<br>（2）对map函数输出的<code><key,value></key,value></code>调用分区函数，将数据进行分区。不同分区的数据会被送到不同的Reducer任务中。<br>（3）对于不同分区的数据，它会按照Key进行排序，因此此处的Key必须实现<code>WritableComparable</code>接口，该接口继承了<code>Comparable</code>，因此可以进行比较排序。<br>（4）对于排序后的<code><key,value></key,value></code>，它会按照Key进行分组。如果Key相同，那么相同Key的<code><key,value></key,value></code>就被分到一个组中，这样使得最后每个分组都会调用一次reduce函数。<br>（5）排序、分组后的数据就会被送到Reducer节点中。</p>
<h3 id="MapReduce二次排序的代码实现"><a href="#MapReduce二次排序的代码实现" class="headerlink" title="MapReduce二次排序的代码实现"></a>MapReduce二次排序的代码实现</h3><p>新建一个secondsort包，并在里面新建一个<code>IntPair</code>类，该类就是定义每次（行读取）的两个整数。其中的代码如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">public class IntPair implements WritableComparable<intpair> {</intpair></span><br><span class="line">    private int first = 0;</span><br><span class="line">    private int second = 0;</span><br><span class="line"></span><br><span class="line">    public void set(int left,int right){</span><br><span class="line">        this.first = left;</span><br><span class="line">        this.second = right;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public int getFirst(){</span><br><span class="line">        return first;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public int getSecond(){</span><br><span class="line">        return second;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public int hashCode() {</span><br><span class="line">        return first+"".hashCode()+second+"".hashCode();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public boolean equals(Object right) {</span><br><span class="line">        if(right instanceof IntPair){</span><br><span class="line">            IntPair r = (IntPair)right;</span><br><span class="line">            return r.first == first && r.second == second;</span><br><span class="line">        }else{</span><br><span class="line">            return false;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void readFields(DataInput dataInput) throws IOException {</span><br><span class="line">        first = dataInput.readInt();</span><br><span class="line">        second = dataInput.readInt();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void write(DataOutput dataOutput) throws IOException {</span><br><span class="line">        dataOutput.writeInt(first);</span><br><span class="line">        dataOutput.writeInt(second);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 自定义Key排序时的方法</span><br><span class="line">     * */</span><br><span class="line">    @Override</span><br><span class="line">    public int compareTo(IntPair o) {</span><br><span class="line">        if(first !=o.first){</span><br><span class="line">            return first-o.first;</span><br><span class="line">        }else if(second != o.second){</span><br><span class="line">            return second - o.second;</span><br><span class="line">        }else{</span><br><span class="line">            return 0;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div>
<p>接着新建一个<code>SecondarySortApp</code>类，该类为项目的启动类，里面的代码如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">public class SecondarySortApp {</span><br><span class="line">    public static class MyMapper extends Mapper<longwritable, text,intpair, intwritable>{</longwritable,></span><br><span class="line">        private final IntPair key = new IntPair();</span><br><span class="line">        private final IntWritable value = new IntWritable();</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void map(LongWritable inKey, Text inValue, Context context) throws IOException, InterruptedException {</span><br><span class="line">            StringTokenizer itr = new StringTokenizer(inValue.toString());</span><br><span class="line">            int left = 0;</span><br><span class="line">            int right = 0;</span><br><span class="line">            if(itr.hasMoreTokens()){</span><br><span class="line">                left = Integer.parseInt(itr.nextToken());</span><br><span class="line">                if(itr.hasMoreTokens()){</span><br><span class="line">                    right = Integer.parseInt(itr.nextToken());</span><br><span class="line">                }</span><br><span class="line">                key.set(left,right);</span><br><span class="line">                value.set(right);</span><br><span class="line">                context.write(key,value);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        /**</span><br><span class="line">         * 在分组的时候，只比较原来的key，而不是组合key</span><br><span class="line">         * */</span><br><span class="line">        public static class GroupComparator implements RawComparator<intpair>{</intpair></span><br><span class="line">            @Override</span><br><span class="line">            public int compare(byte[] b1, int s1, int i1, byte[] b2, int s2, int i2) {</span><br><span class="line">                return WritableComparator.compareBytes(b1,s1,Integer.SIZE/8,b2,s2,Integer.SIZE/8);</span><br><span class="line">            }</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public int compare(IntPair o1, IntPair o2) {</span><br><span class="line">                return o1.getFirst() - o2.getFirst();</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    public static class MyReducer extends Reducer<intpair,intwritable,text,intwritable>{</intpair,intwritable,text,intwritable></span><br><span class="line">        private static final Text SEPARATOR = new Text("----------");</span><br><span class="line">        private final Text first = new Text();</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void reduce(IntPair key, Iterable<intwritable> values, Context context) throws IOException, InterruptedException {</intwritable></span><br><span class="line">            context.write(SEPARATOR,null);</span><br><span class="line">            first.set(Integer.toString(key.getFirst()));</span><br><span class="line">            for(IntWritable value:values){</span><br><span class="line">                context.write(first,value);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws URISyntaxException, IOException, ClassNotFoundException, InterruptedException {</span><br><span class="line">        String INPUT_PATH = "hdfs://master:9000/inputsecondsort";</span><br><span class="line">        String OUTPUT_PATH = "hdfs://master:9000/outputsecondsort";</span><br><span class="line"></span><br><span class="line">        Configuration configuration= new Configuration();</span><br><span class="line">        final FileSystem fileSystem = FileSystem.get(new URI(INPUT_PATH), configuration);</span><br><span class="line">        if(fileSystem.exists(new Path(OUTPUT_PATH))){</span><br><span class="line">            fileSystem.delete(new Path(OUTPUT_PATH),true);</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        Job job = Job.getInstance(configuration,"SecondarySortApp");</span><br><span class="line"></span><br><span class="line">        //运行Jar类</span><br><span class="line">        job.setJarByClass(SecondarySortApp.class);</span><br><span class="line"></span><br><span class="line">        //设置自定义Mapper类和map函数输出数据的Key和Value的类型</span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line">        job.setMapOutputKeyClass(IntPair.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        //分组函数</span><br><span class="line">        job.setGroupingComparatorClass(MyMapper.GroupComparator.class);</span><br><span class="line"></span><br><span class="line">        //Shuffle把数据从Map端拷贝到Reduce端</span><br><span class="line">        //指定Reducer类和输出Key、Value的类型</span><br><span class="line">        job.setReducerClass(MyReducer.class);</span><br><span class="line">        //设置输出结果的key/value的类型，也就是最终存储在HDFS上结果文件的key/value的类型</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        //设置输入/输出路径</span><br><span class="line">        FileInputFormat.addInputPath(job,new Path(INPUT_PATH));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, new Path(OUTPUT_PATH));</span><br><span class="line"></span><br><span class="line">        //设置输入/输出格式</span><br><span class="line">        job.setInputFormatClass(TextInputFormat.class);</span><br><span class="line">        job.setOutputFormatClass(TextOutputFormat.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        //提交job</span><br><span class="line">        //如果job运行成功，那么程序就会正常退出</span><br><span class="line">        System.exit(job.waitForCompletion(true)?0:1);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div>
<h3 id="运行作业-2"><a href="#运行作业-2" class="headerlink" title="运行作业"></a>运行作业</h3><p>接下来将提交该作业至集群中运行，操作过程如下所示：<br>（1）在本地Windows机器上使用<code>mvn clean package -DskipTests</code>命令或者直接在IDEA中使用maven插件进行清理打包，之后就可以生成<code>envy-mapreduce-1.0-SNAPSHOT.jar</code>包，为了和之前的代码进行区分，这里将其重命名为<code>envy-mapreduce-secondarysort-1.0-SNAPSHOT.jar</code>；<br>（2）将（1）中的jar包上传至虚拟机<code>/home/hadoop/lib</code>目录下；<br>（3）在虚拟机<code>/home/hadoop</code>目录中新建一个secondarysort.txt的测试文件，其中的内容如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">50  60</span><br><span class="line">30  20</span><br><span class="line">40  20</span><br><span class="line">30  40</span><br><span class="line"></span><br><span class="line">50  50</span><br><span class="line">40  10</span><br><span class="line">50  20</span><br><span class="line">40  30</span><br><span class="line"></span><br><span class="line">50  10</span><br><span class="line">30  30</span><br><span class="line">40  5</span><br><span class="line">30  10</span><br></pre></td></tr></tbody></table></figure></div>
<p>之后在HDFS根目录下新建<code>inputsecondsort</code>目录（这个目录就必须与你设置的<code>INPUT_PATH</code>保持一致，前面的<code>hdfs://master:9000</code>表示主机），之后将这两个文件上传至该目录：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -mkdir /inputsecondsort</span><br><span class="line">[root@master sbin]# hadoop fs -put /home/hadoop/secondarysort.txt /inputsecondsort</span><br></pre></td></tr></tbody></table></figure></div>
<p>之后确认文件上传HDFS中：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -ls -R /inputsecondsort</span><br><span class="line">-rw-r--r--   1 root supergroup         73 2020-06-16 15:57 /inputsecondsort/secondarysort.txt</span><br></pre></td></tr></tbody></table></figure></div>
<p>（4）提交MapReduce作业到集群中运行：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop jar /home/hadoop/lib/envy-mapreduce-secondarysort-1.0-SNAPSHOT.jar com.envy.envymapreduce.secondsort.SecondarySortApp</span><br></pre></td></tr></tbody></table></figure></div>
<p>执行流程如下所示：</p>
<p><a href="https://upload-images.jianshu.io/upload_images/8964398-0658b1f8bc3863e1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" target="_blank" rel="noopener" data-fancybox="group" data-caption class="fancybox"><img alt data-src="https://upload-images.jianshu.io/upload_images/8964398-0658b1f8bc3863e1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload mediumZoom" title></a></p>
<p>（5）查看作业输出结果，如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master hadoop]# hadoop fs -ls /outputsecondsort</span><br><span class="line">Found 2 items</span><br><span class="line">-rw-r--r--   1 root supergroup          0 2020-06-16 16:03 /outputsecondsort/_SUCCESS</span><br><span class="line">-rw-r--r--   1 root supergroup        104 2020-06-16 16:03 /outputsecondsort/part-r-00000</span><br></pre></td></tr></tbody></table></figure></div>
<p>之后查看一下各个文件的内容，如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@master hadoop]# hadoop fs -text /outputsecondsort/*</span><br><span class="line">----------</span><br><span class="line">30	10</span><br><span class="line">30	20</span><br><span class="line">30	30</span><br><span class="line">30	40</span><br><span class="line">----------</span><br><span class="line">40	5</span><br><span class="line">40	10</span><br><span class="line">40	20</span><br><span class="line">40	30</span><br><span class="line">----------</span><br><span class="line">50	10</span><br><span class="line">50	20</span><br><span class="line">50	50</span><br><span class="line">50	60</span><br></pre></td></tr></tbody></table></figure></div>
<h1 id="使用MapReduce合并小文件"><a href="#使用MapReduce合并小文件" class="headerlink" title="使用MapReduce合并小文件"></a>使用MapReduce合并小文件</h1><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>前面说过Hadoop处理单个大文件比处理多个小文件更有效率，此外单个文件也非常占用HDFS的存储空间，因此将小文件合并起来进行处理是较为科学的方式。</p>
<h3 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h3><p>要求通过使用MapReduce API来对小文件进行合并，并输出为SequenceFile。</p>
<h3 id="合并小文件的代码实现"><a href="#合并小文件的代码实现" class="headerlink" title="合并小文件的代码实现"></a>合并小文件的代码实现</h3><p>新建一个merge包，并在里面新建一个<code>WholeFileRecordReader</code>类，这是开发者自定义的<code>RecordReader</code>类，注意它需要继承RecordReader，并重写其中的方法：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">public class WholeFileRecordReader extends RecordReader<nullwritable, byteswritable> {</nullwritable,></span><br><span class="line"></span><br><span class="line">    private FileSplit fileSplit;</span><br><span class="line">    private Configuration configuration;</span><br><span class="line">    private BytesWritable value = new BytesWritable();</span><br><span class="line">    private boolean processed = false;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void initialize(InputSplit inputSplit, TaskAttemptContext taskAttemptContext) throws IOException, InterruptedException {</span><br><span class="line">        this.fileSplit = (FileSplit) inputSplit;</span><br><span class="line">        this.configuration = taskAttemptContext.getConfiguration();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public boolean nextKeyValue() throws IOException, InterruptedException {</span><br><span class="line">        if(!processed){</span><br><span class="line">            byte[] contents = new byte[(int)fileSplit.getLength()];</span><br><span class="line">            Path path = fileSplit.getPath();</span><br><span class="line">            FileSystem fileSystem = path.getFileSystem(configuration);</span><br><span class="line">            FSDataInputStream inputStream = null;</span><br><span class="line">            try{</span><br><span class="line">                inputStream = fileSystem.open(path);</span><br><span class="line">                IOUtils.readFully(inputStream,contents,0,contents.length);</span><br><span class="line">                value.set(contents,0,contents.length);</span><br><span class="line">            }finally {</span><br><span class="line">                IOUtils.closeStream(inputStream);</span><br><span class="line">            }</span><br><span class="line">            processed = true;</span><br><span class="line">            return true;</span><br><span class="line">        }</span><br><span class="line">        return false;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public NullWritable getCurrentKey() throws IOException, InterruptedException {</span><br><span class="line">        return NullWritable.get();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public BytesWritable getCurrentValue() throws IOException, InterruptedException {</span><br><span class="line">        return value;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public float getProgress() throws IOException, InterruptedException {</span><br><span class="line">        return processed ? 1.0f: 0.0f;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void close() throws IOException {</span><br><span class="line">        //do nothing</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div>
<p>接着新建一个<code>WholeFileInputFormat</code>类，该类用于将整个文件作为一条记录处理的<code>InputFormat</code>类，其中的代码如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public class WholeFileInputFormat extends FileInputFormat<nullwritable, byteswritable> {</nullwritable,></span><br><span class="line">    //设置每个小文件不可分片，保证一个小文件生成一个key-value</span><br><span class="line">    @Override</span><br><span class="line">    protected boolean isSplitable(JobContext context, Path filename) {</span><br><span class="line">        return false;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public RecordReader<nullwritable, byteswritable> createRecordReader(InputSplit inputSplit, TaskAttemptContext taskAttemptContext) throws IOException, InterruptedException {</nullwritable,></span><br><span class="line">        WholeFileRecordReader wholeFileRecordReader = new WholeFileRecordReader();</span><br><span class="line">        wholeFileRecordReader.initialize(inputSplit,taskAttemptContext);</span><br><span class="line">        return wholeFileRecordReader;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div>
<p>最后新建一个启动类<code>WholeMergeApp</code>，里面的代码如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">public class WholeMergeApp {</span><br><span class="line">    /**</span><br><span class="line">     * 将小文件打包成SequenceFile</span><br><span class="line">     */</span><br><span class="line">    static class SequenceFileMapper extends Mapper<nullwritable, byteswritable, text,byteswritable>{</nullwritable,></span><br><span class="line">        private Text filenameKey;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void setup(Context context) throws IOException, InterruptedException {</span><br><span class="line">            InputSplit split = context.getInputSplit();</span><br><span class="line">            Path path =( (FileSplit)split).getPath();</span><br><span class="line">            filenameKey = new Text(path.toString());</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void map(NullWritable key, BytesWritable value, Context context) throws IOException, InterruptedException {</span><br><span class="line">            context.write(filenameKey,value);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws URISyntaxException, IOException, ClassNotFoundException, InterruptedException {</span><br><span class="line">        String INPUT_PATH = "hdfs://master:9000/inputmerge";</span><br><span class="line">        String OUTPUT_PATH = "hdfs://master:9000/outputmerge";</span><br><span class="line"></span><br><span class="line">        Configuration configuration= new Configuration();</span><br><span class="line">        final FileSystem fileSystem = FileSystem.get(new URI(INPUT_PATH), configuration);</span><br><span class="line">        if(fileSystem.exists(new Path(OUTPUT_PATH))){</span><br><span class="line">            fileSystem.delete(new Path(OUTPUT_PATH),true);</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        Job job = Job.getInstance(configuration,"WholeMergeApp");</span><br><span class="line"></span><br><span class="line">        //运行Jar类</span><br><span class="line">        job.setJarByClass(WholeMergeApp.class);</span><br><span class="line"></span><br><span class="line">        //设置输入/输出格式</span><br><span class="line">        job.setInputFormatClass(WholeFileInputFormat.class);</span><br><span class="line">        job.setOutputFormatClass(SequenceFileOutputFormat.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        //设置输出结果的key/value的类型，也就是最终存储在HDFS上结果文件的key/value的类型</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(BytesWritable.class);</span><br><span class="line">        job.setMapperClass(SequenceFileMapper.class);</span><br><span class="line"></span><br><span class="line">        //设置输入/输出目录</span><br><span class="line">        FileInputFormat.addInputPath(job,new Path(INPUT_PATH));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, new Path(OUTPUT_PATH));</span><br><span class="line"></span><br><span class="line">        //提交job</span><br><span class="line">        //如果job运行成功，那么程序就会正常退出</span><br><span class="line">        System.exit(job.waitForCompletion(true)?0:1);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></div>
<h3 id="运行作业-3"><a href="#运行作业-3" class="headerlink" title="运行作业"></a>运行作业</h3><p>接下来将提交该作业至集群中运行，操作过程如下所示：<br>（1）在本地Windows机器上使用<code>mvn clean package -DskipTests</code>命令或者直接在IDEA中使用maven插件进行清理打包，之后就可以生成<code>envy-mapreduce-1.0-SNAPSHOT.jar</code>包，为了和之前的代码进行区分，这里将其重命名为<code>envy-mapreduce-merge-1.0-SNAPSHOT.jar</code>；<br>（2）将（1）中的jar包上传至虚拟机<code>/home/hadoop/lib</code>目录下；<br>（3）在虚拟机<code>/home/hadoop</code>目录中新建一个merge.txt的测试文件，其中的内容如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">50  60</span><br><span class="line">30  20</span><br><span class="line">40  20</span><br><span class="line">30  40</span><br></pre></td></tr></tbody></table></figure></div>
<p>之后在HDFS根目录下新建<code>inputmerge</code>目录（这个目录就必须与你设置的<code>INPUT_PATH</code>保持一致，前面的<code>hdfs://master:9000</code>表示主机），之后将这两个文件上传至该目录：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -mkdir /inputmerge</span><br><span class="line">[root@master sbin]# hadoop fs -put /home/hadoop/merge.txt /inputmerge</span><br></pre></td></tr></tbody></table></figure></div>
<p>之后确认文件上传HDFS中：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -ls -R /inputmerge</span><br><span class="line">-rw-r--r--   1 root supergroup         28 2020-06-16 22:19 /inputmerge/merge.txt</span><br></pre></td></tr></tbody></table></figure></div>
<p>（4）提交MapReduce作业到集群中运行：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop jar /home/hadoop/lib/envy-mapreduce-merge-1.0-SNAPSHOT.jar com.envy.envymapreduce.merge.WholeMergeApp</span><br></pre></td></tr></tbody></table></figure></div>
<p>执行流程如下所示：</p>
<p><a href="https://upload-images.jianshu.io/upload_images/8964398-0fd8ddbd20e4b278.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" target="_blank" rel="noopener" data-fancybox="group" data-caption class="fancybox"><img alt data-src="https://upload-images.jianshu.io/upload_images/8964398-0fd8ddbd20e4b278.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" class="lazyload mediumZoom" title></a></p>
<p>（5）查看作业输出结果，如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master hadoop]# hadoop fs -ls /outputmerge</span><br><span class="line">Found 2 items</span><br><span class="line">-rw-r--r--   1 root supergroup          0 2020-06-16 22:21 /outputmerge/_SUCCESS</span><br><span class="line">-rw-r--r--   1 root supergroup        167 2020-06-16 22:21 /outputmerge/part-r-00000</span><br></pre></td></tr></tbody></table></figure></div>
<p>之后查看一下各个文件的内容，如下所示：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master hadoop]# hadoop fs -text /outputmerge/*</span><br><span class="line">hdfs://master:9000/inputmerge/merge.txt	35 30 20 20 36 30 0a 33 30 20 20 32 30 0a 34 30 20 20 32 30 0a 33 30 20 20 34 30 0a</span><br></pre></td></tr></tbody></table></figure></div>
<p>这样本篇关于MapReduce的高级应用相关内容就到此为止，后续学习其他内容。</p>
</body></html></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">余思</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://envyzhan.top/2020/10/26/hadoop-11-advanced-application-of-mapreduce/">http://envyzhan.top/2020/10/26/hadoop-11-advanced-application-of-mapreduce/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://envyzhan.top">余思博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/hadoop/">hadoop    </a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/10/27/hadoop-12-yarn-basic/"><img class="prev_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>YARN入门</span></div></a></div><div class="next-post pull_right"><a href="/2020/10/23/hadoop-10-other-content-partitioner-and-recordreader/"><img class="next_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>MapReduce其他内容</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/10/27/hadoop-12-yarn-basic/" title="YARN入门"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2021-03-01</div><div class="relatedPosts_title">YARN入门</div></div></a></div><div class="relatedPosts_item"><a href="/2020/10/23/hadoop-10-other-content-partitioner-and-recordreader/" title="MapReduce其他内容"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2021-03-01</div><div class="relatedPosts_title">MapReduce其他内容</div></div></a></div><div class="relatedPosts_item"><a href="/2020/10/22/hadoop-9-how-to-develop-mapreduce-application/" title="如何开发MapReduce应用"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2021-03-01</div><div class="relatedPosts_title">如何开发MapReduce应用</div></div></a></div><div class="relatedPosts_item"><a href="/2020/10/21/hadoop-8-mapreduce-basic/" title="MapReduce入门"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2021-03-01</div><div class="relatedPosts_title">MapReduce入门</div></div></a></div><div class="relatedPosts_item"><a href="/2020/10/19/hadoop-7-hdfs-advanced-knowledge/" title="HDFS高级知识"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2021-03-01</div><div class="relatedPosts_title">HDFS高级知识</div></div></a></div><div class="relatedPosts_item"><a href="/2020/10/17/hadoop-6-deeply-study-the-operation-principal-of-hdfs/" title="深入学习HDFS的运行原理"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2021-03-01</div><div class="relatedPosts_title">深入学习HDFS的运行原理</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '9996b44b488f2fc52124',
  clientSecret: '6bec0f8e9c032eeae6211a5d4cffa3c97e2d4a64',
  repo: 'blogcomment',
  owner: 'Envythink',
  admin: 'Envythink',
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN',
  updateCountCallback: commentCount
})
gitalk.render('gitalk-container')

function commentCount(n){
  document.getElementsByClassName('gitalk-comment-count')[0].innerHTML= n
}</script></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">Copyright &copy;2017-2021 余思博客, 版权所有</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">簡</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/fireworks.js"></script><script src="/js/tw_cn.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>