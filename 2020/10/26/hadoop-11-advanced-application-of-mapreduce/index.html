<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>MapReduce的高级应用 | 余思博客</title><meta name="keywords" content="hadoop"><meta name="author" content="余思"><meta name="copyright" content="余思"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="写在前面前面学习的都是MapReduce较为基本的操作，接下来学习一些MapReduce的高级应用，主要包括使用MapReduce完成join操作、排序操作、二次排序操作和小文件合并操作，这些应用在实际工作中非常有帮助。 MapReduce实现join操作join操作概述如果你之前熟悉数据库，那么肯定知道使用SQL语法实现join操作是非常简单的，但是在大数据场景下使用MapReduce编程模型来">
<meta property="og:type" content="article">
<meta property="og:title" content="MapReduce的高级应用">
<meta property="og:url" content="http://envyzhan.asia/2020/10/26/hadoop-11-advanced-application-of-mapreduce/index.html">
<meta property="og:site_name" content="余思博客">
<meta property="og:description" content="写在前面前面学习的都是MapReduce较为基本的操作，接下来学习一些MapReduce的高级应用，主要包括使用MapReduce完成join操作、排序操作、二次排序操作和小文件合并操作，这些应用在实际工作中非常有帮助。 MapReduce实现join操作join操作概述如果你之前熟悉数据库，那么肯定知道使用SQL语法实现join操作是非常简单的，但是在大数据场景下使用MapReduce编程模型来">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png">
<meta property="article:published_time" content="2020-10-26T13:23:04.000Z">
<meta property="article:modified_time" content="2021-03-01T07:07:54.245Z">
<meta property="article:author" content="余思">
<meta property="article:tag" content="hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="http://envyzhan.asia/2020/10/26/hadoop-11-advanced-application-of-mapreduce/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'MapReduce的高级应用',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-03-01 15:07:54'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="余思博客" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">249</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 前端</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/html/"><i class="fa-fw fa fa-cog"></i><span> HTML/CSS</span></a></li><li><a class="site-page child" href="/categories/javascript/"><i class="fa-fw fa fa-cogs"></i><span> JavaScript</span></a></li><li><a class="site-page child" href="/categories/vuejs/"><i class="fa-fw fa fa-certificate"></i><span> Vue.js</span></a></li><li><a class="site-page child" href="/categories/flutter/"><i class="fa-fw fa fa-bullseye"></i><span> Flutter</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> Java</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/java/"><i class="fa-fw fa fa-book"></i><span> Java</span></a></li><li><a class="site-page child" href="/categories/ssm/"><i class="fa-fw fa fa-cube"></i><span> SSM</span></a></li><li><a class="site-page child" href="/categories/springboot/"><i class="fa-fw fa fa-cubes"></i><span> SpringBoot</span></a></li><li><a class="site-page child" href="/categories/springcloud/"><i class="fa-fw fa fa-cloud"></i><span> SpringCloud</span></a></li><li><a class="site-page child" href="/categories/springsecurity/"><i class="fa-fw fa fa-bullseye"></i><span> SpringSecurity</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 运维</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/pythonbase/"><i class="fa-fw fa fa-book"></i><span> Python</span></a></li><li><a class="site-page child" href="/categories/go/"><i class="fa-fw fa fa-google-plus"></i><span> Golang</span></a></li><li><a class="site-page child" href="/categories/devops/"><i class="fa-fw fa fa-road"></i><span> DevOps</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 中间件</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/mysql/"><i class="fa-fw fa fa-database"></i><span> MySQL</span></a></li><li><a class="site-page child" href="/categories/redis/"><i class="fa-fw fa fa-random"></i><span> Redis</span></a></li><li><a class="site-page child" href="/categories/other/"><i class="fa-fw fa fa-location-arrow"></i><span> 其他</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-bell"></i><span> 其他</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/datastructs/"><i class="fa-fw fa fa-plug"></i><span> 算法结构</span></a></li><li><a class="site-page child" href="/categories/tools/"><i class="fa-fw fa fa-hourglass"></i><span> 实用工具</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-address-book"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/onenote/"><i class="fa-fw fa fa-laptop"></i><span> 个人随笔</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-comment"></i><span> 留言</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">余思博客</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 前端</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/html/"><i class="fa-fw fa fa-cog"></i><span> HTML/CSS</span></a></li><li><a class="site-page child" href="/categories/javascript/"><i class="fa-fw fa fa-cogs"></i><span> JavaScript</span></a></li><li><a class="site-page child" href="/categories/vuejs/"><i class="fa-fw fa fa-certificate"></i><span> Vue.js</span></a></li><li><a class="site-page child" href="/categories/flutter/"><i class="fa-fw fa fa-bullseye"></i><span> Flutter</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> Java</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/java/"><i class="fa-fw fa fa-book"></i><span> Java</span></a></li><li><a class="site-page child" href="/categories/ssm/"><i class="fa-fw fa fa-cube"></i><span> SSM</span></a></li><li><a class="site-page child" href="/categories/springboot/"><i class="fa-fw fa fa-cubes"></i><span> SpringBoot</span></a></li><li><a class="site-page child" href="/categories/springcloud/"><i class="fa-fw fa fa-cloud"></i><span> SpringCloud</span></a></li><li><a class="site-page child" href="/categories/springsecurity/"><i class="fa-fw fa fa-bullseye"></i><span> SpringSecurity</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 运维</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/pythonbase/"><i class="fa-fw fa fa-book"></i><span> Python</span></a></li><li><a class="site-page child" href="/categories/go/"><i class="fa-fw fa fa-google-plus"></i><span> Golang</span></a></li><li><a class="site-page child" href="/categories/devops/"><i class="fa-fw fa fa-road"></i><span> DevOps</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 中间件</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/mysql/"><i class="fa-fw fa fa-database"></i><span> MySQL</span></a></li><li><a class="site-page child" href="/categories/redis/"><i class="fa-fw fa fa-random"></i><span> Redis</span></a></li><li><a class="site-page child" href="/categories/other/"><i class="fa-fw fa fa-location-arrow"></i><span> 其他</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-bell"></i><span> 其他</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/datastructs/"><i class="fa-fw fa fa-plug"></i><span> 算法结构</span></a></li><li><a class="site-page child" href="/categories/tools/"><i class="fa-fw fa fa-hourglass"></i><span> 实用工具</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-address-book"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/onenote/"><i class="fa-fw fa fa-laptop"></i><span> 个人随笔</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-comment"></i><span> 留言</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">MapReduce的高级应用</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-10-26T13:23:04.000Z" title="发表于 2020-10-26 21:23:04">2020-10-26</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-03-01T07:07:54.245Z" title="更新于 2021-03-01 15:07:54">2021-03-01</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>前面学习的都是MapReduce较为基本的操作，接下来学习一些MapReduce的高级应用，主要包括使用MapReduce完成join操作、排序操作、二次排序操作和小文件合并操作，这些应用在实际工作中非常有帮助。</p>
<h1 id="MapReduce实现join操作"><a href="#MapReduce实现join操作" class="headerlink" title="MapReduce实现join操作"></a>MapReduce实现join操作</h1><h3 id="join操作概述"><a href="#join操作概述" class="headerlink" title="join操作概述"></a>join操作概述</h3><p>如果你之前熟悉数据库，那么肯定知道使用SQL语法实现join操作是非常简单的，但是在大数据场景下使用MapReduce编程模型来实现类似的join操作其实是比较困难的。通常在实际工作中，我们都是借助于Hive、Spark SQL等框架来实现join，既然这里是学习，那么对于MapReduce实现join操作的原理还是有必要学习一下，它对于理解join操作的底层是有非常大的帮助。接下来开始学习，如何使用MapReduce API来实现join操作。</p>
<h3 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h3><p>假设现在有如下两个txt文件，里面的内容如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">//emp.txt数据</span><br><span class="line">519,smith,clerk,8920,1990-10-01,880.00,20</span><br><span class="line">536,alien,salesman,8945,1992-09-11,1600.00,30</span><br><span class="line">558,ward,salesman,8945,1992-09-22,1380.00,30</span><br><span class="line">596,jones,manager,8968,1992-12-19,3682.00,20</span><br><span class="line"></span><br><span class="line">//dept.txt数据</span><br><span class="line">10,accounting,new york</span><br><span class="line">20,research,dallas</span><br><span class="line">30,sales,chicago</span><br><span class="line">40,operations,boston</span><br></pre></td></tr></table></figure>
<p>其中emp.txt中各列的含义为empno、ename、ejob、enumber、ebirthday、emoney、deptno。而dept.txt中各列的含义为deptno、dname和city。</p>
<p>将下来有如下一条SQL语句：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select e.empno,e.ename,d.deptno,d.dname from emp e join dept d on e.deptno=d.deptno;</span><br></pre></td></tr></table></figure>
<p>可以看到这个SQL语句中只使用了empno、ename、deptno、dname 等4个属性，因此可以定义一个Employee，然后再加一个flag属性，当它值为1标识dept，为0则是emp。<br>我们希望能使用MapReduce来实现上述SQL的功能。</p>
<h3 id="Map端join的实现原理"><a href="#Map端join的实现原理" class="headerlink" title="Map端join的实现原理"></a>Map端join的实现原理</h3><p>接下来学习MapReduce Map端的join的实现原理，如下所示：<br>（1）Map端读取所有的文件，并在输出的内容中加上标识，用于表示数据是从哪个文件里来的。<br>（2）在Reduce处理函数中，按照（1）中的标识来对数据进行处理；<br>（3）之后根据Key，使用join来求出结果并进行输出。</p>
<h3 id="Map端join的代码实现"><a href="#Map端join的代码实现" class="headerlink" title="Map端join的代码实现"></a>Map端join的代码实现</h3><p>（1）定义一个员工类。新建一个reducejoin包，并在该包内新建一个<code>Employee</code>类，其中的代码如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line">public class Employee implements WritableComparable &#123;</span><br><span class="line">    private String empNo = &quot;&quot;;</span><br><span class="line">    private String empName = &quot;&quot;;</span><br><span class="line">    private String deptNo = &quot;&quot;;</span><br><span class="line">    private String deptName = &quot;&quot;;</span><br><span class="line">    //用于区分是员工还是部门</span><br><span class="line">    private int flag = 0;</span><br><span class="line"></span><br><span class="line">    public Employee() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public Employee(String empNo, String empName, String deptNo, String deptName, int flag) &#123;</span><br><span class="line">        this.empNo = empNo;</span><br><span class="line">        this.empName = empName;</span><br><span class="line">        this.deptNo = deptNo;</span><br><span class="line">        this.deptName = deptName;</span><br><span class="line">        this.flag = flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 这个方法后续使用非常方便</span><br><span class="line">     * */</span><br><span class="line">    public Employee(Employee employee)&#123;</span><br><span class="line">        this.empNo = employee.empNo;</span><br><span class="line">        this.empName = employee.empName;</span><br><span class="line">        this.deptNo = employee.deptNo;</span><br><span class="line">        this.deptName = employee.deptName;</span><br><span class="line">        this.flag = employee.flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public String getEmpNo() &#123;</span><br><span class="line">        return empNo;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setEmpNo(String empNo) &#123;</span><br><span class="line">        this.empNo = empNo;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public String getEmpName() &#123;</span><br><span class="line">        return empName;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setEmpName(String empName) &#123;</span><br><span class="line">        this.empName = empName;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public String getDeptNo() &#123;</span><br><span class="line">        return deptNo;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setDeptNo(String deptNo) &#123;</span><br><span class="line">        this.deptNo = deptNo;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public String getDeptName() &#123;</span><br><span class="line">        return deptName;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setDeptName(String deptName) &#123;</span><br><span class="line">        this.deptName = deptName;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public int getFlag() &#123;</span><br><span class="line">        return flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setFlag(int flag) &#123;</span><br><span class="line">        this.flag = flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public String toString() &#123;</span><br><span class="line">        return &quot;Employee&#123;&quot; +</span><br><span class="line">                &quot;empNo=&#x27;&quot; + empNo + &#x27;\&#x27;&#x27; +</span><br><span class="line">                &quot;, empName=&#x27;&quot; + empName + &#x27;\&#x27;&#x27; +</span><br><span class="line">                &quot;, deptNo=&#x27;&quot; + deptNo + &#x27;\&#x27;&#x27; +</span><br><span class="line">                &quot;, deptName=&#x27;&quot; + deptName + &#x27;\&#x27;&#x27; +</span><br><span class="line">                &quot;, flag=&quot; + flag +</span><br><span class="line">                &#x27;&#125;&#x27;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void readFields(DataInput dataInput) throws IOException &#123;</span><br><span class="line">        this.empNo = dataInput.readUTF();</span><br><span class="line">        this.empName = dataInput.readUTF();</span><br><span class="line">        this.deptNo = dataInput.readUTF();</span><br><span class="line">        this.deptName = dataInput.readUTF();</span><br><span class="line">        this.flag = dataInput.readInt();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void write(DataOutput dataOutput) throws IOException &#123;</span><br><span class="line">        dataOutput.writeUTF(this.empNo);</span><br><span class="line">        dataOutput.writeUTF(this.empName);</span><br><span class="line">        dataOutput.writeUTF(this.deptNo);</span><br><span class="line">        dataOutput.writeUTF(this.deptName);</span><br><span class="line">        dataOutput.writeInt(this.flag);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    //不进行排序</span><br><span class="line">    @Override</span><br><span class="line">    public int compareTo(Object o) &#123;</span><br><span class="line">        return 0;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（2）自定义一个Mapper类。在reducejoin包内新建一个<code>MyMapper</code>类，其中的代码如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">public class MyMapper extends Mapper&lt;LongWritable, Text,LongWritable,Employee&gt; &#123;</span><br><span class="line">    @Override</span><br><span class="line">    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">        String[] valArray = value.toString().split(&quot;,&quot;);</span><br><span class="line">        System.out.println(&quot;valArray.length=&quot;+valArray.length + &quot; valArray[0]=&quot;+valArray[0]);</span><br><span class="line"></span><br><span class="line">        if(valArray.length&lt;=3)&#123;</span><br><span class="line">            //根据每行依据逗号分隔后形成的数组的长度来判断是emp还是dept</span><br><span class="line">            //小于或者等于3为dept</span><br><span class="line">            Employee dept = new Employee();</span><br><span class="line">            dept.setDeptNo(valArray[0]);</span><br><span class="line">            dept.setDeptName(valArray[1]);</span><br><span class="line">            //dept的flag的值为1</span><br><span class="line">            dept.setFlag(1);</span><br><span class="line">            context.write(new LongWritable(Long.parseLong(valArray[0])),dept);</span><br><span class="line">        &#125;else&#123;</span><br><span class="line">            //反正则说明为emp</span><br><span class="line">            Employee employee = new Employee();</span><br><span class="line">            employee.setEmpNo(valArray[0]);</span><br><span class="line">            employee.setEmpName(valArray[1]);</span><br><span class="line">            employee.setDeptNo(valArray[6]);</span><br><span class="line">            //emp的flag的值为0</span><br><span class="line">            //emp的部门deptName需要通过deptNo从dept中获取</span><br><span class="line">            employee.setFlag(0);</span><br><span class="line">            context.write(new LongWritable(Long.parseLong(valArray[0])),employee);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（3）自定义一个Reducer类。在reducejoin包内新建一个<code>MyReducer</code>类，其中的代码如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">public class MyReducer extends Reducer&lt;LongWritable,Employee, NullWritable, Text&gt; &#123;</span><br><span class="line">    @Override</span><br><span class="line">    protected void reduce(LongWritable key, Iterable&lt;Employee&gt; values, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">        //员工与部门之间存在多对一的关系</span><br><span class="line">        Employee dept = null;</span><br><span class="line">        List&lt;Employee&gt; employeeList = new ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        for(Employee value:values)&#123;</span><br><span class="line">            if(value.getFlag()==0)&#123;</span><br><span class="line">                //emp的flag的值为0，故此为emp</span><br><span class="line">                Employee employee = new Employee(value);</span><br><span class="line">                employeeList.add(employee);</span><br><span class="line">            &#125;else&#123;</span><br><span class="line">                //dept的flag的值为1，故此为dept</span><br><span class="line">                dept = new Employee(value);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if(dept!=null)&#123;</span><br><span class="line">            for(Employee employee:employeeList)&#123;</span><br><span class="line">                employee.setDeptName(dept.getDeptName());</span><br><span class="line">                context.write(NullWritable.get(),new Text(employee.toString()));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（4）自定义一个驱动类。在reducejoin包内新建一个<code>MyReduceJoinApp</code>类，其中的代码如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">public class MyReduceJoinApp &#123;</span><br><span class="line">    public static void main(String[] args) throws URISyntaxException, IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">        String INPUT_PATH = &quot;hdfs://master:9000/inputjoin&quot;;</span><br><span class="line">        String OUTPUT_PATH = &quot;hdfs://master:9000/outputjoin&quot;;</span><br><span class="line"></span><br><span class="line">        Configuration configuration= new Configuration();</span><br><span class="line">        final FileSystem fileSystem = FileSystem.get(new URI(INPUT_PATH), configuration);</span><br><span class="line">        if(fileSystem.exists(new Path(OUTPUT_PATH)))&#123;</span><br><span class="line">            fileSystem.delete(new Path(OUTPUT_PATH),true);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Job job = Job.getInstance(configuration,&quot;MyReduceJoinApp&quot;);</span><br><span class="line"></span><br><span class="line">        //运行Jar类</span><br><span class="line">        job.setJarByClass(MyReduceJoinApp.class);</span><br><span class="line"></span><br><span class="line">        //设置自定义Mapper类和map函数输出数据的Key和Value的类型</span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line">        job.setMapOutputKeyClass(LongWritable.class);</span><br><span class="line">        job.setMapOutputValueClass(Employee.class);</span><br><span class="line"></span><br><span class="line">        //Shuffle把数据从Map端拷贝到Reduce端</span><br><span class="line">        //指定Reducer类和输出Key、Value的类型</span><br><span class="line">        job.setReducerClass(MyReducer.class);</span><br><span class="line">        //设置输出结果的key/value的类型，也就是最终存储在HDFS上结果文件的key/value的类型</span><br><span class="line">        job.setOutputKeyClass(NullWritable.class);</span><br><span class="line">        job.setOutputValueClass(Employee.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        //设置输入/输出格式</span><br><span class="line">        FileInputFormat.addInputPath(job,new Path(INPUT_PATH));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, new Path(OUTPUT_PATH));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        //提交job</span><br><span class="line">        //如果job运行成功，那么程序就会正常退出</span><br><span class="line">        System.exit(job.waitForCompletion(true)?0:1);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="运行作业"><a href="#运行作业" class="headerlink" title="运行作业"></a>运行作业</h3><p>接下来将提交该作业至集群中运行，操作过程如下所示：<br>（1）在本地Windows机器上使用<code>mvn clean package -DskipTests</code>命令或者直接在IDEA中使用maven插件进行清理打包，之后就可以生成<code>envy-mapreduce-1.0-SNAPSHOT.jar</code>包，为了和之前的代码进行区分，这里将其重命名为<code>envy-mapreduce-reducejoin-1.0-SNAPSHOT.jar</code>；<br>（2）将（1）中的jar包上传至虚拟机<code>/home/hadoop/lib</code>目录下；<br>（3）在虚拟机<code>/home/hadoop</code>目录中新建一个emp.txt的测试文件，其中的内容如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">519,smith,clerk,8920,1990-10-01,880.00,20</span><br><span class="line">536,alien,salesman,8945,1992-09-11,1600.00,30</span><br><span class="line">558,ward,salesman,8945,1992-09-22,1380.00,30</span><br><span class="line">596,jones,manager,8968,1992-12-19,3682.00,20</span><br></pre></td></tr></table></figure>
<p>接着再新建另一个dept.txt的测试文件，其中的内容如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">10,accounting,new york</span><br><span class="line">20,research,dallas</span><br><span class="line">30,sales,chicago</span><br><span class="line">40,operations,boston</span><br></pre></td></tr></table></figure>
<p>之后在HDFS根目录下新建<code>inputjoin</code>目录（这个目录就必须与你设置的<code>INPUT_PATH</code>保持一致，前面的<code>hdfs://master:9000</code>表示主机），之后将这两个文件上传至该目录：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -mkdir /inputjoin</span><br><span class="line">[root@master sbin]# hadoop fs -put /home/hadoop/emp.txt /inputjoin</span><br><span class="line">[root@master sbin]# hadoop fs -put /home/hadoop/dept.txt /inputjoin</span><br></pre></td></tr></table></figure>
<p>之后确认文件上传HDFS中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -ls -R /inputjoin</span><br><span class="line">-rw-r--r--   1 root supergroup         80 2020-06-13 21:58 /inputjoin/dept.txt</span><br><span class="line">-rw-r--r--   1 root supergroup        178 2020-06-13 21:56 /inputjoin/emp.txt</span><br></pre></td></tr></table></figure>
<p>（4）提交MapReduce作业到集群中运行：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop jar /home/hadoop/lib/envy-mapreduce-reducejoin-1.0-SNAPSHOT.jar com.envy.envymapreduce.reducejoin.MyReduceJoinApp</span><br></pre></td></tr></table></figure>
<p>执行流程如下所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/8964398-baabb442a47fbf1f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
<p>（5）查看作业输出结果，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master lib]# hadoop fs -ls /outputjoin</span><br><span class="line">Found 5 items</span><br><span class="line">-rw-r--r--   1 root supergroup          0 2020-06-13 22:00 /outputjoin/_SUCCESS</span><br><span class="line">-rw-r--r--   1 root supergroup          0 2020-06-13 22:00 /outputjoin/part-r-00000</span><br></pre></td></tr></table></figure>
<p>之后查看一下各个文件的内容，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@master lib]# hadoop fs -text /outputjoin/*</span><br><span class="line">Employee&#123;empNo=&#x27;519&#x27;, empName=&#x27;smith&#x27;, deptNo=&#x27;20&#x27;, deptName=&#x27;research&#x27;, flag=0&#125;</span><br><span class="line">Employee&#123;empNo=&#x27;596&#x27;, empName=&#x27;jones&#x27;, deptNo=&#x27;20&#x27;, deptName=&#x27;research0&#x27;, flag=0&#125;</span><br><span class="line">Employee&#123;empNo=&#x27;536&#x27;, empName=&#x27;alien&#x27;, deptNo=&#x27;30&#x27;, deptName=&#x27;sales&#x27;, flag=0&#125;</span><br><span class="line">Employee&#123;empNo=&#x27;558&#x27;, empName=&#x27;ward&#x27;, deptNo=&#x27;30&#x27;, deptName=&#x27;sales&#x27;, flag=0&#125;</span><br></pre></td></tr></table></figure>
<h1 id="MapReduce实现排序操作"><a href="#MapReduce实现排序操作" class="headerlink" title="MapReduce实现排序操作"></a>MapReduce实现排序操作</h1><h3 id="需求分析-1"><a href="#需求分析-1" class="headerlink" title="需求分析"></a>需求分析</h3><p>现在要求对输入文件中的数据进行排序，其中输入文件中的每行内容均为一个数字，即一个数据。要求在每行输出两个间隔的数字，其中第一个数字代表原始数据在原始数据集中的排位，第二个数字则代表原始数据。</p>
<h3 id="MapReduce排序的实现原理"><a href="#MapReduce排序的实现原理" class="headerlink" title="MapReduce排序的实现原理"></a>MapReduce排序的实现原理</h3><p>MapReduce默认支持排序，如果Key为封装int的IntWritable类型，那么MapReduce将会按照数字大小来对Key进行排序。如果Key为封装String的Text类型，那么MapReduce将会按照字典顺序来对字符串进行排序。</p>
<p>因此开发者可以使用MapReduce中内置的排序功能来实现上述需求，但在此之前需要了解默认排序的规则，即按照Key值进行排序。</p>
<p>那么上例，我们就应该使用封装int的IntWritable类型，也就是在map中将读入的数据转化成IntWritable类型，之后将其作为Key值（此时的Value值随意）；reduce在拿到<code>&lt;Key,Value-list&gt;</code>之后，将输入的Key作为Value进行输出，并根据<code>Value-list</code>中元素的个数来决定输出的次数。也就是说输出的Key其实是一个全局变量，它用于统计Key的当前位次信息。</p>
<h3 id="MapReduce排序的代码实现"><a href="#MapReduce排序的代码实现" class="headerlink" title="MapReduce排序的代码实现"></a>MapReduce排序的代码实现</h3><p>新建一个sort包，并在里面新建一个<code>SortApp</code>类，其中的代码如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">public class SortApp &#123;</span><br><span class="line">    /**</span><br><span class="line">     * 接口中泛型KEYIN, VALUEIN, KEYOUT, VALUEOUT</span><br><span class="line">     * */</span><br><span class="line">    public static class MyMapper extends Mapper&lt;LongWritable, Text, IntWritable,IntWritable&gt;&#123;</span><br><span class="line"></span><br><span class="line">        private static IntWritable data = new IntWritable();</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">           String line = value.toString();</span><br><span class="line">           data.set(Integer.parseInt(line));</span><br><span class="line">           context.write(data,new IntWritable(1));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 接口中泛型KEYIN, VALUEIN, KEYOUT, VALUEOUT</span><br><span class="line">     * */</span><br><span class="line">    public static class MyReducer extends Reducer&lt;IntWritable, IntWritable, IntWritable,IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">        private static IntWritable data = new IntWritable(1);</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void reduce(IntWritable key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            //此处的key其实就是mapper中的data，即原始数据</span><br><span class="line">            for(IntWritable value:values)&#123;</span><br><span class="line">                context.write(data,key);</span><br><span class="line">                data = new IntWritable(data.get()+1);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws URISyntaxException, IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">        String INPUT_PATH = &quot;hdfs://master:9000/inputsort&quot;;</span><br><span class="line">        String OUTPUT_PATH = &quot;hdfs://master:9000/outputsort&quot;;</span><br><span class="line"></span><br><span class="line">        Configuration configuration= new Configuration();</span><br><span class="line">        final FileSystem fileSystem = FileSystem.get(new URI(INPUT_PATH), configuration);</span><br><span class="line">        if(fileSystem.exists(new Path(OUTPUT_PATH)))&#123;</span><br><span class="line">            fileSystem.delete(new Path(OUTPUT_PATH),true);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Job job = Job.getInstance(configuration,&quot;SortApp&quot;);</span><br><span class="line"></span><br><span class="line">        //运行Jar类</span><br><span class="line">        job.setJarByClass(SortApp.class);</span><br><span class="line"></span><br><span class="line">        //设置自定义Mapper类和map函数输出数据的Key和Value的类型</span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line">        job.setMapOutputKeyClass(IntWritable.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        //Shuffle把数据从Map端拷贝到Reduce端</span><br><span class="line">        //指定Reducer类和输出Key、Value的类型</span><br><span class="line">        job.setReducerClass(MyReducer.class);</span><br><span class="line">        //设置输出结果的key/value的类型，也就是最终存储在HDFS上结果文件的key/value的类型</span><br><span class="line">        job.setOutputKeyClass(IntWritable.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line">        </span><br><span class="line">        //设置输入/输出格式</span><br><span class="line">        FileInputFormat.addInputPath(job,new Path(INPUT_PATH));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, new Path(OUTPUT_PATH));</span><br><span class="line">        </span><br><span class="line">        //提交job</span><br><span class="line">        //如果job运行成功，那么程序就会正常退出</span><br><span class="line">        System.exit(job.waitForCompletion(true)?0:1);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="运行作业-1"><a href="#运行作业-1" class="headerlink" title="运行作业"></a>运行作业</h3><p>接下来将提交该作业至集群中运行，操作过程如下所示：<br>（1）在本地Windows机器上使用<code>mvn clean package -DskipTests</code>命令或者直接在IDEA中使用maven插件进行清理打包，之后就可以生成<code>envy-mapreduce-1.0-SNAPSHOT.jar</code>包，为了和之前的代码进行区分，这里将其重命名为<code>envy-mapreduce-sort-1.0-SNAPSHOT.jar</code>；<br>（2）将（1）中的jar包上传至虚拟机<code>/home/hadoop/lib</code>目录下；<br>（3）在虚拟机<code>/home/hadoop</code>目录中新建一个sort.txt的测试文件，其中的内容如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1</span><br><span class="line">4</span><br><span class="line">3</span><br><span class="line">6</span><br><span class="line">8</span><br><span class="line">5</span><br><span class="line">2</span><br><span class="line">9</span><br><span class="line">7</span><br></pre></td></tr></table></figure>
<p>之后在HDFS根目录下新建<code>inputsort</code>目录（这个目录就必须与你设置的<code>INPUT_PATH</code>保持一致，前面的<code>hdfs://master:9000</code>表示主机），之后将这个文件上传至该目录：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -mkdir /inputsort</span><br><span class="line">[root@master sbin]# hadoop fs -put /home/hadoop/sort.txt /inputsort</span><br></pre></td></tr></table></figure>
<p>之后确认文件上传HDFS中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -ls -R /inputsort</span><br><span class="line">-rw-r--r--   1 root supergroup         80 2020-06-13 21:58 /inputsort/sort.txt</span><br></pre></td></tr></table></figure>
<p>（4）提交MapReduce作业到集群中运行：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop jar /home/hadoop/lib/envy-mapreduce-sort-1.0-SNAPSHOT.jar com.envy.envymapreduce.sort.SortApp</span><br></pre></td></tr></table></figure>
<p>执行流程如下所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/8964398-78ef2e9c3a3ec276.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
<p>（5）查看作业输出结果，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master lib]# hadoop fs -ls /outputsort</span><br><span class="line">Found 2 items</span><br><span class="line">-rw-r--r--   1 root supergroup          0 2020-06-16 16:19 /outputsort/_SUCCESS</span><br><span class="line">-rw-r--r--   1 root supergroup         36 2020-06-16 16:19 /outputsort/part-r-00000</span><br></pre></td></tr></table></figure>
<p>之后查看一下各个文件的内容，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@master hadoop]# hadoop fs -text /outputsort/*</span><br><span class="line">1	1</span><br><span class="line">2	2</span><br><span class="line">3	3</span><br><span class="line">4	4</span><br><span class="line">5	5</span><br><span class="line">6	6</span><br><span class="line">7	7</span><br><span class="line">8	8</span><br><span class="line">9	9</span><br></pre></td></tr></table></figure>
<h1 id="MapReduce实现二次排序操作"><a href="#MapReduce实现二次排序操作" class="headerlink" title="MapReduce实现二次排序操作"></a>MapReduce实现二次排序操作</h1><h3 id="二次排序概述"><a href="#二次排序概述" class="headerlink" title="二次排序概述"></a>二次排序概述</h3><p>默认情况下，Map输出的结果会对Key进行默认的排序，但是有时候在对Key进行排序的同时，还需要对Value进行排序，这就是常说的二次排序。</p>
<h3 id="需求分析-2"><a href="#需求分析-2" class="headerlink" title="需求分析"></a>需求分析</h3><p>现在要求对输入文件中的数据进行二次排序，如下所示的每行两列，列与列之间采用逗号进行分割，要求输出结果先按照第一列的值进行升序排序，如果第一列的值相等，那么就按照第二列的值进行升序排序。下面就是经过二次排序后的内容：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">30 10</span><br><span class="line">30 20</span><br><span class="line">30 30</span><br><span class="line">30 40</span><br><span class="line"></span><br><span class="line">40 5</span><br><span class="line">40 10</span><br><span class="line">40 20</span><br><span class="line">40 30</span><br><span class="line"></span><br><span class="line">50 10</span><br><span class="line">50 20</span><br><span class="line">50 50</span><br><span class="line">50 60</span><br></pre></td></tr></table></figure>
<h3 id="MapReduce二次排序的实现原理"><a href="#MapReduce二次排序的实现原理" class="headerlink" title="MapReduce二次排序的实现原理"></a>MapReduce二次排序的实现原理</h3><p>（1）Mapper任务会接收输入分片，然后不断调用map函数，进而对记录进行处理，处理完成后，将其转换为新的<code>&lt;key,value&gt;</code>输出。<br>（2）对map函数输出的<code>&lt;key,value&gt;</code>调用分区函数，将数据进行分区。不同分区的数据会被送到不同的Reducer任务中。<br>（3）对于不同分区的数据，它会按照Key进行排序，因此此处的Key必须实现<code>WritableComparable</code>接口，该接口继承了<code>Comparable</code>，因此可以进行比较排序。<br>（4）对于排序后的<code>&lt;key,value&gt;</code>，它会按照Key进行分组。如果Key相同，那么相同Key的<code>&lt;key,value&gt;</code>就被分到一个组中，这样使得最后每个分组都会调用一次reduce函数。<br>（5）排序、分组后的数据就会被送到Reducer节点中。</p>
<h3 id="MapReduce二次排序的代码实现"><a href="#MapReduce二次排序的代码实现" class="headerlink" title="MapReduce二次排序的代码实现"></a>MapReduce二次排序的代码实现</h3><p>新建一个secondsort包，并在里面新建一个<code>IntPair</code>类，该类就是定义每次（行读取）的两个整数。其中的代码如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">public class IntPair implements WritableComparable&lt;IntPair&gt; &#123;</span><br><span class="line">    private int first = 0;</span><br><span class="line">    private int second = 0;</span><br><span class="line"></span><br><span class="line">    public void set(int left,int right)&#123;</span><br><span class="line">        this.first = left;</span><br><span class="line">        this.second = right;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public int getFirst()&#123;</span><br><span class="line">        return first;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public int getSecond()&#123;</span><br><span class="line">        return second;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public int hashCode() &#123;</span><br><span class="line">        return first+&quot;&quot;.hashCode()+second+&quot;&quot;.hashCode();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public boolean equals(Object right) &#123;</span><br><span class="line">        if(right instanceof IntPair)&#123;</span><br><span class="line">            IntPair r = (IntPair)right;</span><br><span class="line">            return r.first == first &amp;&amp; r.second == second;</span><br><span class="line">        &#125;else&#123;</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void readFields(DataInput dataInput) throws IOException &#123;</span><br><span class="line">        first = dataInput.readInt();</span><br><span class="line">        second = dataInput.readInt();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void write(DataOutput dataOutput) throws IOException &#123;</span><br><span class="line">        dataOutput.writeInt(first);</span><br><span class="line">        dataOutput.writeInt(second);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 自定义Key排序时的方法</span><br><span class="line">     * */</span><br><span class="line">    @Override</span><br><span class="line">    public int compareTo(IntPair o) &#123;</span><br><span class="line">        if(first !=o.first)&#123;</span><br><span class="line">            return first-o.first;</span><br><span class="line">        &#125;else if(second != o.second)&#123;</span><br><span class="line">            return second - o.second;</span><br><span class="line">        &#125;else&#123;</span><br><span class="line">            return 0;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接着新建一个<code>SecondarySortApp</code>类，该类为项目的启动类，里面的代码如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">public class SecondarySortApp &#123;</span><br><span class="line">    public static class MyMapper extends Mapper&lt;LongWritable, Text,IntPair, IntWritable&gt;&#123;</span><br><span class="line">        private final IntPair key = new IntPair();</span><br><span class="line">        private final IntWritable value = new IntWritable();</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void map(LongWritable inKey, Text inValue, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            StringTokenizer itr = new StringTokenizer(inValue.toString());</span><br><span class="line">            int left = 0;</span><br><span class="line">            int right = 0;</span><br><span class="line">            if(itr.hasMoreTokens())&#123;</span><br><span class="line">                left = Integer.parseInt(itr.nextToken());</span><br><span class="line">                if(itr.hasMoreTokens())&#123;</span><br><span class="line">                    right = Integer.parseInt(itr.nextToken());</span><br><span class="line">                &#125;</span><br><span class="line">                key.set(left,right);</span><br><span class="line">                value.set(right);</span><br><span class="line">                context.write(key,value);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        /**</span><br><span class="line">         * 在分组的时候，只比较原来的key，而不是组合key</span><br><span class="line">         * */</span><br><span class="line">        public static class GroupComparator implements RawComparator&lt;IntPair&gt;&#123;</span><br><span class="line">            @Override</span><br><span class="line">            public int compare(byte[] b1, int s1, int i1, byte[] b2, int s2, int i2) &#123;</span><br><span class="line">                return WritableComparator.compareBytes(b1,s1,Integer.SIZE/8,b2,s2,Integer.SIZE/8);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public int compare(IntPair o1, IntPair o2) &#123;</span><br><span class="line">                return o1.getFirst() - o2.getFirst();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static class MyReducer extends Reducer&lt;IntPair,IntWritable,Text,IntWritable&gt;&#123;</span><br><span class="line">        private static final Text SEPARATOR = new Text(&quot;----------&quot;);</span><br><span class="line">        private final Text first = new Text();</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void reduce(IntPair key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            context.write(SEPARATOR,null);</span><br><span class="line">            first.set(Integer.toString(key.getFirst()));</span><br><span class="line">            for(IntWritable value:values)&#123;</span><br><span class="line">                context.write(first,value);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws URISyntaxException, IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">        String INPUT_PATH = &quot;hdfs://master:9000/inputsecondsort&quot;;</span><br><span class="line">        String OUTPUT_PATH = &quot;hdfs://master:9000/outputsecondsort&quot;;</span><br><span class="line"></span><br><span class="line">        Configuration configuration= new Configuration();</span><br><span class="line">        final FileSystem fileSystem = FileSystem.get(new URI(INPUT_PATH), configuration);</span><br><span class="line">        if(fileSystem.exists(new Path(OUTPUT_PATH)))&#123;</span><br><span class="line">            fileSystem.delete(new Path(OUTPUT_PATH),true);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Job job = Job.getInstance(configuration,&quot;SecondarySortApp&quot;);</span><br><span class="line"></span><br><span class="line">        //运行Jar类</span><br><span class="line">        job.setJarByClass(SecondarySortApp.class);</span><br><span class="line"></span><br><span class="line">        //设置自定义Mapper类和map函数输出数据的Key和Value的类型</span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line">        job.setMapOutputKeyClass(IntPair.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        //分组函数</span><br><span class="line">        job.setGroupingComparatorClass(MyMapper.GroupComparator.class);</span><br><span class="line"></span><br><span class="line">        //Shuffle把数据从Map端拷贝到Reduce端</span><br><span class="line">        //指定Reducer类和输出Key、Value的类型</span><br><span class="line">        job.setReducerClass(MyReducer.class);</span><br><span class="line">        //设置输出结果的key/value的类型，也就是最终存储在HDFS上结果文件的key/value的类型</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        //设置输入/输出路径</span><br><span class="line">        FileInputFormat.addInputPath(job,new Path(INPUT_PATH));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, new Path(OUTPUT_PATH));</span><br><span class="line"></span><br><span class="line">        //设置输入/输出格式</span><br><span class="line">        job.setInputFormatClass(TextInputFormat.class);</span><br><span class="line">        job.setOutputFormatClass(TextOutputFormat.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        //提交job</span><br><span class="line">        //如果job运行成功，那么程序就会正常退出</span><br><span class="line">        System.exit(job.waitForCompletion(true)?0:1);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="运行作业-2"><a href="#运行作业-2" class="headerlink" title="运行作业"></a>运行作业</h3><p>接下来将提交该作业至集群中运行，操作过程如下所示：<br>（1）在本地Windows机器上使用<code>mvn clean package -DskipTests</code>命令或者直接在IDEA中使用maven插件进行清理打包，之后就可以生成<code>envy-mapreduce-1.0-SNAPSHOT.jar</code>包，为了和之前的代码进行区分，这里将其重命名为<code>envy-mapreduce-secondarysort-1.0-SNAPSHOT.jar</code>；<br>（2）将（1）中的jar包上传至虚拟机<code>/home/hadoop/lib</code>目录下；<br>（3）在虚拟机<code>/home/hadoop</code>目录中新建一个secondarysort.txt的测试文件，其中的内容如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">50  60</span><br><span class="line">30  20</span><br><span class="line">40  20</span><br><span class="line">30  40</span><br><span class="line"></span><br><span class="line">50  50</span><br><span class="line">40  10</span><br><span class="line">50  20</span><br><span class="line">40  30</span><br><span class="line"></span><br><span class="line">50  10</span><br><span class="line">30  30</span><br><span class="line">40  5</span><br><span class="line">30  10</span><br></pre></td></tr></table></figure>
<p>之后在HDFS根目录下新建<code>inputsecondsort</code>目录（这个目录就必须与你设置的<code>INPUT_PATH</code>保持一致，前面的<code>hdfs://master:9000</code>表示主机），之后将这两个文件上传至该目录：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -mkdir /inputsecondsort</span><br><span class="line">[root@master sbin]# hadoop fs -put /home/hadoop/secondarysort.txt /inputsecondsort</span><br></pre></td></tr></table></figure>
<p>之后确认文件上传HDFS中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -ls -R /inputsecondsort</span><br><span class="line">-rw-r--r--   1 root supergroup         73 2020-06-16 15:57 /inputsecondsort/secondarysort.txt</span><br></pre></td></tr></table></figure>
<p>（4）提交MapReduce作业到集群中运行：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop jar /home/hadoop/lib/envy-mapreduce-secondarysort-1.0-SNAPSHOT.jar com.envy.envymapreduce.secondsort.SecondarySortApp</span><br></pre></td></tr></table></figure>
<p>执行流程如下所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/8964398-0658b1f8bc3863e1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
<p>（5）查看作业输出结果，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master hadoop]# hadoop fs -ls /outputsecondsort</span><br><span class="line">Found 2 items</span><br><span class="line">-rw-r--r--   1 root supergroup          0 2020-06-16 16:03 /outputsecondsort/_SUCCESS</span><br><span class="line">-rw-r--r--   1 root supergroup        104 2020-06-16 16:03 /outputsecondsort/part-r-00000</span><br></pre></td></tr></table></figure>
<p>之后查看一下各个文件的内容，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@master hadoop]# hadoop fs -text /outputsecondsort/*</span><br><span class="line">----------</span><br><span class="line">30	10</span><br><span class="line">30	20</span><br><span class="line">30	30</span><br><span class="line">30	40</span><br><span class="line">----------</span><br><span class="line">40	5</span><br><span class="line">40	10</span><br><span class="line">40	20</span><br><span class="line">40	30</span><br><span class="line">----------</span><br><span class="line">50	10</span><br><span class="line">50	20</span><br><span class="line">50	50</span><br><span class="line">50	60</span><br></pre></td></tr></table></figure>
<h1 id="使用MapReduce合并小文件"><a href="#使用MapReduce合并小文件" class="headerlink" title="使用MapReduce合并小文件"></a>使用MapReduce合并小文件</h1><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>前面说过Hadoop处理单个大文件比处理多个小文件更有效率，此外单个文件也非常占用HDFS的存储空间，因此将小文件合并起来进行处理是较为科学的方式。</p>
<h3 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h3><p>要求通过使用MapReduce API来对小文件进行合并，并输出为SequenceFile。</p>
<h3 id="合并小文件的代码实现"><a href="#合并小文件的代码实现" class="headerlink" title="合并小文件的代码实现"></a>合并小文件的代码实现</h3><p>新建一个merge包，并在里面新建一个<code>WholeFileRecordReader</code>类，这是开发者自定义的<code>RecordReader</code>类，注意它需要继承RecordReader，并重写其中的方法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">public class WholeFileRecordReader extends RecordReader&lt;NullWritable, BytesWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    private FileSplit fileSplit;</span><br><span class="line">    private Configuration configuration;</span><br><span class="line">    private BytesWritable value = new BytesWritable();</span><br><span class="line">    private boolean processed = false;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void initialize(InputSplit inputSplit, TaskAttemptContext taskAttemptContext) throws IOException, InterruptedException &#123;</span><br><span class="line">        this.fileSplit = (FileSplit) inputSplit;</span><br><span class="line">        this.configuration = taskAttemptContext.getConfiguration();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public boolean nextKeyValue() throws IOException, InterruptedException &#123;</span><br><span class="line">        if(!processed)&#123;</span><br><span class="line">            byte[] contents = new byte[(int)fileSplit.getLength()];</span><br><span class="line">            Path path = fileSplit.getPath();</span><br><span class="line">            FileSystem fileSystem = path.getFileSystem(configuration);</span><br><span class="line">            FSDataInputStream inputStream = null;</span><br><span class="line">            try&#123;</span><br><span class="line">                inputStream = fileSystem.open(path);</span><br><span class="line">                IOUtils.readFully(inputStream,contents,0,contents.length);</span><br><span class="line">                value.set(contents,0,contents.length);</span><br><span class="line">            &#125;finally &#123;</span><br><span class="line">                IOUtils.closeStream(inputStream);</span><br><span class="line">            &#125;</span><br><span class="line">            processed = true;</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public NullWritable getCurrentKey() throws IOException, InterruptedException &#123;</span><br><span class="line">        return NullWritable.get();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public BytesWritable getCurrentValue() throws IOException, InterruptedException &#123;</span><br><span class="line">        return value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public float getProgress() throws IOException, InterruptedException &#123;</span><br><span class="line">        return processed ? 1.0f: 0.0f;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void close() throws IOException &#123;</span><br><span class="line">        //do nothing</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接着新建一个<code>WholeFileInputFormat</code>类，该类用于将整个文件作为一条记录处理的<code>InputFormat</code>类，其中的代码如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public class WholeFileInputFormat extends FileInputFormat&lt;NullWritable, BytesWritable&gt; &#123;</span><br><span class="line">    //设置每个小文件不可分片，保证一个小文件生成一个key-value</span><br><span class="line">    @Override</span><br><span class="line">    protected boolean isSplitable(JobContext context, Path filename) &#123;</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public RecordReader&lt;NullWritable, BytesWritable&gt; createRecordReader(InputSplit inputSplit, TaskAttemptContext taskAttemptContext) throws IOException, InterruptedException &#123;</span><br><span class="line">        WholeFileRecordReader wholeFileRecordReader = new WholeFileRecordReader();</span><br><span class="line">        wholeFileRecordReader.initialize(inputSplit,taskAttemptContext);</span><br><span class="line">        return wholeFileRecordReader;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后新建一个启动类<code>WholeMergeApp</code>，里面的代码如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">public class WholeMergeApp &#123;</span><br><span class="line">    /**</span><br><span class="line">     * 将小文件打包成SequenceFile</span><br><span class="line">     */</span><br><span class="line">    static class SequenceFileMapper extends Mapper&lt;NullWritable, BytesWritable, Text,BytesWritable&gt;&#123;</span><br><span class="line">        private Text filenameKey;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void setup(Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            InputSplit split = context.getInputSplit();</span><br><span class="line">            Path path =( (FileSplit)split).getPath();</span><br><span class="line">            filenameKey = new Text(path.toString());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected void map(NullWritable key, BytesWritable value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            context.write(filenameKey,value);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws URISyntaxException, IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">        String INPUT_PATH = &quot;hdfs://master:9000/inputmerge&quot;;</span><br><span class="line">        String OUTPUT_PATH = &quot;hdfs://master:9000/outputmerge&quot;;</span><br><span class="line"></span><br><span class="line">        Configuration configuration= new Configuration();</span><br><span class="line">        final FileSystem fileSystem = FileSystem.get(new URI(INPUT_PATH), configuration);</span><br><span class="line">        if(fileSystem.exists(new Path(OUTPUT_PATH)))&#123;</span><br><span class="line">            fileSystem.delete(new Path(OUTPUT_PATH),true);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Job job = Job.getInstance(configuration,&quot;WholeMergeApp&quot;);</span><br><span class="line"></span><br><span class="line">        //运行Jar类</span><br><span class="line">        job.setJarByClass(WholeMergeApp.class);</span><br><span class="line"></span><br><span class="line">        //设置输入/输出格式</span><br><span class="line">        job.setInputFormatClass(WholeFileInputFormat.class);</span><br><span class="line">        job.setOutputFormatClass(SequenceFileOutputFormat.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        //设置输出结果的key/value的类型，也就是最终存储在HDFS上结果文件的key/value的类型</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(BytesWritable.class);</span><br><span class="line">        job.setMapperClass(SequenceFileMapper.class);</span><br><span class="line"></span><br><span class="line">        //设置输入/输出目录</span><br><span class="line">        FileInputFormat.addInputPath(job,new Path(INPUT_PATH));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, new Path(OUTPUT_PATH));</span><br><span class="line"></span><br><span class="line">        //提交job</span><br><span class="line">        //如果job运行成功，那么程序就会正常退出</span><br><span class="line">        System.exit(job.waitForCompletion(true)?0:1);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="运行作业-3"><a href="#运行作业-3" class="headerlink" title="运行作业"></a>运行作业</h3><p>接下来将提交该作业至集群中运行，操作过程如下所示：<br>（1）在本地Windows机器上使用<code>mvn clean package -DskipTests</code>命令或者直接在IDEA中使用maven插件进行清理打包，之后就可以生成<code>envy-mapreduce-1.0-SNAPSHOT.jar</code>包，为了和之前的代码进行区分，这里将其重命名为<code>envy-mapreduce-merge-1.0-SNAPSHOT.jar</code>；<br>（2）将（1）中的jar包上传至虚拟机<code>/home/hadoop/lib</code>目录下；<br>（3）在虚拟机<code>/home/hadoop</code>目录中新建一个merge.txt的测试文件，其中的内容如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">50  60</span><br><span class="line">30  20</span><br><span class="line">40  20</span><br><span class="line">30  40</span><br></pre></td></tr></table></figure>
<p>之后在HDFS根目录下新建<code>inputmerge</code>目录（这个目录就必须与你设置的<code>INPUT_PATH</code>保持一致，前面的<code>hdfs://master:9000</code>表示主机），之后将这两个文件上传至该目录：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -mkdir /inputmerge</span><br><span class="line">[root@master sbin]# hadoop fs -put /home/hadoop/merge.txt /inputmerge</span><br></pre></td></tr></table></figure>
<p>之后确认文件上传HDFS中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -ls -R /inputmerge</span><br><span class="line">-rw-r--r--   1 root supergroup         28 2020-06-16 22:19 /inputmerge/merge.txt</span><br></pre></td></tr></table></figure>
<p>（4）提交MapReduce作业到集群中运行：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop jar /home/hadoop/lib/envy-mapreduce-merge-1.0-SNAPSHOT.jar com.envy.envymapreduce.merge.WholeMergeApp</span><br></pre></td></tr></table></figure>
<p>执行流程如下所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/8964398-0fd8ddbd20e4b278.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
<p>（5）查看作业输出结果，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master hadoop]# hadoop fs -ls /outputmerge</span><br><span class="line">Found 2 items</span><br><span class="line">-rw-r--r--   1 root supergroup          0 2020-06-16 22:21 /outputmerge/_SUCCESS</span><br><span class="line">-rw-r--r--   1 root supergroup        167 2020-06-16 22:21 /outputmerge/part-r-00000</span><br></pre></td></tr></table></figure>
<p>之后查看一下各个文件的内容，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master hadoop]# hadoop fs -text /outputmerge/*</span><br><span class="line">hdfs://master:9000/inputmerge/merge.txt	35 30 20 20 36 30 0a 33 30 20 20 32 30 0a 34 30 20 20 32 30 0a 33 30 20 20 34 30 0a</span><br></pre></td></tr></table></figure>
<p>这样本篇关于MapReduce的高级应用相关内容就到此为止，后续学习其他内容。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://envyzhan.asia">余思</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://envyzhan.asia/2020/10/26/hadoop-11-advanced-application-of-mapreduce/">http://envyzhan.asia/2020/10/26/hadoop-11-advanced-application-of-mapreduce/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://envyzhan.asia" target="_blank">余思博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/hadoop/">hadoop</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/10/27/hadoop-12-yarn-basic/"><img class="prev-cover" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">YARN入门</div></div></a></div><div class="next-post pull-right"><a href="/2020/10/23/hadoop-10-other-content-partitioner-and-recordreader/"><img class="next-cover" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">MapReduce其他内容</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2020/10/09/hadoop-1-introudction/" title="大数据概述"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-09</div><div class="title">大数据概述</div></div></a></div><div><a href="/2020/10/27/hadoop-12-yarn-basic/" title="YARN入门"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-27</div><div class="title">YARN入门</div></div></a></div><div><a href="/2020/10/11/hadoop-2-first-to-learn-hadoop/" title="Hadoop初识"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-11</div><div class="title">Hadoop初识</div></div></a></div><div><a href="/2020/10/15/hadoop-4-hdfs-basic/" title="HDFS入门"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-15</div><div class="title">HDFS入门</div></div></a></div><div><a href="/2020/10/17/hadoop-6-deeply-study-the-operation-principal-of-hdfs/" title="深入学习HDFS的运行原理"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-17</div><div class="title">深入学习HDFS的运行原理</div></div></a></div><div><a href="/2020/10/22/hadoop-9-how-to-develop-mapreduce-application/" title="如何开发MapReduce应用"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-22</div><div class="title">如何开发MapReduce应用</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">余思</div><div class="author-info__description">记录成长路上的点滴</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">249</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><div class="card-info-social-icons is-center"><a class="social-icon" href="mailto:envyzhan@aliyun.com" target="_blank" title=""><i class="fa fa-envelope"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title=""><i class="fa fa-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎访问余思博客，一个技术博主的成长试验田！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2"><span class="toc-number">1.</span> <span class="toc-text">写在前面</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MapReduce%E5%AE%9E%E7%8E%B0join%E6%93%8D%E4%BD%9C"><span class="toc-number">2.</span> <span class="toc-text">MapReduce实现join操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#join%E6%93%8D%E4%BD%9C%E6%A6%82%E8%BF%B0"><span class="toc-number">2.0.1.</span> <span class="toc-text">join操作概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90"><span class="toc-number">2.0.2.</span> <span class="toc-text">需求分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Map%E7%AB%AFjoin%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="toc-number">2.0.3.</span> <span class="toc-text">Map端join的实现原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Map%E7%AB%AFjoin%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.0.4.</span> <span class="toc-text">Map端join的代码实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E4%BD%9C%E4%B8%9A"><span class="toc-number">2.0.5.</span> <span class="toc-text">运行作业</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MapReduce%E5%AE%9E%E7%8E%B0%E6%8E%92%E5%BA%8F%E6%93%8D%E4%BD%9C"><span class="toc-number">3.</span> <span class="toc-text">MapReduce实现排序操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90-1"><span class="toc-number">3.0.1.</span> <span class="toc-text">需求分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce%E6%8E%92%E5%BA%8F%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="toc-number">3.0.2.</span> <span class="toc-text">MapReduce排序的实现原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce%E6%8E%92%E5%BA%8F%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.0.3.</span> <span class="toc-text">MapReduce排序的代码实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E4%BD%9C%E4%B8%9A-1"><span class="toc-number">3.0.4.</span> <span class="toc-text">运行作业</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MapReduce%E5%AE%9E%E7%8E%B0%E4%BA%8C%E6%AC%A1%E6%8E%92%E5%BA%8F%E6%93%8D%E4%BD%9C"><span class="toc-number">4.</span> <span class="toc-text">MapReduce实现二次排序操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E6%AC%A1%E6%8E%92%E5%BA%8F%E6%A6%82%E8%BF%B0"><span class="toc-number">4.0.1.</span> <span class="toc-text">二次排序概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90-2"><span class="toc-number">4.0.2.</span> <span class="toc-text">需求分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce%E4%BA%8C%E6%AC%A1%E6%8E%92%E5%BA%8F%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="toc-number">4.0.3.</span> <span class="toc-text">MapReduce二次排序的实现原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce%E4%BA%8C%E6%AC%A1%E6%8E%92%E5%BA%8F%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">4.0.4.</span> <span class="toc-text">MapReduce二次排序的代码实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E4%BD%9C%E4%B8%9A-2"><span class="toc-number">4.0.5.</span> <span class="toc-text">运行作业</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8MapReduce%E5%90%88%E5%B9%B6%E5%B0%8F%E6%96%87%E4%BB%B6"><span class="toc-number">5.</span> <span class="toc-text">使用MapReduce合并小文件</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-number">5.0.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9C%80%E6%B1%82"><span class="toc-number">5.0.2.</span> <span class="toc-text">需求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%88%E5%B9%B6%E5%B0%8F%E6%96%87%E4%BB%B6%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">5.0.3.</span> <span class="toc-text">合并小文件的代码实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E4%BD%9C%E4%B8%9A-3"><span class="toc-number">5.0.4.</span> <span class="toc-text">运行作业</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/03/01/2023-100-practice-of-function-switch-in-business/" title="功能开关在业务中的实践"><img src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="功能开关在业务中的实践"/></a><div class="content"><a class="title" href="/2023/03/01/2023-100-practice-of-function-switch-in-business/" title="功能开关在业务中的实践">功能开关在业务中的实践</a><time datetime="2023-03-01T09:55:30.000Z" title="发表于 2023-03-01 17:55:30">2023-03-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/26/2023-12-use-jenkins-gitlab-to-package-and-deploy-the-springboot-application/" title="使用Jenkins+Gitlab一键打包部署SpringBoot应用"><img src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="使用Jenkins+Gitlab一键打包部署SpringBoot应用"/></a><div class="content"><a class="title" href="/2023/02/26/2023-12-use-jenkins-gitlab-to-package-and-deploy-the-springboot-application/" title="使用Jenkins+Gitlab一键打包部署SpringBoot应用">使用Jenkins+Gitlab一键打包部署SpringBoot应用</a><time datetime="2023-02-26T14:55:30.000Z" title="发表于 2023-02-26 22:55:30">2023-02-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/24/2023-11-use-docker-compose-to-deploy-springboot-application/" title="使用Docker Compose部署SpringBoot应用"><img src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="使用Docker Compose部署SpringBoot应用"/></a><div class="content"><a class="title" href="/2023/02/24/2023-11-use-docker-compose-to-deploy-springboot-application/" title="使用Docker Compose部署SpringBoot应用">使用Docker Compose部署SpringBoot应用</a><time datetime="2023-02-24T02:55:30.000Z" title="发表于 2023-02-24 10:55:30">2023-02-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/23/2023-10-use-dockerfil-to-build-docker-image-for-springboot-application/" title="使用Dockerfile为SpringBoot应用构建Docker镜像"><img src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="使用Dockerfile为SpringBoot应用构建Docker镜像"/></a><div class="content"><a class="title" href="/2023/02/23/2023-10-use-dockerfil-to-build-docker-image-for-springboot-application/" title="使用Dockerfile为SpringBoot应用构建Docker镜像">使用Dockerfile为SpringBoot应用构建Docker镜像</a><time datetime="2023-02-23T10:15:33.000Z" title="发表于 2023-02-23 18:15:33">2023-02-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/20/2023-9-use-maven-plug-in-to-build-docker-image-for-springboot-application/" title="使用Maven插件为SpringBoot应用构建Docker镜像"><img src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="使用Maven插件为SpringBoot应用构建Docker镜像"/></a><div class="content"><a class="title" href="/2023/02/20/2023-9-use-maven-plug-in-to-build-docker-image-for-springboot-application/" title="使用Maven插件为SpringBoot应用构建Docker镜像">使用Maven插件为SpringBoot应用构建Docker镜像</a><time datetime="2023-02-20T03:51:30.000Z" title="发表于 2023-02-20 11:51:30">2023-02-20</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2017 - 2023  余思博客,记录成长</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: '9996b44b488f2fc52124',
      clientSecret: '6bec0f8e9c032eeae6211a5d4cffa3c97e2d4a64',
      repo: 'blogcomment',
      owner: 'Envythink',
      admin: ['Envythink'],
      id: '4e2e2066a7ec2711d13f8cce39d625c5',
      updateCountCallback: commentCount
    },))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div></div></body></html>