<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>MapReduce入门 | 余思博客</title><meta name="keywords" content="hadoop"><meta name="author" content="余思"><meta name="copyright" content="余思"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="写在前面本篇来学习MapReduce，主要包括MapReduce简介、设计目标、特点、不适合场景、编程模型等内容，并在此基础上通过一个词频统计功能来加深对于MapReduce的理解。 MapReduce简介MapReduce是谷歌开源的一个用于大数据量的计算框架，对于大数据量的计算，通常采用并行计算方式来处理。但是如果让开发人员自己来完全实现一个并行计算程序，这是非常困难的，鉴于此种情况，MapR">
<meta property="og:type" content="article">
<meta property="og:title" content="MapReduce入门">
<meta property="og:url" content="http://envyzhan.asia/2020/10/21/hadoop-8-mapreduce-basic/index.html">
<meta property="og:site_name" content="余思博客">
<meta property="og:description" content="写在前面本篇来学习MapReduce，主要包括MapReduce简介、设计目标、特点、不适合场景、编程模型等内容，并在此基础上通过一个词频统计功能来加深对于MapReduce的理解。 MapReduce简介MapReduce是谷歌开源的一个用于大数据量的计算框架，对于大数据量的计算，通常采用并行计算方式来处理。但是如果让开发人员自己来完全实现一个并行计算程序，这是非常困难的，鉴于此种情况，MapR">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png">
<meta property="article:published_time" content="2020-10-21T13:23:04.000Z">
<meta property="article:modified_time" content="2021-03-01T07:03:01.210Z">
<meta property="article:author" content="余思">
<meta property="article:tag" content="hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="http://envyzhan.asia/2020/10/21/hadoop-8-mapreduce-basic/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'MapReduce入门',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-03-01 15:03:01'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="余思博客" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">254</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">19</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 前端</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/html/"><i class="fa-fw fa fa-cog"></i><span> HTML/CSS</span></a></li><li><a class="site-page child" href="/categories/javascript/"><i class="fa-fw fa fa-cogs"></i><span> JavaScript</span></a></li><li><a class="site-page child" href="/categories/vuejs/"><i class="fa-fw fa fa-certificate"></i><span> Vue.js</span></a></li><li><a class="site-page child" href="/categories/flutter/"><i class="fa-fw fa fa-bullseye"></i><span> Flutter</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> Java</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/java/"><i class="fa-fw fa fa-book"></i><span> Java</span></a></li><li><a class="site-page child" href="/categories/ssm/"><i class="fa-fw fa fa-cube"></i><span> SSM</span></a></li><li><a class="site-page child" href="/categories/springboot/"><i class="fa-fw fa fa-cubes"></i><span> SpringBoot</span></a></li><li><a class="site-page child" href="/categories/springcloud/"><i class="fa-fw fa fa-cloud"></i><span> SpringCloud</span></a></li><li><a class="site-page child" href="/categories/springsecurity/"><i class="fa-fw fa fa-bullseye"></i><span> SpringSecurity</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 运维</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/pythonbase/"><i class="fa-fw fa fa-book"></i><span> Python</span></a></li><li><a class="site-page child" href="/categories/go/"><i class="fa-fw fa fa-google-plus"></i><span> Golang</span></a></li><li><a class="site-page child" href="/categories/devops/"><i class="fa-fw fa fa-road"></i><span> DevOps</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 中间件</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/mysql/"><i class="fa-fw fa fa-database"></i><span> MySQL</span></a></li><li><a class="site-page child" href="/categories/redis/"><i class="fa-fw fa fa-random"></i><span> Redis</span></a></li><li><a class="site-page child" href="/categories/other/"><i class="fa-fw fa fa-location-arrow"></i><span> 其他</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-bell"></i><span> 其他</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/datastructs/"><i class="fa-fw fa fa-plug"></i><span> 算法结构</span></a></li><li><a class="site-page child" href="/categories/tools/"><i class="fa-fw fa fa-hourglass"></i><span> 实用工具</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-address-book"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/onenote/"><i class="fa-fw fa fa-laptop"></i><span> 个人随笔</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-comment"></i><span> 留言</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">余思博客</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 前端</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/html/"><i class="fa-fw fa fa-cog"></i><span> HTML/CSS</span></a></li><li><a class="site-page child" href="/categories/javascript/"><i class="fa-fw fa fa-cogs"></i><span> JavaScript</span></a></li><li><a class="site-page child" href="/categories/vuejs/"><i class="fa-fw fa fa-certificate"></i><span> Vue.js</span></a></li><li><a class="site-page child" href="/categories/flutter/"><i class="fa-fw fa fa-bullseye"></i><span> Flutter</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> Java</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/java/"><i class="fa-fw fa fa-book"></i><span> Java</span></a></li><li><a class="site-page child" href="/categories/ssm/"><i class="fa-fw fa fa-cube"></i><span> SSM</span></a></li><li><a class="site-page child" href="/categories/springboot/"><i class="fa-fw fa fa-cubes"></i><span> SpringBoot</span></a></li><li><a class="site-page child" href="/categories/springcloud/"><i class="fa-fw fa fa-cloud"></i><span> SpringCloud</span></a></li><li><a class="site-page child" href="/categories/springsecurity/"><i class="fa-fw fa fa-bullseye"></i><span> SpringSecurity</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 运维</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/pythonbase/"><i class="fa-fw fa fa-book"></i><span> Python</span></a></li><li><a class="site-page child" href="/categories/go/"><i class="fa-fw fa fa-google-plus"></i><span> Golang</span></a></li><li><a class="site-page child" href="/categories/devops/"><i class="fa-fw fa fa-road"></i><span> DevOps</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 中间件</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/mysql/"><i class="fa-fw fa fa-database"></i><span> MySQL</span></a></li><li><a class="site-page child" href="/categories/redis/"><i class="fa-fw fa fa-random"></i><span> Redis</span></a></li><li><a class="site-page child" href="/categories/other/"><i class="fa-fw fa fa-location-arrow"></i><span> 其他</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-bell"></i><span> 其他</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/datastructs/"><i class="fa-fw fa fa-plug"></i><span> 算法结构</span></a></li><li><a class="site-page child" href="/categories/tools/"><i class="fa-fw fa fa-hourglass"></i><span> 实用工具</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-address-book"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/onenote/"><i class="fa-fw fa fa-laptop"></i><span> 个人随笔</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-comment"></i><span> 留言</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">MapReduce入门</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-10-21T13:23:04.000Z" title="发表于 2020-10-21 21:23:04">2020-10-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-03-01T07:03:01.210Z" title="更新于 2021-03-01 15:03:01">2021-03-01</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>本篇来学习MapReduce，主要包括MapReduce简介、设计目标、特点、不适合场景、编程模型等内容，并在此基础上通过一个词频统计功能来加深对于MapReduce的理解。</p>
<h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>MapReduce是谷歌开源的一个用于大数据量的计算框架，对于大数据量的计算，通常采用并行计算方式来处理。但是如果让开发人员自己来完全实现一个并行计算程序，这是非常困难的，鉴于此种情况，MapReduce就孕育而生，它是一种简化并行计算的编程模型，允许没有并发计算经验的开发者也能开发出并行计算程序，这无疑大大降低了并行计算的实现门槛。</p>
<h3 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h3><p>从简介中可以知道MapReduce的设计目标就是便于开发人员在不熟悉分布式并发编程的情况下，也能将自己的程序运行在分布式系统上。</p>
<p>MapReduce采用的是“分而治之”的思想，即把对大规模数据集的操作，分发给一个主节点管理下的各个子节点，让它们共同来完成，之后整合各个子节点的中间结果，进而得到最终的计算结果。用一句话来概括MapReduce就是“分散任务，汇总结果”。</p>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><p>（1）容易编程。MapReduce只需简单实现一些接口，就能完成一个个分布式程序，且这些分布式程序可以分布到大量廉价的PC机上运行。这使得开发者写一个分布式程序就像写一个简单的串行程序一样，非常简单，这也是MapReduce编程非常流行的原因。<br>（2）扩展性良好。当开发者的计算资源无法得到满足时，可以通过简单的增加机器来扩展它的计算能力。<br>（3）高容错性。MapReduce的设计初衷是要求程序能够部署在大量廉价的PC机上，这就要求MapReduce具备较高的容错性。我们知道程序在廉价PC机上出现故障的概率很大，这就要求当某台机器出现故障宕机了，可以将它上面的计算任务转移到另外一个节点上运行，而不至于导致整个任务运行失败，而且这个过程不需要人工干预，完全是由Hadoop内部完成的。<br>（4）能够对PB及以上级别的海量数据进行离线处理。也就是说MapReduce比较适合离线处理，而不适合实时处理，对延迟率要求苛刻的时候不建议使用这个。MapReduce很难做到毫秒级返回一个计算结果。</p>
<h3 id="不适合场景"><a href="#不适合场景" class="headerlink" title="不适合场景"></a>不适合场景</h3><p>易于编程的MapReduce尽管具有很多优点，但是也有一些不太擅长的地方，注意这里的说法是太擅长，而不是无法做到，只是在某些场景下实现的效果较差，此时更适合使用其他的框架。这些不适合场景主要有以下几个：<br>（1）实时计算。前面说过MapReduce无法像MySQL那样在毫秒或者秒级内返回计算结果。<br>（2）流式计算。所谓的流式计算是指计算输入的数据是动态的，而MapReduce的输入数据集必须是静态的，不能动态发生变化，这个就是MapReduce自身设计特点所决定的。<br>（3）DAG（有向图）计算。多个应用程序之间存在依赖关系，前一个应用程序的输出，作为后一个应用程序的输入，在这种情况下，MapReduce并不是不能做，只是使用MapReduce之后，每个MapReduce作业的输出结果都会写入到磁盘，势必会造成大量的磁盘IO，进而降低使用性能。</p>
<h1 id="MapReduce编程模型"><a href="#MapReduce编程模型" class="headerlink" title="MapReduce编程模型"></a>MapReduce编程模型</h1><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>其实单从MapReduce这个名字就能知道，MapReduce由Map和Reduce这两个阶段组成。也就是说用户只需编写<code>map()</code>和<code>reduce()</code>这两个函数，就能完成简单的分布式程序的设计。</p>
<p><code>map()</code>函数以Key-Value键值对作为输入，之后产生另外一系列的Key-Value键值对作为中间输出写入本地磁盘。MapReduce框架会自动将这些中间数据按照Key值进行聚集，且Key值相同的数据会被统一交给<code>reduce()</code>函数来处理。请注意这个聚集策略用户可以自定义，系统默认采用的是对Key值进行哈希取模。</p>
<p><code>reduce()</code>函数以Key及对应的Value列表作为输入，经合并Key相同的Value值后，会产生另外一系列Key-Value键值对来作为最终输出，进而写入到HDFS中。</p>
<p>MapReduce将作业（其实就是一个MapReduce程序）的整个运行过程分为Map和Reduce这两个过程，这里以后续介绍的词频统计功能来介绍MapReduce编程模型：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/8964398-0661c35b60e0c6a4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
<p>（1）Map阶段由一定数量的Map Task组成：</p>
<ul>
<li>输入数据格式解析：InputFormat(将输入文件分片)；</li>
<li>输入数据处理：Mapper；</li>
<li>数据分组：Partitioner。</li>
</ul>
<p>（2）Reduce阶段由一定数量的Reduce Task组成：</p>
<ul>
<li>数据远程拷贝（从Map Task的输出拷贝部分数据）；</li>
<li>数据按照Key排序和分组（即Key相同的都放在一起，按照Key进行分组操作，每一组交由Reducer进行处理）；</li>
<li>数据处理：Reducer；</li>
<li>数据输出格式：OutputFormat（输出文件格式、设置分隔符等）。<h3 id="MapReduce编程步骤"><a href="#MapReduce编程步骤" class="headerlink" title="MapReduce编程步骤"></a>MapReduce编程步骤</h3>从上述词频统计功能就能看出MapReduce编程步骤如下所示：<br>（1）Input：输入一系列的(k1,v1)键值对；<br>（2）Map和Reduce：Map：(k1,v1)-&gt;list(k2,v2)，之后Reduce：(k2,list(v2))-&gt;list(k3,v3)。其中k2/v2是中间结果对。<br>（3）Output：一系列(k3,v3)键值对。<h3 id="MapReduce词频统计实例"><a href="#MapReduce词频统计实例" class="headerlink" title="MapReduce词频统计实例"></a>MapReduce词频统计实例</h3>接下来通过一个WordCount程序来详细解释MapReduce模型。一个最简单的MapReduce程序至少包含3个部分：一个Map函数、一个Reduce函数和一个main函数。</li>
</ul>
<p>也就是说在运行一个MapReduce计算任务时，这个任务过程会被划分为Map阶段和Reduce阶段，每个阶段都采用Key-Value键值对作为输入(input)和输出(output)，main函数则将作业控制和文件输入/输出结合起来。</p>
<p>WordCount程序需求：现在有大量的文件，每个文件中又有大量的单词，要求统计每个单词出现的词频。</p>
<p>MapReduce完整的执行流程如下所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/8964398-aebfcf9dbf2571cb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
<p><strong>（1）WordCount实现设计分析</strong>。<br>（a）Map过程：并行读取文本，对读取的单词进行map操作，每个词都以&lt;Key,Value&gt;形式生成。</p>
<p>读取第一行Deer Bear River，分割单词形成Map：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;Deer,1&gt; &lt;Bear,1&gt; &lt;River,1&gt;</span><br></pre></td></tr></table></figure>
<p>读取第二行Car Car River，分割单词形成Map：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;Car,1&gt; &lt;Car,1&gt; &lt;River,1&gt;</span><br></pre></td></tr></table></figure>
<p>读取第三行Deer Car Bear，分割单词形成Map：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;Deer,1&gt; &lt;Car,1&gt; &lt;Bear,1&gt;</span><br></pre></td></tr></table></figure>
<p>（b）Reduce过程：对Map的结果进行排序、合并，最后得到词频。</p>
<p>reduce将形成的Map根据相同的Key组合成Value数组，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;Bear,1,1&gt; &lt;Car,1,1,1&gt; &lt;Deer,1,1&gt; &lt;River,1,1&gt;</span><br></pre></td></tr></table></figure>
<p>之后循环执行<code>Reduce(K,V[])</code>，分别统计出每个单词出现的此处，结果如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;Bear,2&gt; &lt;Car,3&gt; &lt;Deer,2&gt; &lt;River,2&gt;</span><br></pre></td></tr></table></figure>
<p><strong>（2）WordCount代码实现</strong>。创建一个Maven项目，名称为envy-mapReduce，之后在其pom.xml依赖文件中添加如下信息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">&lt;properties&gt;</span><br><span class="line">    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;</span><br><span class="line">    &lt;hadoop.version&gt;2.6.0&lt;/hadoop.version&gt;</span><br><span class="line">&lt;/properties&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependencies&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;hadoop.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;hadoop-hdfs&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;hadoop.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;hadoop-mapreduce-client-core&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;hadoop.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;hadoop-mapreduce-client-jobclient&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;hadoop.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;junit&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;junit&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;4.10&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">&lt;/dependencies&gt;</span><br></pre></td></tr></table></figure>
<p>接着在java包内新建<code>com/envy/envymapreduce/app</code>包，并在app包内新建EnvyWordCountApp类，其中的代码如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line">public class EnvyWordCountApp &#123;</span><br><span class="line">    public static class MyMapper extends Mapper&lt;Object, Text,Text, IntWritable&gt; &#123;</span><br><span class="line">        //new一个int类型用于计数，并赋值为1，因为不管每个单词出现几次，都是直接输出1</span><br><span class="line">        //假设输入数据为nice to nice,one赋值为1，那么使用context.write(word,one)的输出结果就是nice 1,to 1,nice 1</span><br><span class="line">        //如果one赋值为2，那么使用context.write(word,one)的输出结果就是nice 2,to 2,nice 2</span><br><span class="line">        private static final IntWritable one = new IntWritable(1);</span><br><span class="line">        //new一个String类型</span><br><span class="line">        private Text word = new Text();</span><br><span class="line"></span><br><span class="line">        /**</span><br><span class="line">         * 重写map函数，其中的context参数是上下文，用于记录key和value的值</span><br><span class="line">         * */</span><br><span class="line">        @Override</span><br><span class="line">        public void map(Object key, Text value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            //字符串分解类，将一行单词分解为多个单词</span><br><span class="line">            StringTokenizer itr =  new StringTokenizer(value.toString());</span><br><span class="line">            //循环条件表示返回是否还有分隔符</span><br><span class="line">            while (itr.hasMoreTokens())&#123;</span><br><span class="line">                //使用itr.nextToken()来获取单词</span><br><span class="line">                //word.set()方法将Java数据类型转换为Hadoop数据类型，这样后续才能输出</span><br><span class="line">                word.set(itr.nextToken());</span><br><span class="line">                //按照输出格式来输出结果，如nice 1</span><br><span class="line">                context.write(word,one);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static class MyReducer extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt;&#123;</span><br><span class="line">        private IntWritable result = new IntWritable();</span><br><span class="line"></span><br><span class="line">        /**</span><br><span class="line">         * 重写reduce函数，其中的context参数是上下文，用于记录key和result的值</span><br><span class="line">         * */</span><br><span class="line">        @Override</span><br><span class="line">        public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            //定义一个Java数据类型的sum，用于记录相同单词的数量</span><br><span class="line">            int sum = 0;</span><br><span class="line">            //遍历得到的结果</span><br><span class="line">            for(IntWritable value:values)&#123;</span><br><span class="line">                //由于value是IntWritable类型，因此需要调用get()方法来返回Java类型的值</span><br><span class="line">                //请注意IntWritable.get()和IntWritable.set()都可以进行数据类型转换，不同的是set是将Java数据类型转换为Hadoop数据类型</span><br><span class="line">                //而get则是将Hadoop数据类型转换为Java数据类型</span><br><span class="line"></span><br><span class="line">                sum+=value.get();</span><br><span class="line">            &#125;</span><br><span class="line">            //将Java数据类型转换为Hadoop数据类型</span><br><span class="line">            result.set(sum);</span><br><span class="line">            //将结果输出到HDFS中</span><br><span class="line">            context.write(key,result);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        //配置输入路径</span><br><span class="line">        String INPUT_PATH = &quot;hdfs://master:9000/inputwc&quot;;</span><br><span class="line">        //配置输出路径</span><br><span class="line">        String OUTPUT_PATH = &quot;hdfs://master:9000/outputwc&quot;;</span><br><span class="line"></span><br><span class="line">        //读取Hadoop的配置文件</span><br><span class="line">        Configuration configuration= new Configuration();</span><br><span class="line">        final FileSystem fileSystem = FileSystem.get(new URI(INPUT_PATH), configuration);</span><br><span class="line">        if(fileSystem.exists(new Path(OUTPUT_PATH)))&#123;</span><br><span class="line">            fileSystem.delete(new Path(OUTPUT_PATH),true);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        //创建一个任务，第一个参数是配置对象，第二个参数是任务名称，这里是EnvyWordCountApp</span><br><span class="line">        Job job = Job.getInstance(configuration,&quot;EnvyWordCountApp&quot;);</span><br><span class="line"></span><br><span class="line">        //运行Jar类</span><br><span class="line">        job.setJarByClass(EnvyWordCountApp.class);</span><br><span class="line"></span><br><span class="line">        //设置map</span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        //设置reduce</span><br><span class="line">        job.setReducerClass(MyReducer.class);</span><br><span class="line">        //设置输出结果的key/value的类型，也就是最终存储在HDFS上结果文件的key/value的类型</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        //设置输入格式</span><br><span class="line">        //设置输入文件路径</span><br><span class="line">        job.setInputFormatClass(TextInputFormat.class);</span><br><span class="line">        Path inputPath = new Path(INPUT_PATH);</span><br><span class="line">        FileInputFormat.addInputPath(job,inputPath);</span><br><span class="line"></span><br><span class="line">        //设置输出格式</span><br><span class="line">        job.setOutputFormatClass(TextOutputFormat.class);</span><br><span class="line">        Path outputPath = new Path(OUTPUT_PATH);</span><br><span class="line">        //设置输出文件路径</span><br><span class="line">        FileOutputFormat.setOutputPath(job, outputPath);</span><br><span class="line"></span><br><span class="line">        //提交job</span><br><span class="line">        //如果job运行成功，那么程序就会正常退出</span><br><span class="line">        System.exit(job.waitForCompletion(true)?0:1);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>请注意目前直接运行代码中的main方法是会抛异常的，正确的启动会在后面进行介绍。</p>
<h3 id="WordCount代码详解"><a href="#WordCount代码详解" class="headerlink" title="WordCount代码详解"></a>WordCount代码详解</h3><p>尽管笔者在代码中对部分语句进行了注释，但是这里还是有必要对 WordCount代码进行详解。</p>
<p>（1）对于map方法来说，其参数如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public void map(Object key, Text value, Context context)</span><br></pre></td></tr></table></figure>
<p>请注意这个方法存在于MyMapper类中，它需要继承Mapper类，并实现map方法。这个map方法有三个参数，前面的<code>Object key</code>和<code>Text value</code>就是输入的key和value，第三个参数<code>Context context</code>记录的则是整个上下文，因此开发者可以通过context将数据写出去。</p>
<p>（2）对于reduce方法来说，其参数如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span><br></pre></td></tr></table></figure>
<p>请注意这个方法存在于MyReducer类中，它需要继承Reducer类，并实现reduce方法。这个reduce方法有三个参数，前面的<code>Text key</code>和<code>Iterable&lt;IntWritable&gt; values</code>也是输入的key/values形式，不过可以看到它的value是迭代器形式的<code>Iterable&lt;IntWritable&gt; values</code>，也就是说reduce的输入是一个key对应一组value，reduce方法也有context参数，且作用和之前map方法中的作用一样。</p>
<p>（3）对于main方法来说，其分析如下所示：<br>（a）创建Configuration类，请注意在运行MapReduce程序前都需要初始化Configuration类，该类主要是读取MapReduce系统配置信息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Configuration configuration= new Configuration();</span><br></pre></td></tr></table></figure>
<p>（b）创建Job类：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ob job = Job.getInstance(configuration,&quot;EnvyWordCountApp&quot;);</span><br><span class="line">job.setJarByClass(EnvyWordCountApp.class);</span><br><span class="line">job.setMapperClass(MyMapper.class);</span><br><span class="line">job.setReducerClass(MyReducer.class);</span><br></pre></td></tr></table></figure>
<p>第一行代码用于构建一个Job对象，它有两个参数，一个是configuration，另一个是job名称。第二行则是用户自定义的MapReduce类。第三行和第四行则是分别设置map函数和reduce函数的实现类。</p>
<p>（c）设置输出的key/value类型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">job.setMapOutputKeyClass(Text.class);</span><br><span class="line">job.setMapOutputValueClass(IntWritable.class);</span><br></pre></td></tr></table></figure>
<p>上面设置的是中间输出key/value的类型，还需要设置最终存储在HDFS中的结果文件中的key/value的类型，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">job.setOutputKeyClass(Text.class);</span><br><span class="line">job.setOutputValueClass(IntWritable.class);</span><br></pre></td></tr></table></figure>
<p>（d）设置Job的输入和输出路径并提交到集群中运行：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">job.setInputFormatClass(TextInputFormat.class);</span><br><span class="line">Path inputPath = new Path(INPUT_PATH);</span><br><span class="line">FileInputFormat.addInputPath(job,inputPath);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">job.setOutputFormatClass(TextOutputFormat.class);</span><br><span class="line">Path outputPath = new Path(OUTPUT_PATH);</span><br><span class="line">FileOutputFormat.setOutputPath(job, outputPath);</span><br><span class="line"></span><br><span class="line">System.exit(job.waitForCompletion(true)?0:1);</span><br></pre></td></tr></table></figure>
<p>可以看到上面一共有三段代码，其中第一段用于构建输入的数据文件，第二段用于构建输出的数据文件，第三段则表示如果job运行成功，则程序就会正常退出。</p>
<p>请注意，虽然我们编写MapReduce程序只需要实现map函数和reduce函数，但是在实际开发中往往需要实现三个方法，第三个方法是为了配置MapReduce如何运行map和reduce函数，说白了就是构建一个MapReduce能执行的job。</p>
<h3 id="WordCount提交到集群运行"><a href="#WordCount提交到集群运行" class="headerlink" title="WordCount提交到集群运行"></a>WordCount提交到集群运行</h3><p>接下来介绍如何将之前的WordCount代码提交到集群中运行，由于这里是第一次接触到MapReduce，因此这里以伪分布式集群的方式来运行WordCount，实际上完全分布式集群的运行和这里的过程是完全一样的。</p>
<p>伪分布式集群方式运行WordCount程序的步骤如下所示：<br>（1）在本地Windows机器上使用<code>mvn clean package -DskipTests</code>命令或者直接在IDEA中使用maven插件进行清理打包，之后就可以生成<code>envy-mapreduce-1.0-SNAPSHOT.jar</code>包；<br>（2）将（1）中的jar包上传至虚拟机<code>/home/hadoop/lib</code>目录下；<br>（3）在虚拟机<code>/home/hadoop</code>目录中新建一个hello.text的测试文件，其中的内容如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Deer Bear River</span><br><span class="line">Car Car River</span><br><span class="line">Deer Car Bear</span><br></pre></td></tr></table></figure>
<p>之后在HDFS根目录下新建<code>inputwc</code>目录，之后将这个hello.txt文件上传至该目录：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -mkdir /inputwc</span><br><span class="line">[root@master sbin]# hadoop fs -put </span><br><span class="line">/home/hadoop/hello.txt /inputwc</span><br></pre></td></tr></table></figure>
<p>之后确认文件上传HDFS中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -ls -R /inputwc</span><br><span class="line">-rw-r--r--   1 root supergroup         44 2020-06-04 21:23 /inputwc/hello.txt</span><br></pre></td></tr></table></figure>
<p>（4）提交MapReduce作业到集群中运行：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop jar /home/hadoop/lib/envy-mapreduce-1.0-SNAPSHOT.jar com.envy.envymapreduce.app.EnvyWordCountApp</span><br></pre></td></tr></table></figure>
<p>执行流程如下所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/8964398-a79aabadda7d62b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/8964398-cbad3ab10b452643.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
<p>（5）查看作业输出结果，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -text /outputwc/part-*</span><br><span class="line">Bear	2</span><br><span class="line">Car	3</span><br><span class="line">Deer	2</span><br><span class="line">River	2</span><br></pre></td></tr></table></figure>
<p>顺便看一下HDFS上<code>/outputwc</code>目录信息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@master sbin]# hadoop fs -ls -R /outputwc</span><br><span class="line">-rw-r--r--   1 root supergroup          0 2020-06-04 21:27 /outputwc/_SUCCESS</span><br><span class="line">-rw-r--r--   1 root supergroup         28 2020-06-04 21:27 /outputwc/part-r-00000</span><br></pre></td></tr></table></figure>
<p>这样WordCount作业就执行成功了，那么本篇关于MapReduce的入门学习就到此为止。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://envyzhan.asia">余思</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://envyzhan.asia/2020/10/21/hadoop-8-mapreduce-basic/">http://envyzhan.asia/2020/10/21/hadoop-8-mapreduce-basic/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://envyzhan.asia" target="_blank">余思博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/hadoop/">hadoop</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/10/22/hadoop-9-how-to-develop-mapreduce-application/"><img class="prev-cover" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">如何开发MapReduce应用</div></div></a></div><div class="next-post pull-right"><a href="/2020/10/19/hadoop-7-hdfs-advanced-knowledge/"><img class="next-cover" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">HDFS高级知识</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2020/10/09/hadoop-1-introudction/" title="大数据概述"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-09</div><div class="title">大数据概述</div></div></a></div><div><a href="/2020/10/27/hadoop-12-yarn-basic/" title="YARN入门"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-27</div><div class="title">YARN入门</div></div></a></div><div><a href="/2020/10/11/hadoop-2-first-to-learn-hadoop/" title="Hadoop初识"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-11</div><div class="title">Hadoop初识</div></div></a></div><div><a href="/2020/10/15/hadoop-4-hdfs-basic/" title="HDFS入门"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-15</div><div class="title">HDFS入门</div></div></a></div><div><a href="/2020/10/17/hadoop-6-deeply-study-the-operation-principal-of-hdfs/" title="深入学习HDFS的运行原理"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-17</div><div class="title">深入学习HDFS的运行原理</div></div></a></div><div><a href="/2020/10/22/hadoop-9-how-to-develop-mapreduce-application/" title="如何开发MapReduce应用"><img class="cover" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-22</div><div class="title">如何开发MapReduce应用</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">余思</div><div class="author-info__description">记录成长路上的点滴</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">254</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">19</div></a></div><div class="card-info-social-icons is-center"><a class="social-icon" href="mailto:envyzhan@aliyun.com" target="_blank" title=""><i class="fa fa-envelope"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title=""><i class="fa fa-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎访问余思博客，一个技术博主的成长试验田！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2"><span class="toc-number">1.</span> <span class="toc-text">写在前面</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MapReduce"><span class="toc-number">2.</span> <span class="toc-text">MapReduce</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">2.0.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BE%E8%AE%A1%E7%9B%AE%E6%A0%87"><span class="toc-number">2.0.2.</span> <span class="toc-text">设计目标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E7%82%B9"><span class="toc-number">2.0.3.</span> <span class="toc-text">特点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8D%E9%80%82%E5%90%88%E5%9C%BA%E6%99%AF"><span class="toc-number">2.0.4.</span> <span class="toc-text">不适合场景</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MapReduce%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.</span> <span class="toc-text">MapReduce编程模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-number">3.0.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce%E7%BC%96%E7%A8%8B%E6%AD%A5%E9%AA%A4"><span class="toc-number">3.0.2.</span> <span class="toc-text">MapReduce编程步骤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1%E5%AE%9E%E4%BE%8B"><span class="toc-number">3.0.3.</span> <span class="toc-text">MapReduce词频统计实例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#WordCount%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3"><span class="toc-number">3.0.4.</span> <span class="toc-text">WordCount代码详解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#WordCount%E6%8F%90%E4%BA%A4%E5%88%B0%E9%9B%86%E7%BE%A4%E8%BF%90%E8%A1%8C"><span class="toc-number">3.0.5.</span> <span class="toc-text">WordCount提交到集群运行</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/03/02/2024-1-six-common-configuration-methods-for-reading-properties/" title="聊一聊六种常用的属性配置读取方式"><img src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="聊一聊六种常用的属性配置读取方式"/></a><div class="content"><a class="title" href="/2024/03/02/2024-1-six-common-configuration-methods-for-reading-properties/" title="聊一聊六种常用的属性配置读取方式">聊一聊六种常用的属性配置读取方式</a><time datetime="2024-03-02T02:55:30.000Z" title="发表于 2024-03-02 10:55:30">2024-03-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/28/2023-104-cleverly-using-paginated-list-caching-to-quickly-respond-to-user-requests/" title="巧用分页列表缓存，快速响应用户请求"><img src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="巧用分页列表缓存，快速响应用户请求"/></a><div class="content"><a class="title" href="/2023/05/28/2023-104-cleverly-using-paginated-list-caching-to-quickly-respond-to-user-requests/" title="巧用分页列表缓存，快速响应用户请求">巧用分页列表缓存，快速响应用户请求</a><time datetime="2023-05-28T08:55:30.000Z" title="发表于 2023-05-28 16:55:30">2023-05-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/10/2023-103-implementation-of-interface-idempotency-verification-based-on-reqParam/" title="基于请求参数校验的接口幂等性实现方案"><img src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于请求参数校验的接口幂等性实现方案"/></a><div class="content"><a class="title" href="/2023/05/10/2023-103-implementation-of-interface-idempotency-verification-based-on-reqParam/" title="基于请求参数校验的接口幂等性实现方案">基于请求参数校验的接口幂等性实现方案</a><time datetime="2023-05-10T02:55:30.000Z" title="发表于 2023-05-10 10:55:30">2023-05-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/20/2023-102-redis-skillfully-uses-various-data-types/" title="Redis各种数据类型巧用"><img src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Redis各种数据类型巧用"/></a><div class="content"><a class="title" href="/2023/04/20/2023-102-redis-skillfully-uses-various-data-types/" title="Redis各种数据类型巧用">Redis各种数据类型巧用</a><time datetime="2023-04-20T02:55:30.000Z" title="发表于 2023-04-20 10:55:30">2023-04-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/06/2023-101-talk-about-the-bloom-filter-in-redis/" title="聊一聊Redis中的布隆过滤器"><img src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="聊一聊Redis中的布隆过滤器"/></a><div class="content"><a class="title" href="/2023/04/06/2023-101-talk-about-the-bloom-filter-in-redis/" title="聊一聊Redis中的布隆过滤器">聊一聊Redis中的布隆过滤器</a><time datetime="2023-04-06T11:55:30.000Z" title="发表于 2023-04-06 19:55:30">2023-04-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2017 - 2024  余思博客,记录成长</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: '9996b44b488f2fc52124',
      clientSecret: '6bec0f8e9c032eeae6211a5d4cffa3c97e2d4a64',
      repo: 'blogcomment',
      owner: 'Envythink',
      admin: ['Envythink'],
      id: '6fdd196ade9e48f62018860e7be1f17c',
      updateCountCallback: commentCount
    },))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div></div></body></html>