<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>余思博客</title>
  
  
  <link href="http://aichating.xyz/atom.xml" rel="self"/>
  
  <link href="http://aichating.xyz/"/>
  <updated>2025-11-02T14:31:22.000Z</updated>
  <id>http://aichating.xyz/</id>
  
  <author>
    <name>余思</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Milvus简介及安装</title>
    <link href="http://aichating.xyz/2025/11/01/2025-19-Introduction%20to%20Milvus%20and%20Its%20Installation/"/>
    <id>http://aichating.xyz/2025/11/01/2025-19-Introduction%20to%20Milvus%20and%20Its%20Installation/</id>
    <published>2025-11-01T06:01:20.000Z</published>
    <updated>2025-11-02T14:31:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Milvus简介"><a href="#Milvus简介" class="headerlink" title="Milvus简介"></a>Milvus简介</h1><h2 id="什么是Milvus"><a href="#什么是Milvus" class="headerlink" title="什么是Milvus"></a>什么是Milvus</h2><p>（1）Milvus是一款云原生向量数据库，它具备高可用、高性能、易拓展的特点，用于海量向量数据的实时召回。</p><p>（2）Milvus基于FAISS、Annoy、HNSW等向量搜索库构建，核心是解决稠密向量相似度检索的问题。</p><p>（3）在向量检索库的基础上，Milvus支持数据分区分片、数据持久化、增量数据摄取、标量向量混合查询、time travel 等功能，同时大幅优化了向量检索的性能，可满足任何向量检索场景的应用需求。</p><p>（4）通常，建议用户使用 Kubernetes 部署 Milvus，以获得最佳可用性和弹性。</p><p><font style="color:rgb(51, 51, 51);">Milvus 采用</font>共享存储架构，<strong>存储计算完全分离</strong>，计算节点支持横向扩展。从架构上来看，Milvus 遵循数据流和控制流分离，整体分为了四个层次，分别为接入层（access layer）、协调服务（coordinator service）、执行节点（worker node）和存储层（storage）。各个层次相互独立，独立扩展和容灾。</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762511182931-a6771352-5678-4303-9812-9e15e73655f0.png"></p><h2 id="为什么需要Milvus"><a href="#为什么需要Milvus" class="headerlink" title="为什么需要Milvus"></a>为什么需要Milvus</h2><p>随着互联网不断发展，电子邮件、论文、物联网传感数据、社交媒体照片、蛋白质分子结构等<strong>非结构化数据</strong>已经变得越来越普遍。如果想要使用计算机来处理这些数据，需要使用embedding技术将这些数据转化为向量。随后，Milvus会存储这些向量，并为其建立索引。Milvus 能够根据两个向量之间的距离来分析他们的相关性。如果两个向量十分相似，这说明向量所代表的源数据也十分相似。</p><p>Milvus 向量数据库专为向量查询与检索设计，能够为万亿级向量数据建立索引。Milvus 在底层设计上就是为了处理由各种非结构化数据转换而来的Embedding向量而生。</p><h2 id="为什么使用Milvus"><a href="#为什么使用Milvus" class="headerlink" title="为什么使用Milvus"></a>为什么使用Milvus</h2><p>（1）高性能：性能高超，可对海量数据集进行向量相似度检索；</p><p>（2）高可用、高可靠：Milvus 支持在云上扩展，其容灾能力能够保证服务高可用；</p><p>（3）混合查询：Milvus 支持在向量相似度检索过程中进行标量字段过滤，实现混合查询；</p><p>（4）开发者友好：支持多语言、多工具的 Milvus 生态系统。</p><h1 id="Milvus系统架构"><a href="#Milvus系统架构" class="headerlink" title="Milvus系统架构"></a>Milvus系统架构</h1><h2 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h2><p>Milvus 2.0 是一款云原生向量数据库，采用存储与计算分离的架构设计，所有组件均为无状态组件，极大地增强了系统弹性和灵活性：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762507905049-b8a65870-541b-4a26-aa2b-f8ed25bcd82e.png"></p><p>整个系统分为四个层次，各个层次相互独立，独立扩展和容灾：</p><p>（1）接入层（Access Layer）：它是系统的门面，由一组无状态的Proxy组成，对外提供用户连接的endpoint，负责验证客户端请求并合并返回结果。</p><p>（2）协调服务（Coordinator Service）：系统的大脑，负责分配任务给执行节点。协调服务共有四种角色，分别为 root coord、data coord、query coord 和 index coord。</p><p>（3）执行节点（Worker Node）：系统的四肢，负责完成协调服务下发的指令和proxy发起的数据操作语言（DML）命令。执行节点分为三种角色，分别为data node、query node和index node。</p><p>（4） 存储服务 （Storage）： 系统的骨骼，负责Milvus数据的持久化，分为元数据存储（meta store）、消息存储（log broker）和对象存储（object storage）三个部分。</p><h2 id="接入层（Access-Layer）"><a href="#接入层（Access-Layer）" class="headerlink" title="接入层（Access Layer）"></a>接入层（Access Layer）</h2><p>（1）接入层由一组无状态 proxy 组成，是整个系统的门面，对外提供用户连接的 endpoint。接入层负责验证客户端请求并减少返回结果；</p><p>（2）Proxy本身是无状态的，一般通过负载均衡组件（Nginx、Kubernetes Ingress、NodePort、LVS）对外提供统一的访问地址并提供服务。</p><p>（3） 由于Milvus采用大规模并行处理（MPP）架构，proxy会先对执行节点返回的中间结果进行全局聚合和后处理后，再返回至客户端。</p><h2 id="协调服务（Coordinator-Service）"><a href="#协调服务（Coordinator-Service）" class="headerlink" title="协调服务（Coordinator Service）"></a>协调服务（Coordinator Service）</h2><p>（1）协调服务是系统的大脑，负责向执行节点分配任务。它承担的任务包括集群拓扑节点管理、负载均衡、时间戳生成、数据声明和数据管理等。</p><p>（2）协调服务共有四种角色：</p><ul><li>Root coordinator（root coord）：负责处理数据定义语言（DDL）和数据控制语言（DCL）请求。比如，创建或删除collection、partition、index等，同时负责维护中心授时服务TSO和时间窗口的推进。</li><li>Query coordinator (query coord）：负责管理query node的拓扑结构和负载均衡以及从增长的 segment 移交切换到密封的 segment。</li><li>Data coordinator (data coord）：负责管理data node的拓扑结构，维护数据的元信息以及触发 flush、compact 等后台数据操作。</li><li>Index coordinator (index coord）：负责管理index node的拓扑结构，构建索引和维护索引元信息。</li></ul><h2 id="执行节点（Worker-Node）"><a href="#执行节点（Worker-Node）" class="headerlink" title="执行节点（Worker Node）"></a>执行节点（Worker Node）</h2><p>（1）执行节点是系统的四肢，负责完成协调服务下发的指令和 proxy 发起的数据操作语言（DML）命令。</p><p>（2）由于采取了存储计算分离，执行节点是无状态的，可以配合 Kubernetes 快速实现扩缩容和故障恢复</p><p>（3）执行节点分为三种角色：</p><ul><li>Query node： Query node 通过订阅消息存储（log broker）获取增量日志数据并转化为 growing segment，基于对象存储加载历史数据，提供标量 + 向量的混合查询和搜索功能。</li><li>Data node：Data node 通过订阅消息存储获取增量日志数据，处理更改请求，并将日志数据打包存储在对象存储上实现日志快照持久化。</li><li>Index node：Index node 负责执行索引构建任务。Index node 不需要常驻于内存，可以通过 serverless 的模式实现。</li></ul><h2 id="存储服务-（Storage）"><a href="#存储服务-（Storage）" class="headerlink" title="存储服务 （Storage）"></a>存储服务 （Storage）</h2><p>存储服务是系统的骨骼，负责 Milvus 数据的持久化，分为元数据存储（meta store）、对象存储（object storage）和消息存储（log broker）三个部分。</p><h3 id="元数据存储（meta-store）"><a href="#元数据存储（meta-store）" class="headerlink" title="元数据存储（meta store）"></a>元数据存储（meta store）</h3><p>负责存储元信息的快照，如集合 schema 信息、节点状态信息、消息消费的 checkpoint 等。元信息存储需要极高的可用性、强一致和事务支持，因此etcd是这个场景下的不二选择。除此之外，etcd还承担了服务注册和健康检查的职责。</p><h3 id="对象存储（object-storage）"><a href="#对象存储（object-storage）" class="headerlink" title="对象存储（object storage）"></a>对象存储（object storage）</h3><p>负责存储日志的快照文件、标量 / 向量索引文件以及查询的中间处理结果。Milvus 采用MinIO作为对象存储，另外也支持部署于AWS S3和Azure Blob这两大最广泛使用的低成本存储。但是，由于对象存储访问延迟较高，且需要按照查询计费，因此Milvus未来计划支持基于内存或 SSD 的缓存池，通过冷热分离的方式提升性能以降低成本。</p><h3 id="消息存储（log-broker）"><a href="#消息存储（log-broker）" class="headerlink" title="消息存储（log broker）"></a>消息存储（log broker）</h3><p>消息存储是一套支持回放的发布订阅系统，用于持久化流式写入的数据，以及可靠的异步执行查询、事件通知和结果返回。执行节点宕机恢复时，通过回放消息存储保证增量数据的完整性。</p><p>目前，分布式版Milvus依赖Pulsar作为消息存储，单机版Milvus依赖RocksDB作为消息存储。消息存储也可以替换为Kafka、Pravega等流式存储。整个Milvus围绕日志为核心来设计，遵循<strong>日志即数据</strong>的准则，因此在 2.0 版本中没有维护物理上的表，而是通过日志持久化和日志快照来保证数据的可靠性。</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762508954322-a30f956d-f741-48a3-ab4a-255ed97feee9.png"></p><p>日志系统作为系统的主干，承担了数据持久化和解耦的作用。通过日志的发布订阅机制，Milvus将系统的读、写组件解耦。一个极致简化的模型如上图所示，整个系统主要由两个角色构成，分别是消息存储（log broker）（负责维护”日志序列 “）与“日志订阅者”。其中的“日志序列” 记录了所有改变库表状态的操作，“日志订阅者”通过订阅日志序列更新本地数据，以只读副本的方式提供服务。 发布订阅机制还为系统在变更数据捕获（CDC）和全面的分布式部署方面的可扩展性提供了空间。</p><h1 id="Milvus主要的组件"><a href="#Milvus主要的组件" class="headerlink" title="Milvus主要的组件"></a>Milvus主要的组件</h1><p>Milvus支持两种部署模式，单机模式（standalone）和分布式模式（cluster）。两种模式具备完全相同的能力，用户可根据数据规模、访问量等因素选择适合自己的模式。Standalone模式部署的Milvus暂时不支持在线升级为cluster模式。</p><h2 id="单机模式"><a href="#单机模式" class="headerlink" title="单机模式"></a>单机模式</h2><p>单机版的Milvus主要有三个组件，分别是Milvus、etcd和MinIO：</p><ul><li>Milvus负责提供系统的核心功能；</li><li>etcd是元数据引擎，用于管理Milvus内部组件的元数据访问和存储，例如：proxy、index node等；</li><li>MinIO是存储引擎，负责维护Milvus的数据持久化。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762509223944-66e7b2fa-cb29-4916-af07-2ed18325376d.png"></p><h2 id="分布式模式"><a href="#分布式模式" class="headerlink" title="分布式模式"></a>分布式模式</h2><p>（1）分布式版的Milvus主要有八个微服务组件和三个第三方依赖组成，每个微服务组件可使用 Kubernetes 独立部署。</p><p>（2）八个微服务组件分别是：Root coord、Proxy、Query coord、Query node、Index coord、 Index node、Data coord和Data node。</p><p>（3）三个第三方依赖，分别是etcd、MinIO和Pulsar：</p><ul><li>etcd 负责存储集群中各组件的元数据信息；</li><li>MinIO 负责处理集群中大型文件的数据持久化，如索引文件和全二进制日志文件；</li><li>Pulsar 负责管理近期更改操作的日志，输出流式日志及提供日志订阅服务。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762509488543-8dd69fa0-db59-4513-bedb-c4a857f4c463.png"></p><h1 id="Milvus的应用场景"><a href="#Milvus的应用场景" class="headerlink" title="Milvus的应用场景"></a>Milvus的应用场景</h1><p>开发者可以使用Milvus搭建符合自己场景需求的向量相似度检索系统。Milvus的使用场景如下：</p><p>（1） 图片检索系统：以图搜图，从海量数据库中即时返回与上传图片最相似的图片。</p><p>（2）视频检索系统：将视频关键帧转化为向量并插入 Milvus，便可检索相似视频，或进行实时视频推荐。</p><p>（3）音频检索系统：快速检索海量演讲、音乐、音效等音频数据，并返回相似音频。</p><p>（4） 分子式检索系统：超高速检索相似化学分子结构、超结构、子结构。</p><p>（5） 推荐系统：根据用户行为及需求推荐相关信息或商品。</p><p>（6）智能问答机器人：交互式智能问答机器人可自动为用户答疑解惑。</p><p>（7）DNA序列分类系统：通过对比相似 DNA 序列，仅需几毫秒便可精确对基因进行分类。</p><p>（8） 文本搜索引擎：帮助用户从文本数据库中通过关键词搜索所需信息。</p><h1 id="Milvus支持的搜索类型"><a href="#Milvus支持的搜索类型" class="headerlink" title="Milvus支持的搜索类型"></a>Milvus支持的搜索类型</h1><p>Milvus支持多种类型的搜索功能，如下：</p><p>（1）ANN搜索：查找最接近查询向量的前K个向量；</p><p>（2）过滤搜索：在指定的过滤条件下执行 ANN 搜索；</p><p>（3）范围搜索：查找查询向量指定半径范围内的向量；</p><p>（4）混合搜索：基于多个向量场进行 ANN 搜索；</p><p>（5）全文搜索：基于 BM25 的全文搜索；</p><p>（6）Rerankers：根据附加标准或辅助算法调整搜索结果顺序，完善初始 ANN 搜索结果；</p><p>（7）获取：根据主键检索数据；</p><p>（8）查询：使用特定表达式检索数据。</p><h1 id="Milvus与Pinecone的对比"><a href="#Milvus与Pinecone的对比" class="headerlink" title="Milvus与Pinecone的对比"></a>Milvus与Pinecone的对比</h1><p>以下是Milvus与Pinecone的整体对比：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762504908085-f70ee99a-35db-4743-a62d-2d5b1251a56b.png"></p><p>虽然两者作为向量数据库功能相似，但是在特定领域的术语不同：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762504927303-2270bdf2-7bf7-441d-b0e7-ec896c969757.png"></p><p>当然两者在能力方面也存在不同：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762505020541-609f12ee-1fa5-4d40-b66e-3f30b11d6261.png"></p><ul><li><strong><font style="color:rgb(0, 0, 0);">部署模式</font></strong><font style="color:rgb(0, 0, 0);">：</font>Milvus提供多种部署选项，包括本地部署、Docker、Kubernetes on-premises、云SaaS和面向企业的自带云（BYOC），而Pinecone仅限于SaaS部署。</li><li><strong><font style="color:rgb(0, 0, 0);">嵌入功能</font></strong><font style="color:rgb(0, 0, 0);">：</font>Milvus 支持额外的嵌入库，可直接使用嵌入模型将源数据转换为向量。</li><li><strong><font style="color:rgb(0, 0, 0);">数据类型</font></strong><font style="color:rgb(0, 0, 0);">：</font>与 Pinecone 相比，Milvus 支持更广泛的数据类型，包括数组和 JSON。Pinecone 只支持以字符串、数字、布尔值或字符串列表为值的扁平元数据结构，而 Milvus 可以在一个 JSON 字段内处理任何 JSON 对象，包括嵌套结构。Pinecone 限制每个向量的元数据大小为 40KB。</li><li><strong><font style="color:rgb(0, 0, 0);">度量和索引类型</font></strong><font style="color:rgb(0, 0, 0);">：</font>Milvus 支持多种度量和索引类型，以适应各种使用情况，而 Pinecone 的选择较为有限。虽然在 Milvus 中必须为向量建立索引，但也提供了 AUTO_INDEX 选项来简化配置过程。</li><li><strong><font style="color:rgb(0, 0, 0);">Schema 设计</font></strong><font style="color:rgb(0, 0, 0);">：</font>Milvus 为模式设计提供了灵活的<code>create_collection</code> 模式，包括快速设置动态模式，以获得类似 Pinecone 的无模式体验，以及自定义设置预定义模式字段和索引，类似关系数据库管理系统（RDBMS）。</li><li><strong><font style="color:rgb(0, 0, 0);">多向量字段</font></strong><font style="color:rgb(0, 0, 0);">：</font>Milvus 支持在单个 Collections 中存储多个向量字段，这些字段可以是稀疏的，也可以是密集的，维度也可能不同。Pinecone 不提供类似功能。</li><li><strong><font style="color:rgb(0, 0, 0);">工具</font></strong><font style="color:rgb(0, 0, 0);">：</font>Milvus 为数据库管理和利用提供了更广泛的工具选择，如 Attu、Birdwatcher、Backup、CLI、CDC 以及 Spark 和 Kafka 连接器。</li></ul><h1 id="Milvus基本概念"><a href="#Milvus基本概念" class="headerlink" title="Milvus基本概念"></a>Milvus基本概念</h1><h2 id="非结构化数据"><a href="#非结构化数据" class="headerlink" title="非结构化数据"></a>非结构化数据</h2><p>（1）非结构化数据指的是数据结构不规则，没有统一的预定义数据模型，不方便用数据库二维逻辑表来表现的数据。</p><p>（2）非结构化数据包括图片、视频、音频、自然语言等，占所有数据总量的 80%。</p><p>（3）非结构化数据的处理可以通过各种人工智能（AI）或机器学习（ML）模型转化为向量数据后进行处理。</p><h2 id="特征向量"><a href="#特征向量" class="headerlink" title="特征向量"></a>特征向量</h2><p>（1）向量又称为embedding vector，是指由embedding技术从离散变量（如图片、视频、音频、自然语言等各种非结构化数据）转变而来的连续向量。</p><p>（2）在数学表示上，向量是一个由浮点数或者二值型数据组成的 n 维数组。</p><p>（3）通过现代的向量转化技术，比如各种人工智能（AI）或者机器学习（ML）模型，可以将非结构化数据抽象为 n 维特征向量空间的向量。这样就可以采用最近邻算法（ANN）计算非结构化数据之间的相似度。</p><h2 id="向量相似度检索"><a href="#向量相似度检索" class="headerlink" title="向量相似度检索"></a>向量相似度检索</h2><p>（1）相似度检索是指将目标对象与数据库中数据进行比对，并召回最相似的结果。同理，向量相似度检索返回的是最相似的向量数据。</p><p>（2）近似最近邻搜索（ANN）算法能够计算向量之间的距离，从而提升向量相似度检索的速度。如果两条向量十分相似，这就意味着他们所代表的源数据也十分相似。</p><h2 id="Collection"><a href="#Collection" class="headerlink" title="Collection"></a>Collection</h2><p>包含一组 entity，可以等价于关系型数据库系统（RDBMS）中的表。</p><h2 id="Entity"><a href="#Entity" class="headerlink" title="Entity"></a>Entity</h2><p>（1）包含一组field。field与实际对象相对应。field可以是代表对象属性的结构化数据，也可以是代表对象特征的向量。primary key用于指代一个entity的唯一值。</p><p>（2）开发者可以自定义primary key，否则Milvus将会自动生成primary key。</p><p>（3）请注意，目前Milvus不支持primary key去重，因此有可能在一个collection内出现primary key相同的entity。</p><h2 id="Field"><a href="#Field" class="headerlink" title="Field"></a>Field</h2><p>（1）Entity 的组成部分。Field 可以是结构化数据，例如数字和字符串，也可以是向量。</p><p>（2）Milvus 2.0 现已支持标量字段过滤。并且，Milvus 2.0 在一个集合中只支持一个主键字段。</p><h2 id="Milvus与关系数据库对比"><a href="#Milvus与关系数据库对比" class="headerlink" title="Milvus与关系数据库对比"></a>Milvus与关系数据库对比</h2><p>Milvus 与关系型数据库的对应关系如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762510468244-ec2606d3-96a2-420f-a783-250667713890.png"></p><h2 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a><font style="color:rgb(0, 0, 0);">Partition</font></h2><p>分区（Partition）是集合（Collection）的一个分区。Milvus 支持将收集数据划分为物理存储上的多个部分。这个过程称为分区，每个分区可以包含多个段。</p><h2 id="Segment"><a href="#Segment" class="headerlink" title="Segment"></a><font style="color:rgb(51, 51, 51);">Segment</font></h2><p>Milvus在数据插入时，通过合并数据自动创建的数据文件。一个collection可以包含多个segment。一个segment可以包含多个entity。在搜索中，Milvus会搜索每个segment，并返回合并后的结果。</p><h2 id="Sharding"><a href="#Sharding" class="headerlink" title="Sharding"></a>Sharding</h2><p>（1）Shard 是指将数据写入操作分散到不同节点上，使 Milvus 能充分利用集群的并行计算能力进行写入。默认情况下，单个 Collection 包含 2 个分片（Shard）。</p><p>（2）目前 Milvus 采用基于<strong>主键哈希</strong>的分片方式，未来将支持随机分片、自定义分片等更加灵活的分片方式。</p><p>（3）<strong>分区的意义在于通过划定分区减少数据读取，而分片的意义在于多台机器上并行写入操作。</strong></p><h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p>（1）索引基于原始数据构建，可以提高对 collection 数据搜索的速度。</p><p>（2）Milvus 支持多种索引类型。为提高查询性能，开发者可以为每个向量字段指定一种索引类型。目前，一个向量字段仅支持一种索引类型。切换索引类型时，Milvus 自动删除之前的索引。</p><p>（3）<strong>相似性搜索引擎的工作原理：将输入的对象与数据库中的对象进行比较，找出与输入最相似的对象</strong>。</p><p>（4）索引是有效组织数据的过程，极大地加速了对大型数据集的查询，在相似性搜索的实现中起着重要作用。对一个大规模向量数据集创建索引后，查询可以被路由到最有可能包含与输入查询相似的向量的集群或数据子集。在实践中，这意味着要牺牲一定程度的准确性来加快对真正的大规模向量数据集的查询。</p><h2 id="PChannel"><a href="#PChannel" class="headerlink" title="PChannel"></a>PChannel</h2><p>PChannel 表示物理信道。每个 PChannel 对应一个日志存储主题。默认情况下，将分配一组 256 个 PChannels 来存储记录 Milvus 集群启动时数据插入、删除和更新的日志。</p><h2 id="VChannel"><a href="#VChannel" class="headerlink" title="VChannel"></a>VChannel</h2><p>VChannel 表示逻辑通道。每个集合将分配一组 VChannels，用于记录数据的插入、删除和更新。VChannels 在逻辑上是分开的，但在物理上共享资源。</p><h1 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h1><p>关于Docker的具体安装，这里不详细介绍，只给出docker engine的可用镜像地址：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;builder&quot;: &#123;</span><br><span class="line">    &quot;gc&quot;: &#123;</span><br><span class="line">      &quot;defaultKeepStorage&quot;: &quot;20GB&quot;,</span><br><span class="line">      &quot;enabled&quot;: true</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;experimental&quot;: false,</span><br><span class="line">  &quot;registry-mirrors&quot;: [</span><br><span class="line">    &quot;https://ccr.ccs.tencentyun.com&quot;,</span><br><span class="line">    &quot;https://mirrors.tuna.tsinghua.edu.cn/&quot;,</span><br><span class="line">    &quot;https://9cpn8tt6.mirror.aliyuncs.com&quot;,</span><br><span class="line">    &quot;https://registry.docker-cn.com&quot;,</span><br><span class="line">    &quot;https://mirror.ccs.tencentyun.com&quot;,</span><br><span class="line">    &quot;https://docker.1panel.live&quot;,</span><br><span class="line">    &quot;https://2a6bf1988cb6428c877f723ec7530dbc.mirror.swr.myhuaweicloud.com&quot;,</span><br><span class="line">    &quot;https://docker.m.daocloud.io&quot;,</span><br><span class="line">    &quot;https://hub-mirror.c.163.com&quot;,</span><br><span class="line">    &quot;https://mirror.baidubce.com&quot;,</span><br><span class="line">    &quot;https://dockerhub.icu&quot;,</span><br><span class="line">    &quot;https://docker.registry.cyou&quot;,</span><br><span class="line">    &quot;https://docker-cf.registry.cyou&quot;,</span><br><span class="line">    &quot;https://dockercf.jsdelivr.fyi&quot;,</span><br><span class="line">    &quot;https://docker.jsdelivr.fyi&quot;,</span><br><span class="line">    &quot;https://dockertest.jsdelivr.fyi&quot;,</span><br><span class="line">    &quot;https://mirror.aliyuncs.com&quot;,</span><br><span class="line">    &quot;https://dockerproxy.com&quot;,</span><br><span class="line">    &quot;https://mirror.baidubce.com&quot;,</span><br><span class="line">    &quot;https://docker.m.daocloud.io&quot;,</span><br><span class="line">    &quot;https://docker.nju.edu.cn&quot;,</span><br><span class="line">    &quot;https://docker.mirrors.sjtug.sjtu.edu.cn&quot;,</span><br><span class="line">    &quot;https://docker.mirrors.ustc.edu.cn&quot;,</span><br><span class="line">    &quot;https://mirror.iscas.ac.cn&quot;,</span><br><span class="line">    &quot;https://docker.rainbond.cc&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="安装Milvus"><a href="#安装Milvus" class="headerlink" title="安装Milvus"></a>安装Milvus</h1><p>点击 <a href="https://github.com/milvus-io/milvus/releases">这里</a> 选择对应的版本，或者直接点击 <a href="https://github.com/milvus-io/milvus/releases/download/v2.6.4/milvus-standalone-docker-compose.yml">链接</a> 下载2.6.4的版本：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761477872496-785f1c4e-234d-479d-978b-a82bfeb00c6e.png"></p><p>下载完成后，修改yaml文件名称为<font style="color:rgb(51, 51, 51);">docker-compose.yml。新建一个目录，名字可以为milvus，然后cmd到该目录中，执行如下命令：</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure><p>由于在下载镜像，所以需要一些时间，出现下面的信息，说明下载完成：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761478071707-76d732ed-723c-4754-b9b4-f77201195154.png"></p><p>然后执行如下命令来查看是否启动成功：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker compose ps</span><br></pre></td></tr></table></figure><p>三个都是up，则说明启动成功：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761478152304-2ede08c2-93af-4577-85c6-4e41b27f9ca9.png"></p><p>在Docker-DeskTop中也能查看启动情况：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761478226934-28a668d9-97d0-481e-9955-7e81403f8bf8.png"></p><p>这样我们就安装完Milvus，但是这样不直观，需要可视化工具来管理向量，下面就开始安装Attu这一工具。</p><h1 id="安装Attu"><a href="#安装Attu" class="headerlink" title="安装Attu"></a>安装Attu</h1><p>第一步，使用ipconfig命令查看一下当前IP地址：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761478323187-d32f1892-0ec6-4173-8115-ca9c571b341b.png"></p><p>笔者使用的是WLAN，所以只需看这个适配器的IPV4地址，如果你开了虚拟机，那么VMnet1和VMnet8也是不用管的。</p><p>第二步，使用如下命令来安装Attu：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --name attu-261 -p 3000:3000 -e MILVUS_URL=192.168.43.212:19530 zilliz/attu:v2.6.1</span><br></pre></td></tr></table></figure><p>其中表示将容器的3000端口转发到宿主机的3000端口，而其中的MILVUS_URL则是之前的本地IP地址，19530是向量数据库的端口，容器名称为attu-261，出现下面的<a href="http://172.17.0.2:3000表示启动成功：">http://172.17.0.2:3000表示启动成功：</a></p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761478529707-43185e94-a023-4ec6-ba53-56af5bfe38ee.png"></p><h1 id="访问Attu"><a href="#访问Attu" class="headerlink" title="访问Attu"></a>访问Attu</h1><p>打开浏览器，访问如下地址：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:3000</span><br></pre></td></tr></table></figure><p>页面出现如下信息：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761477785809-5105cb24-3fd1-4109-90b3-615f99bd08da.png"></p><p>点击连接，即可登录到控制台：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761477790589-0b1768a9-0321-4c4c-a98c-87c77057a98c.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Milvus简介&quot;&gt;&lt;a href=&quot;#Milvus简介&quot; class=&quot;headerlink&quot; title=&quot;Milvus简介&quot;&gt;&lt;/a&gt;Milvus简介&lt;/h1&gt;&lt;h2 id=&quot;什么是Milvus&quot;&gt;&lt;a href=&quot;#什么是Milvus&quot; class=&quot;he</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>LangChain4j之向量存储</title>
    <link href="http://aichating.xyz/2025/10/25/2025-18-lang-chain-4j-9-vector-store/"/>
    <id>http://aichating.xyz/2025/10/25/2025-18-lang-chain-4j-9-vector-store/</id>
    <published>2025-10-25T10:01:20.000Z</published>
    <updated>2025-10-26T11:31:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="向量存储"><a href="#向量存储" class="headerlink" title="向量存储"></a>向量存储</h1><h2 id="主流向量数据库对比"><a href="#主流向量数据库对比" class="headerlink" title="主流向量数据库对比"></a>主流向量数据库对比</h2><p>点击 <a href="https://docs.langchain4j.dev/tutorials/rag/#embedding-store">这里</a>，查看langchain4j对于向量存储的支持说明：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761359800143-41d76b5d-f153-462f-83f3-6980cd571ad3.png"></p><p>下图是主流的向量数据库的对比：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761359690512-2d668242-38fa-4ab7-bb1f-e17e31a6e074.png"></p><p><strong>研发 / 原型阶段</strong></p><ul><li>推荐：FAISS（本地），Chroma</li><li>优点：轻量、易用、社区丰富</li></ul><p><strong>构建 Web 应用 / 小中型系统</strong></p><ul><li>推荐：Qdrant，Weaviate，Milvus-lite</li><li>优点：支持 <code>REST/gRPC/客户端SDK</code>，带元数据过滤，可集成 <code>LangChain</code></li></ul><p><strong>大规模生产部署 / 高并发</strong></p><ul><li>推荐：Milvus（完整集群），Pinecone（托管），Vespa（超大规模）</li><li>优点：高可扩展性，多副本，支持异构资源</li></ul><h2 id="Pinecone简介"><a href="#Pinecone简介" class="headerlink" title="Pinecone简介"></a>Pinecone简介</h2><p>之前我们使用InMemoryEmbeddingStore作为向量存储，但是不建议在生产中使用基于内存的向量存储，因此接下来我们使用Pinecone作为向量数据库。</p><p>点击 <a href="https://www.pinecone.io/">这里</a>，查看Pinecone的官方网站，用户默认有2GB的免费存储空间。之后进行注册、登录和使用。</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761359999608-d17a51bf-6d34-4e25-a299-14c5fc5fd13c.png"></p><h2 id="Pinecone使用"><a href="#Pinecone使用" class="headerlink" title="Pinecone使用"></a>Pinecone使用</h2><p><strong>【得分的含义</strong>】</p><p>在向量检索场景中，当我们把查询文本转换为向量后，会在嵌入存储（<strong>EmbeddingStore</strong>）里查找与之最相似的向量（这些向量对应文档片段的内容）。为了衡量查询向量和存储向量之间的相似程度，会使用某种相似度计算方法（如余弦相似度等）来得出一个数值，这个数值就是得分。得分越高，表明查询向量和存储向量越相似，对应的文档片段与查询文本的相关性也就越高。</p><p><strong>【得分的作用】</strong></p><p>（1）<strong>筛选结果</strong>：通过设置<code>minScore</code> 阈值，能够过滤掉那些与查询文本相关性较低的结果。在代码中，<code>minScore(0.8)</code> 意味着只有得分大于等于 0.8 的结果才会被返回，低于这个阈值的结果会被舍弃。这样可以确保返回的结果是与查询文本高度相关的，提升检索结果的质量。</p><p>（2）<strong>控制召回率和准确率</strong>：调整 <code>minScore</code> 的值可以在召回率和准确率之间进行权衡。如果把阈值设置得较低，那么更多的结果会被返回，召回率会提高，但可能会包含一些相关性不太强的结果，导致准确率下降。反之，如果把阈值设置得较高，返回的结果数量会减少，准确率会提高，但可能会遗漏一些相关的结果，使得召回率降低。在实际应用中，需要根据具体的业务需求来合理设置<code>minScore</code>的值。</p><p>【一个例子】</p><p>假设我们有一个关于水果的文档集合，嵌入存储中存储了这些文档片段的向量。当我们使用 “苹果的营养价值” 作为查询文本时，向量检索会计算查询向量与存储向量的相似度得分。如果 minScore设置为 0.8，那么只有那些与 “苹果的营养价值” 相关性非常高的文档片段才会被返回，而一些只简单提及苹果但没有详细讨论其营养价值的文档片段可能由于得分低于 0.8 而不会被返回。</p><h2 id="Pinecone集成"><a href="#Pinecone集成" class="headerlink" title="Pinecone集成"></a>Pinecone集成</h2><h3 id="添加依赖"><a href="#添加依赖" class="headerlink" title="添加依赖"></a>添加依赖</h3><p>点击 <a href="https://docs.langchain4j.dev/integrations/embedding-stores/pinecone/">链接</a>，查看langchain4j对于Pinecone的支持说明：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761361586794-a17ffccb-f4d7-4844-a872-ed50ae8acb89.png"></p><p>在项目的pom文件中引入依赖：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 集成pinecone --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;langchain4j-pinecone&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><h3 id="配置向量存储对象"><a href="#配置向量存储对象" class="headerlink" title="配置向量存储对象"></a>配置向量存储对象</h3><p>（1）在langchain4j中，<code>EmbeddingStore</code>接口提供了统一的API，使得开发者可以很方便切换不同的向量数据库实现。</p><p>（2）<code>EmbeddingStore</code>的主要功能包括：</p><ul><li><strong>存储嵌入向量</strong>。将文本或其他数据转换为嵌入向量后，存储到向量数据库中。</li><li><strong>相似度搜索</strong>。根据输入的查询向量，检索与之相似的嵌入向量，实现语义搜索。</li><li><strong>关联原始数据</strong>。可以将嵌入向量与原始的<code>TextSegment</code>数据一起存储，便于在检索时获取完整的上下文信息。</li></ul><p>在项目的config包内定义一个名为 EmbeddingStoreConfig 的配置类：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">public class EmbeddingStoreConfig &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    private EmbeddingModel embeddingModel;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    public EmbeddingStore&lt;TextSegment&gt; embeddingStore()&#123;</span><br><span class="line">        return PineconeEmbeddingStore.builder()</span><br><span class="line">                .apiKey(&quot;your_apiKey&quot;)</span><br><span class="line">                .index(&quot;yusi-index&quot;)</span><br><span class="line">                .nameSpace(&quot;yusi-namespace&quot;)</span><br><span class="line">                .createIndex(PineconeServerlessIndexConfig.builder()</span><br><span class="line">                        .cloud(&quot;AWS&quot;).region(&quot;us-east-1&quot;)</span><br><span class="line">                        .dimension(embeddingModel.dimension()).build()).build();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>简单解释一下上述代码的含义：</p><p>（1）apiKey：设置对应的apiKey；</p><p>（2）index：设置对应的索引，如果指定的索引名称不存在，那么将创建一个新的索引；</p><p>（3）nameSpace：设置对应的命名空间，如果指定的命名空间不存在，那么将创建一个新的命名空间；</p><p>（4）cloud：指定索引部署在AWS云服务上；</p><p>（5）region：指定索引所在AWS的区域为us-east-1；</p><p>（6）dimension：指定索引的向量维度，该维度与embeddedModel生成的向量维度相同。</p><p>实际上这些参数可以参考下面创建索引时的步骤来获取：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761367468334-b003ea83-f6ce-4034-8c12-f89fd4bcb098.png"></p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761367483400-eb845af8-d463-4eda-9982-da77c80a32f1.png"></p><h3 id="测试向量存储"><a href="#测试向量存储" class="headerlink" title="测试向量存储"></a>测试向量存储</h3><p>修改EmbeddingController中的代码为如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">@Slf4j</span><br><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/embedding&quot;)</span><br><span class="line">public class EmbeddingController &#123;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private OllamaEmbeddingModel ollamaEmbeddingModel;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private EmbeddingStore embeddingStore;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 测试向量存储</span><br><span class="line">     */</span><br><span class="line">    @GetMapping(&quot;/testEmbeddingStore&quot;)</span><br><span class="line">    public String testEmbeddingStore()&#123;</span><br><span class="line">        //将文本转换成向量</span><br><span class="line">        TextSegment textSegment = TextSegment.from(&quot;你好&quot;);</span><br><span class="line">        //获取向量</span><br><span class="line">        Embedding embedding = ollamaEmbeddingModel.embed(textSegment).content();</span><br><span class="line">        //添加向量</span><br><span class="line">        embeddingStore.add(embedding, textSegment);</span><br><span class="line">        return &quot;success&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>之后访问如下链接：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/embedding/testEmbeddingStore</span><br></pre></td></tr></table></figure><p>页面返回success信息后，刷新Pinecone的index界面：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761367944006-7008d772-805a-4a04-a68d-0b4246dad32d.png"></p><p>可以看到此时已经有一个向量存储在Pinecone服务器上了。</p><h3 id="相似度匹配"><a href="#相似度匹配" class="headerlink" title="相似度匹配"></a>相似度匹配</h3><p>所谓相似度匹配，即接收请求获取问题，将问题转换为向量，在 Pinecone 向量数据库中进行相似度搜索，找到最相似的文本片段，并将其文本内容返回给客户端。</p><p>第一步，调用前面测试向量存储的接口，往里面存入文本内容为“我喜欢吃西瓜”的向量数据，以便后面使用：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761368282537-ceb4d396-15f6-4bb4-a619-eb52e63e5cfe.png"></p><p>第二步，修改EmbeddingController中的代码为如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">@Slf4j</span><br><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/embedding&quot;)</span><br><span class="line">public class EmbeddingController &#123;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private OllamaEmbeddingModel ollamaEmbeddingModel;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private EmbeddingStore embeddingStore;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 测试向量搜索</span><br><span class="line">     */</span><br><span class="line">    @GetMapping(&quot;/testEmbeddingSearch&quot;)</span><br><span class="line">    public String testEmbeddingSearch()&#123;</span><br><span class="line">        //提问，并将问题转成向量数据</span><br><span class="line">        Embedding queryEmbedding = ollamaEmbeddingModel.embed(&quot;你最喜欢什么水果？&quot;)</span><br><span class="line">                                                        .content();</span><br><span class="line">        //创建搜索请求对象</span><br><span class="line">        EmbeddingSearchRequest searchRequest = EmbeddingSearchRequest.builder()</span><br><span class="line">                .queryEmbedding(queryEmbedding)</span><br><span class="line">                .maxResults(1) // 设置最大返回结果数量</span><br><span class="line">                .minScore(0.1) // 设置最小得分阈值</span><br><span class="line">                .build();</span><br><span class="line">        //根据搜索请求 searchRequest 在向量存储中进行相似度搜索</span><br><span class="line">        EmbeddingSearchResult&lt;TextSegment&gt; searchResult = embeddingStore</span><br><span class="line">                                                          .search(searchRequest);</span><br><span class="line">        //获取搜索结果,获取最相似的向量,返回一个</span><br><span class="line">        EmbeddingMatch&lt;TextSegment&gt; embeddingMatch = searchResult.matches().get(0);</span><br><span class="line">        //获取匹配项的相似度得分</span><br><span class="line">        log.info(&quot;相似度得分：&#123;&#125;&quot;,embeddingMatch.score());</span><br><span class="line">        // 获取匹配项的向量数据</span><br><span class="line">        String text = embeddingMatch.embedded().text();</span><br><span class="line">        //获取匹配项的元数据,即文本结果</span><br><span class="line">        log.info(&quot;匹配项的元数据：&#123;&#125;&quot;,text);</span><br><span class="line">        return text;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>简单解释一下上述代码的含义：</p><p>（1）ollamaEmbeddingModel.embed().content()：使用的是Ollama因此使用对应的模型进行提问，并将问题转成向量数据；</p><p>（2）EmbeddingSearchRequest.builder().build()：用于创建搜索请求对象，其中maxResults()用于设置最大返回结果数量，而minScore()用于设置最小得分阈值；</p><p>（3）embeddingStore.search()：用于根据搜索请求 searchRequest 在向量存储中进行相似度搜索；</p><p>（4）searchResult.matches().get(0)：searchResult.matches()获取搜索结果中的匹配项列表，然后调用get(0)从匹配项列表中获取第一个匹配项；</p><p>（5）embeddingMatch.score()：获取匹配项的相似度得分；</p><p>（6）embeddingMatch.embedded().text()：用于获取匹配项的元数据,即文本结果。</p><p>之后访问如下链接：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/embedding/testEmbeddingSearch</span><br></pre></td></tr></table></figure><p>打开控制台，输出如下信息：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761368949133-56d911c5-3064-4f9f-a5f2-1d891f8861ad.png"></p><p>可以看到它正确的输出了我们需要的数据。可见<code>EmbeddingSearchRequest</code>的核心作用是构建一个搜索请求，包含以下关键参数：</p><ul><li><strong>queryEmbedding</strong>：待搜索的查询向量，通常由嵌入模型（如 <code>EmbeddingModel</code>）生成。</li><li><strong>filter（可选）</strong>：用于根据元数据（如作者、标签等）对搜索结果进行过滤。</li><li><strong>maxResults</strong>：指定返回的最大结果数量。</li><li><strong>minScore（可选）</strong>：设置结果的最小相似度得分阈值，低于该值的结果将被排除。</li></ul><h1 id="流式输出"><a href="#流式输出" class="headerlink" title="流式输出"></a>流式输出</h1><p>点击 <a href="https://docs.langchain4j.dev/tutorials/ai-services#streaming">这里</a>，了解langchain4j对于流式响应的支持说明：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761467663871-78203d3b-577c-40e8-897d-550df530caa0.png"></p><p>这里我们返回选择Flux：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761467710683-c85fe68c-9dc9-488f-9419-67e0d3ec35ee.png"></p><p>第一步，项目pom文件中引入如下依赖：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--流式输出--&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 响应式编程 --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;langchain4j-reactor&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>第二步，在项目的application.properties配置文件中新增如下配置项：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#ollama stream chatModel</span><br><span class="line">langchain4j.ollama.streaming-chat-model.base-url=http://localhost:11434</span><br><span class="line">langchain4j.ollama.streaming-chat-model.model-name=qwen3:1.7b</span><br><span class="line">langchain4j.ollama.streaming-chat-model.temperature=0.8</span><br><span class="line">langchain4j.ollama.streaming-chat-model.timeout=PT60S</span><br><span class="line">langchain4j.ollama.streaming-chat-model.log-requests=true</span><br><span class="line">langchain4j.ollama.streaming-chat-model.log-responses=true</span><br></pre></td></tr></table></figure><p>第三步，到项目的assistant包内，在里面定义一个名为StreamAssistant的类，专门用于进行流式输出，其中的streamingChatModel属性设置为ollamaStreamingChatModel，同时方法返回的是一个Flux<String>对象：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@AiService(wiringMode = AiServiceWiringMode.EXPLICIT,</span><br><span class="line">        streamingChatModel = &quot;ollamaStreamingChatModel&quot;,</span><br><span class="line">        chatMemoryProvider = &quot;chatMemoryProvider&quot;,</span><br><span class="line">        tools = &quot;mathTools&quot;,</span><br><span class="line">        contentRetriever = &quot;contentRetriever&quot;</span><br><span class="line">)</span><br><span class="line">public interface StreamAssistant &#123;</span><br><span class="line">    @SystemMessage(fromResource = &quot;prompts/assistantV1.txt&quot;)</span><br><span class="line">    Flux&lt;String&gt; chat(@MemoryId int memoryId , @UserMessage String userMessage);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第四步，回到controller包中，我们新创建一个名为ChatController的类：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">@Slf4j</span><br><span class="line">@RestController</span><br><span class="line">public class ChatController &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    private SeparateChatAssistant separateChatAssistant;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private StreamAssistant streamAssistant;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 聊天</span><br><span class="line">     */</span><br><span class="line">    @PostMapping(&quot;/chat&quot;)</span><br><span class="line">    public String chat(@RequestBody ChatFormDTO chatFormDTO)&#123;</span><br><span class="line">        return separateChatAssistant.chat(chatFormDTO.getMemoryId(), </span><br><span class="line">                                          chatFormDTO.getMessage());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 流式聊天</span><br><span class="line">     */</span><br><span class="line">    @PostMapping(&quot;/streamChat&quot;)</span><br><span class="line">    public Flux&lt;String&gt; streamChat(@RequestBody ChatFormDTO chatFormDTO)&#123;</span><br><span class="line">        return streamAssistant.chat(chatFormDTO.getMemoryId(), </span><br><span class="line">                                    chatFormDTO.getMessage());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第五步，启动项目进行测试。访问如下地址，获取接口文档：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/doc.html</span><br></pre></td></tr></table></figure><p>然后我们点击对应的chat测试接口：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761468911394-ac96f83d-11d0-4862-8a89-0a7dd8bf205f.png"></p><p>再来看一下流式输出接口：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761468943199-68f03fb3-2f9e-4244-823f-637d57d86424.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;向量存储&quot;&gt;&lt;a href=&quot;#向量存储&quot; class=&quot;headerlink&quot; title=&quot;向量存储&quot;&gt;&lt;/a&gt;向量存储&lt;/h1&gt;&lt;h2 id=&quot;主流向量数据库对比&quot;&gt;&lt;a href=&quot;#主流向量数据库对比&quot; class=&quot;headerlink&quot; title=</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>LangChain4j之向量模型</title>
    <link href="http://aichating.xyz/2025/10/11/2025-17-lang-chain-4j-8-vector-model/"/>
    <id>http://aichating.xyz/2025/10/11/2025-17-lang-chain-4j-8-vector-model/</id>
    <published>2025-10-11T06:01:20.000Z</published>
    <updated>2025-10-12T12:31:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="向量模型"><a href="#向量模型" class="headerlink" title="向量模型"></a>向量模型</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>这里我们以通用文本向量为例进行说明，它是通义实验室开发的基于LLM的多语言统一文本向量模型，支持多个主流语种，为文本类数据提供高效的向量化转换服务，适用于RAG、文本分类、情感分析等自然语言处理任务。</p><p>点击 <a href="https://help.aliyun.com/zh/model-studio/text-embedding-synchronous-api">这里</a>，了解更多介绍。</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761358349179-489ab70b-d46c-4479-9779-12c8ccdd27b0.png"></p><p>这里我们使用通用文本向量 text-embedding-v3，维度1024进行介绍，请注意，维度越多，对事务的描述越精准，信息检索的精度就越高。点击 <a href="https://docs.langchain4j.dev/category/embedding-models/">这里</a>，查看langchain4j所支持的向量模型。</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761358531335-a9cacaf2-630c-4eec-af26-981d92bfe6d3.png"></p><h2 id="模型配置"><a href="#模型配置" class="headerlink" title="模型配置"></a>模型配置</h2><h3 id="阿里云百炼"><a href="#阿里云百炼" class="headerlink" title="阿里云百炼"></a>阿里云百炼</h3><p>第一步，在项目的pom文件中引入对DashScope embedding的依赖：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 接入阿里云百炼平台 --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;langchain4j-community-dashscope-spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependencyManagement&gt;</span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;!--引入阿里云百炼平台管理清单--&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;langchain4j-community-bom&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;$&#123;langchain4j.version&#125;&lt;/version&gt;</span><br><span class="line">            &lt;type&gt;pom&lt;/type&gt;</span><br><span class="line">            &lt;scope&gt;import&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line">&lt;/dependencyManagement&gt;</span><br></pre></td></tr></table></figure><p>第二步，在项目的application.properties配置文件中新增如下配置项：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 配置阿里通义千问向量模型</span><br><span class="line">langchain4j.community.dashscope.embedding-model.api-key=你的key</span><br><span class="line">langchain4j.community.dashscope.embedding-model.model-name=text-embedding-v3</span><br></pre></td></tr></table></figure><p>第三步，修改EmbeddingController中的代码为如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">@Slf4j</span><br><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/embedding&quot;)</span><br><span class="line">public class EmbeddingController &#123;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private EmbeddingModel embeddingModel;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 测试向量模型</span><br><span class="line">     */</span><br><span class="line">    @GetMapping(&quot;/testEmbeddingModel&quot;)</span><br><span class="line">    public String testEmbeddingModel()&#123;</span><br><span class="line">        String text = &quot;你好&quot;;</span><br><span class="line">        Response&lt;Embedding&gt; response = embeddingModel.embed(text);</span><br><span class="line">        log.info(&quot;向量：&#123;&#125;&quot;,response.content().vector().length);</span><br><span class="line">        log.info(&quot;向量维度：&#123;&#125;&quot;,response.content().dimension());</span><br><span class="line">        log.info(&quot;token用量：&#123;&#125;&quot;,response.tokenUsage());</span><br><span class="line">        log.info(&quot;finishReason：&#123;&#125;&quot;,response.finishReason());</span><br><span class="line">        log.info(&quot;向量输出：&#123;&#125;&quot; ,response);</span><br><span class="line">        return response.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第四步，访问如下链接，即可出现对应信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/embedding/testEmbeddingModel</span><br></pre></td></tr></table></figure><h3 id="Ollama"><a href="#Ollama" class="headerlink" title="Ollama"></a>Ollama</h3><p>第一步，在ollama官网搜索支持embedding的模型，然后下载该模型：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761358764998-67c7ab43-9e62-4dd0-bd66-2c2d960a5b08.png"></p><p>我选择了0.6b，对应的命令为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama pull qwen3-embedding:0.6b</span><br></pre></td></tr></table></figure><p>第二步，在项目的pom文件中引入对Ollama embedding的依赖：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 集成ollama --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;langchain4j-ollama&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.0.0-beta3&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>第三步，在项目的application.properties配置文件中新增如下配置项：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># ollama embeddingModel</span><br><span class="line">langchain4j.ollama.embedding-model.base-url=http://localhost:11434</span><br><span class="line">langchain4j.ollama.embedding-model.model-name=qwen3-embedding:0.6b</span><br><span class="line">langchain4j.ollama.embedding-model.timeout=PT60S</span><br><span class="line">langchain4j.ollama.embedding-model.log-requests=true</span><br><span class="line">langchain4j.ollama.embedding-model.log-responses=true</span><br></pre></td></tr></table></figure><p>第四步，修改EmbeddingController中的代码为如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">@Slf4j</span><br><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/embedding&quot;)</span><br><span class="line">public class EmbeddingController &#123;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private OllamaEmbeddingModel ollamaEmbeddingModel;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 测试向量模型</span><br><span class="line">     */</span><br><span class="line">    @GetMapping(&quot;/testEmbeddingModel&quot;)</span><br><span class="line">    public String testEmbeddingModel()&#123;</span><br><span class="line">        String text = &quot;你好&quot;;</span><br><span class="line">        Response&lt;Embedding&gt; response = ollamaEmbeddingModel.embed(text);</span><br><span class="line">        log.info(&quot;向量：&#123;&#125;&quot;,response.content().vector().length);</span><br><span class="line">        log.info(&quot;向量维度：&#123;&#125;&quot;,response.content().dimension());</span><br><span class="line">        log.info(&quot;token用量：&#123;&#125;&quot;,response.tokenUsage());</span><br><span class="line">        log.info(&quot;finishReason：&#123;&#125;&quot;,response.finishReason());</span><br><span class="line">        log.info(&quot;向量输出：&#123;&#125;&quot; ,response);</span><br><span class="line">        return response.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第五步，访问如下链接：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/embedding/testEmbeddingModel</span><br></pre></td></tr></table></figure><p>打开控制台，输出如下信息：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761359133484-3b77b91e-6b3b-40df-afe0-58c84e931370.png"></p><p>查看一下页面，显示如下信息：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1761359165565-db66e518-e790-4e0b-8dc2-87ea79f802be.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;向量模型&quot;&gt;&lt;a href=&quot;#向量模型&quot; class=&quot;headerlink&quot; title=&quot;向量模型&quot;&gt;&lt;/a&gt;向量模型&lt;/h1&gt;&lt;h2 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>LangChain4j之函数调用(Function Calling)</title>
    <link href="http://aichating.xyz/2025/09/28/2025-16-lang-chain-4j-7-function-calling/"/>
    <id>http://aichating.xyz/2025/09/28/2025-16-lang-chain-4j-7-function-calling/</id>
    <published>2025-09-28T06:01:20.000Z</published>
    <updated>2025-09-28T12:31:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="函数调用（Function-Calling）"><a href="#函数调用（Function-Calling）" class="headerlink" title="函数调用（Function Calling）"></a>函数调用（Function Calling）</h1><p>function calling函数调用，也叫Tools工具。</p><h2 id="入门案例"><a href="#入门案例" class="headerlink" title="入门案例"></a>入门案例</h2><p>大语言模型本身并不擅长数学运算，实际上很多应用场景都会涉及到数学计算，因此我们可以为它提供一个“数学工具”。<strong>当我们提出问题时，大语言模型会判断是否使用某个工具</strong>。</p><h2 id="注解介绍"><a href="#注解介绍" class="headerlink" title="注解介绍"></a>注解介绍</h2><p>（1）【@Tool注解】通过在方法上添加@Tool注解，并在构建 AI 服务时显式指定这些工具，这样LLM可以根据用户的请求决定是否调用相应的工具方法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@Retention(RetentionPolicy.RUNTIME)</span><br><span class="line">@Target(&#123;ElementType.METHOD&#125;)</span><br><span class="line">public @interface Tool &#123;</span><br><span class="line">    String name() default &quot;&quot;;</span><br><span class="line"></span><br><span class="line">    String[] value() default &#123;&quot;&quot;&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在Tool注解中有两个可选的属性：</p><ul><li><code>name</code>（可选）：指定工具的<strong>名称</strong>。如果未提供，默认使用方法名。</li><li><code>value</code>（可选）：提供工具的<strong>描述</strong>，有助于LLM更好地理解工具的用途。</li></ul><p>（2）【@P注解】此外，还可以使用<code>@P</code>注解为<strong>方法参数添加描述</strong>，用于增强LLM对参数含义的理解：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@Retention(RetentionPolicy.RUNTIME)</span><br><span class="line">@Target(&#123;ElementType.PARAMETER&#125;)</span><br><span class="line">public @interface P &#123;</span><br><span class="line">    String value();</span><br><span class="line"></span><br><span class="line">    boolean required() default true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在Tool注解中有两个属性，其中value是必填字段，required是可选字段：</p><ul><li><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;value&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);">：</font>参数的描述信息，这是必填字段。</li><li><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;required&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);">：</font>表示该参数是否为必需项，默认值为 true ，此为可选字段。</li></ul><p>(3)【@ToolMemoryId注解】当你的AIService方法中有一个参数使用了@MemoryId注解，那么就可以使用@ToolMemoryId注解，作为@Tool注解中的一个参数。@ToolMemoryId注解用于在工具方法的参数上，指定用于关联对话上下文的内存标识符（memoryID）。</p><p>提供给AIService方法的memoryID将自动传递给@Tool方法，如果你有多个用户，或每个用户有多个聊天记忆，并且希望在@Tool方法中对它们进行区分，那么这个功能会很有用。</p><h2 id="函数调用流程"><a href="#函数调用流程" class="headerlink" title="函数调用流程"></a>函数调用流程</h2><p>函数调用的流程如下：</p><ol><li><code>LLM</code> 接收用户输入；</li><li>第一次调用大模型时，判断是否需要调用工具方法；</li><li>如果需要，那么第二次调用大模型，调用相应的<code>@Tool</code>方法，并获取返回结果；</li><li>将工具方法的返回结果作为对话的一部分，继续与用户交互。</li></ol><h2 id="创建工具类"><a href="#创建工具类" class="headerlink" title="创建工具类"></a>创建工具类</h2><p>新建一个名为tools的包，并在里面定义一个名为MathTools的类，在里面我们定义了三个方法，分别用于求和、求差和求平方根：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">@Slf4j</span><br><span class="line">@Component</span><br><span class="line">public class MathTools &#123;</span><br><span class="line"></span><br><span class="line">    @Tool(name = &quot;加法&quot;,  value = &quot;计算两个数之和&quot;)</span><br><span class="line">    public double add(@ToolMemoryId int memoryId,</span><br><span class="line">                      @P(value = &quot;加数1&quot;, required = true) double a,</span><br><span class="line">                      @P(value = &quot;加数2&quot;, required = true) double b )&#123;</span><br><span class="line">        log.info(&quot;调用加法运算，运算的memoryId:&#123;&#125;&quot;,memoryId);</span><br><span class="line">        return a + b;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Tool(name = &quot;减法&quot;,  value = &quot;计算两个数之差&quot;)</span><br><span class="line">    public double sub(@ToolMemoryId int memoryId,</span><br><span class="line">                      @P(value = &quot;减数&quot;, required = true) double a,</span><br><span class="line">                      @P(value = &quot;被减数&quot;, required = true) double b )&#123;</span><br><span class="line">        log.info(&quot;调用减法运算，运算的memoryId:&#123;&#125;&quot;,memoryId);</span><br><span class="line">        return a - b;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Tool(name = &quot;平方根&quot;,  value = &quot;计算给定参数的平方根&quot;)</span><br><span class="line">    public double sqrt(@ToolMemoryId int memoryId,</span><br><span class="line">                      double a )&#123;</span><br><span class="line">        log.info(&quot;调用平方根运算，运算的memoryId:&#123;&#125;&quot;,memoryId);</span><br><span class="line">        return Math.sqrt(a);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="给Assistant配置工具类"><a href="#给Assistant配置工具类" class="headerlink" title="给Assistant配置工具类"></a>给Assistant配置工具类</h2><p>回到SeparateChatAssistant类中，我们修改@AiService注解的值，并在里面设置tools属性，然后添加一个测试方法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@AiService(wiringMode = AiServiceWiringMode.EXPLICIT,</span><br><span class="line">        chatModel = &quot;ollamaChatModel&quot;, chatMemoryProvider = &quot;chatMemoryProvider&quot;,</span><br><span class="line">        tools = &quot;mathTools&quot;</span><br><span class="line">)</span><br><span class="line">public interface SeparateChatAssistant &#123;</span><br><span class="line">    @SystemMessage(&quot;你是我的好朋友，请用四川话回答问题。&quot;)</span><br><span class="line">    String chatTool(@MemoryId int memoryId , @UserMessage String userMessage);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>tools属性的值为mathTools，也就是工具类在Spring容器中Bean的名称，之后新增一个chatTool方法。</p><h2 id="创建测试接口"><a href="#创建测试接口" class="headerlink" title="创建测试接口"></a>创建测试接口</h2><p>接着在PromptController类中定义一个名为promptTool的方法，里面的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/prompt&quot;)</span><br><span class="line">public class PromptController &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    private SeparateChatAssistant separateChatAssistant;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 测试提示词调用函数调用</span><br><span class="line">     */</span><br><span class="line">    @GetMapping(&quot;/promptTool&quot;)</span><br><span class="line">    public String promptTool()&#123;</span><br><span class="line">        return separateChatAssistant.chatTool(6,&quot;6+9等于多少？98-17等于多少？255的平方根是多少？&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="启动项目进行测试"><a href="#启动项目进行测试" class="headerlink" title="启动项目进行测试"></a>启动项目进行测试</h2><p>启动项目，访问如下地址：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/prompt/promptTool</span><br></pre></td></tr></table></figure><p>页面报错了，查看一下控制台，输出如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760862381818-cd16a384-87d4-49a2-af97-9167264fac03.png"></p><p>意思就是deepseek-r1:1.5b这个模型不支持函数调用，那么我们可以切换到qwen3:1.7b，修改application.properties配置文件中的参数，然后重新启动项目并进行访问，结果如下所示：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760862220554-0154337b-fd7f-47f6-9982-54ffedd90f56.png"></p><p>查看一下数据库，可以发现也存有这条记录了，同时显示了提示词的类型：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760862235009-051428db-bad4-4c20-a025-42eda5c02f06.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;函数调用（Function-Calling）&quot;&gt;&lt;a href=&quot;#函数调用（Function-Calling）&quot; class=&quot;headerlink&quot; title=&quot;函数调用（Function Calling）&quot;&gt;&lt;/a&gt;函数调用（Function Callin</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>LangChain4j之检索生成增强(RAG)</title>
    <link href="http://aichating.xyz/2025/09/13/2025-15-lang-chain-4j-6-rag/"/>
    <id>http://aichating.xyz/2025/09/13/2025-15-lang-chain-4j-6-rag/</id>
    <published>2025-09-13T10:01:20.000Z</published>
    <updated>2025-09-14T12:31:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="如何让大模型回答专业领域知识"><a href="#如何让大模型回答专业领域知识" class="headerlink" title="如何让大模型回答专业领域知识"></a>如何让大模型回答专业领域知识</h1><p>LLM的知识仅限于它所训练的数据，如果你想让LLM了解特定领域的知识或专有数据，你可以：</p><ul><li>使用RAG；</li><li>使用你的数据微调LLM；</li><li>结合RAG和微调LLM。</li></ul><h2 id="大模型微调"><a href="#大模型微调" class="headerlink" title="大模型微调"></a>大模型微调</h2><p>在现有大模型的基础上，使用小规模的特定任务数据进行再次训练，调整模型参数，让模型更精确地处理特定领域或任务的数据。更新需重新训练，计算资源和时间成本高。</p><ul><li><strong>优点</strong>：一次会话只需一次模型调用，速度快，在特定任务上性能更高，准确性也更高。</li><li><strong>缺点</strong>：知识更新不及时，模型训成本高、训练周期长。</li><li><strong>应用场景</strong>：适合知识库稳定、对生成内容准确性和风格要求高的场景，如对上下文理解和语言生成质量要求高的文学创作、专业文档生成等。</li></ul><h2 id="RAG介绍"><a href="#RAG介绍" class="headerlink" title="RAG介绍"></a>RAG介绍</h2><p>（1）RAG其实是三个单词的缩写，分别是<strong>Retrieval-Augmented-Generation</strong>，即检索增强生成。</p><p>（2）在将原始问题以及提示词信息发送给大语言模型之前，先通过外部知识库检索相关信息，然后将检索结果和原始问题一起发送给大模型，大模型依据外部知识库再结合自身的训练数据，组织自然语言回答问题。通过这种方式，大语言模型可以获取到特定领域的相关信息，并能够利用这些信息进行回复。</p><ul><li><strong>优点</strong>：数据存储在外部知识库，可以实时更新，不依赖对模型自身的训练，成本更低。</li><li><strong>缺点</strong>：需要两次查询：先查询知识库，然后再查询大模型，性能不如微调大模型。</li><li><strong>应用场景</strong>：适用于知识库规模大且频繁更新的场景，如企业客服、实时新闻查询、法律和医疗领域的最新知识问答等。</li></ul><h2 id="RAG常用方法"><a href="#RAG常用方法" class="headerlink" title="RAG常用方法"></a>RAG常用方法</h2><p>RAG有三种常用方法，分别是全文搜索、向量搜索和混合搜索。</p><p>（1）全文搜索，也被称为“关键词搜索”。通过将问题和提示词中的关键词，与知识库文档数据库进行匹配，来搜索文档，然后根据这些关键词在每个文档中的出现频率和相关性对搜索结果进行排序。</p><p>（2）向量搜索，也被称为 “语义搜索”。文本通过“嵌入模型”被转换为“数字向量”，然后它根据查询向量与文档向量之间的余弦相似度或其他相似性/距离度量，来查找和排序文档，从而捕捉更深层次的语义含义。</p><p>（3）混合搜索。结合多种搜索方法（如全文搜索 + 向量搜索）通常可以提高搜索的效果。</p><h1 id="向量搜索（Vector-Search）"><a href="#向量搜索（Vector-Search）" class="headerlink" title="向量搜索（Vector Search）"></a>向量搜索（Vector Search）</h1><h2 id="向量（Vector）"><a href="#向量（Vector）" class="headerlink" title="向量（Vector）"></a>向量（Vector）</h2><p>可以将向量理解为从空间中的一个点到另一个点的移动。举个例子，在下图中，我们可以看到一些二维空间中的向量。a是一个从 (100, 50) 到 (-50, -50) 的向量，b是一个从 (0, 0) 到 (100, -50) 的向量。</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760864186830-68f1b358-210d-4bd1-8aca-76182fa4dfb2.png"></p><p>很多时候，我们处理的向量是从原点 (0, 0) 开始的，比如b。这样我们可以省略向量起点部分，直接说b是向量 (100, -50)。那么问题来了，如何将向量的概念扩展到非数值实体上呢（如文本）？</p><h2 id="维度（Dimensions）"><a href="#维度（Dimensions）" class="headerlink" title="维度（Dimensions）"></a>维度（Dimensions）</h2><p>（1）正如我们所见，每个数值向量都有x和y坐标（或者在多维系统中是 x、y、z，…），其中x、y、z… 是这个向量空间的轴，称为维度。</p><p>（2）对于我们想要表示为向量的一些非数值实体，我们首先需要决定这些维度，并为每个实体在每个维度上分配一个值。</p><p>举个例子，在一个交通工具数据集中，我们可以定义四个维度：“轮子数量”、“是否有发动机”、“是否可以在地上开动”和“最大乘客数”，然后我们可以将一些车辆表示为：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760864422007-87bebeb6-52a1-423b-9344-44bfdb2394c3.png"></p><p>这样汽车Car向量将是 (4, yes, yes, 5)，或者用数值表示为 (4, 1, 1, 5)（将 yes 设为 1，no 设为 0）。</p><p>（3）向量的每个维度代表数据的不同特性，维度越多对事务的描述越精确，我们可以使用“是否有翅膀”、“是否使用柴油”、“最高速度”、“平均重量”、“价格”等等更多的维度信息。</p><h2 id="相似度（Similarity）"><a href="#相似度（Similarity）" class="headerlink" title="相似度（Similarity）"></a>相似度（Similarity）</h2><p>如果用户搜索“轿车Car”，你希望能够返回所有与“汽车automobile”和“车辆vehicle”等信息相关的结果，那么可以使用向量搜索。</p><p><strong>如何确定哪些是最相似的？</strong>我们知道每个向量都有一个长度和方向。在下图中，p 和 a 指向相同的方向，但长度不同。p 和 b 正好指向相反的方向，但有相同的长度。然后还有c，长度比p短一点，方向不完全相同，但很接近。那么问题来了，哪一个最接近 p 呢？</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760864628950-0ebb8e9b-ac4d-4d28-995a-024861b9d6f7.png"></p><p>如果“相似”仅仅意味着指向相似的方向，那么a是最接近p的。接下来是 c。b是最不相似的，因为它正好指向与p相反的方向。如果“相似”仅仅意味着相似的长度，那么 b 是最接近 p 的（因为它有相同的长度），接下来是 c，然后是 a。</p><p>由于向量通常用于描述语义意义，仅仅看长度通常无法满足需求。<strong>大多数相似度测量要么仅依赖于方向，要么同时考虑方向和大小。</strong></p><h2 id="相似度测量（Measures-of-similarity）"><a href="#相似度测量（Measures-of-similarity）" class="headerlink" title="相似度测量（Measures of similarity）"></a>相似度测量（Measures of similarity）</h2><p>相似度测量即相似度计算，四种常见的向量相似度计算方法如下：</p><ul><li>欧几里得距离 Euclidean distance；</li><li>曼哈顿距离 Manhattan distance；</li><li>点积 Dot product；</li><li>余弦相似度 Cosine similarity。</li></ul><h1 id="RAG的过程"><a href="#RAG的过程" class="headerlink" title="RAG的过程"></a>RAG的过程</h1><p>RAG过程分为两个不同的阶段，分别是索引阶段和检索阶段。</p><h2 id="索引阶段"><a href="#索引阶段" class="headerlink" title="索引阶段"></a>索引阶段</h2><p> 在索引阶段，对知识库文档进行预处理，可实现检索阶段的高效搜索。以下是索引阶段的简化图：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760864970418-00a759bb-23d3-42f6-83d7-27c256846ad5.png"></p><p>索引阶段的流程如下：</p><p>（1）加载知识库文档；</p><p>（2）将文档中的<strong>文本分段</strong>；</p><p>（3）利用<strong>向量大模型</strong>将分段后的<strong>文本转换成向量</strong>；</p><p>（4） 将向量<strong>存入向量数据库</strong>。</p><p>什么要进行文本分段？因为大语言模型（LLM）的上下文窗口有限，所以整个知识库可能无法全部容纳其中：</p><ul><li>你在提问中提供的信息越多，大语言模型处理并做出回应所需的时间就越长；</li><li>你在提问中提供的信息越多，花费也就越多；</li><li>提问中的无关信息可能会干扰大语言模型，增加产生幻觉（生成错误信息）的几率</li></ul><p>针对上述问题，我们可以通过将知识库分割成更小、更易于理解的片段来进行解决。</p><h2 id="检索阶段"><a href="#检索阶段" class="headerlink" title="检索阶段"></a>检索阶段</h2><p>以下是检索阶段的简化图：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760865262462-6c917757-78d8-48bf-89dd-3be77980b422.png"></p><p>检索阶段的流程如下：</p><p>（1）通过向量模型将用户查询转换成向量；</p><p>（2）在向量数据库中根据用户查询进行相似度匹配；</p><p>（3）将用户查询和向量数据库中匹配到的相关内容一起交给LLM处理.</p><h1 id="文档加载器（Document-Loader）"><a href="#文档加载器（Document-Loader）" class="headerlink" title="文档加载器（Document Loader）"></a>文档加载器（Document Loader）</h1><h2 id="常见的文档加载器"><a href="#常见的文档加载器" class="headerlink" title="常见的文档加载器"></a>常见的文档加载器</h2><p>点击 <a href="https://docs.langchain4j.dev/category/document-loaders">这里</a>，阅读langchain4j对于文档加载器的说明文档：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760865487553-ddc8ea10-a972-4f03-b6c5-b8b0ad833fdc.png"></p><p>（1）langchain4j 模块的类路径文档加载器（ClassPathDocumentLoader）；</p><p>（2）langchain4j 模块的网址文档加载器（UrlDocumentLoader）；</p><p>（3）langchain4j-document-loader-amazon-s3 模块的亚马逊 S3 文档加载器（AmazonS3DocumentLoader）；</p><p>（4）langchain4j-document-loader-azure-storage-blob 模块的 Azure Blob 存储文档加载器（AzureBlobStorageDocumentLoader）；</p><p>（5）langchain4j-document-loader-github 模块的 GitHub 文档加载器（GitHubDocumentLoader）；</p><p>（6）langchain4j-document-loader-google-cloud-storage 模块的谷歌云存储文档加载器（GoogleCloudStorageDocumentLoader）；</p><p>（7）langchain4j-document-loader-selenium 模块的 Selenium 文档加载器（SeleniumDocumentLoader）；</p><p>（8）langchain4j-document-loader-tencent-cos 模块的腾讯云对象存储文档加载器（TencentCosDocumentLoader）。</p><h2 id="测试文档加载"><a href="#测试文档加载" class="headerlink" title="测试文档加载"></a>测试文档加载</h2><p>这里我们以langchain4j模块的类路径文档加载器，即ClassPathDocumentLoader为例进行学习。</p><p>在controller包内定义一个名为FileController的类，里面的代码如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/file&quot;)</span><br><span class="line">public class FileController &#123;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 使用FileSystemDocumentLoader读取指定目录下的知识库文档</span><br><span class="line">     * 并使用默认的文档解析器TextDocumentParser对文档进行解析</span><br><span class="line">     */</span><br><span class="line">    @GetMapping(&quot;/readOne&quot;)</span><br><span class="line">    public String readOne()&#123;</span><br><span class="line">        String filePath = &quot;E:/Files/langchain4j/files/langchain4j.txt&quot;;</span><br><span class="line">        Document document = FileSystemDocumentLoader.loadDocument(filePath);</span><br><span class="line">        return document.text();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 从一个目录中加载所有文档</span><br><span class="line">     */</span><br><span class="line">    @GetMapping(&quot;/reaAll&quot;)</span><br><span class="line">    public String reaAll()&#123;</span><br><span class="line">        String filePath = &quot;E:/Files/langchain4j/files&quot;;</span><br><span class="line">        List&lt;Document&gt; documents = FileSystemDocumentLoader.loadDocuments(filePath, </span><br><span class="line">                                                          new TextDocumentParser());</span><br><span class="line">        return documents.size() + &quot;&quot;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 从一个目录中加载所有的.txt文档</span><br><span class="line">     */</span><br><span class="line">    @GetMapping(&quot;/reaAllText&quot;)</span><br><span class="line">    public String reaAllText()&#123;</span><br><span class="line">        PathMatcher pathMatcher = FileSystems.getDefault().getPathMatcher(&quot;glob:*.txt&quot;);</span><br><span class="line">        String filePath = &quot;E:/Files/langchain4j/files&quot;;</span><br><span class="line">        List&lt;Document&gt; documents = FileSystemDocumentLoader.loadDocumentsRecursively(</span><br><span class="line">                                        filePath,pathMatcher, new TextDocumentParser());</span><br><span class="line">        return documents.size() + &quot;&quot;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 从一个目录及其子目录中加载所有文档</span><br><span class="line">     */</span><br><span class="line">    @GetMapping(&quot;/reaAllFile&quot;)</span><br><span class="line">    public String reaAllFile()&#123;</span><br><span class="line">        String filePath = &quot;E:/Files/langchain4j/&quot;;</span><br><span class="line">        List&lt;Document&gt; documents = FileSystemDocumentLoader.loadDocumentsRecursively(</span><br><span class="line">                                                   filePath, new TextDocumentParser());</span><br><span class="line">        return documents.size() + &quot;&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后创建E:/Files/langchain4j/files目录，在里面创建四个文件，分别是：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760867685003-74166c04-5f7c-46aa-82fe-3bf97eeceb01.png"></p><p>之后启动项目，开始测试。由于这里使用的是TextDocumentParser，即文本文档解析器，因此只能解析text格式的文件，所以后面三个接口返回的都是2。</p><p>访问如下接口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/file/readOne</span><br></pre></td></tr></table></figure><p>页面显示结果如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760867236956-e8ad7d06-8382-4a20-af74-1c173634108e.png"></p><p>访问后面三个接口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/file/reaAll</span><br><span class="line">http://localhost:8080/file/reaAllText</span><br><span class="line">http://localhost:8080/file/reaAllFile</span><br></pre></td></tr></table></figure><p>页面均返回如下，符合预期：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760867302864-9826ebe9-1402-44da-8e7a-938129edeffe.png"></p><h1 id="文档解析器（Document-Parser）"><a href="#文档解析器（Document-Parser）" class="headerlink" title="文档解析器（Document Parser）"></a>文档解析器（Document Parser）</h1><h2 id="常见的文档解析器"><a href="#常见的文档解析器" class="headerlink" title="常见的文档解析器"></a>常见的文档解析器</h2><p>点击 <a href="https://docs.langchain4j.dev/category/document-parsers">这里</a>，阅读langchain4j对于文档解析器的说明文档：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760867432832-c19a5f4d-f551-4cc3-a9f3-87d1c55469c4.png"></p><p>文档可以是各种格式的文件，如PDF、DOC、TXT 等，为了解析这些不同格式的文件，langchain4j提供了一个 “文档解析器”（DocumentParser）接口，并且我们的库中包含了该接口的几种实现方式：</p><p>（1）来自 langchain4j 模块的文本文档解析器（TextDocumentParser）：</p><ul><li><strong>用途</strong>：解析纯文本文件，如 <code>.txt</code>、<code>.md</code>、<code>.html</code> 等；</li><li><strong>特点</strong>：轻量级，适用于结构简单的文本内容。</li></ul><p>（2）来自 langchain4j-document-parser-apache-pdfbox 模块的 Apache PDFBox 文档解析器（ApachePdfBoxDocumentParser）：</p><ul><li><strong>用途</strong>：解析 PDF 文件；</li><li><strong>特点</strong>：能够提取 PDF 中的文本和元数据。</li></ul><p>（3）来自 langchain4j-document-parser-apache-poi 模块的 Apache POI 文档解析器（ApachePoiDocumentParser）：</p><ul><li><strong>用途</strong>：解析 Microsoft Office 文件，如 <code>.doc</code>、<code>.docx</code>、<code>.xls</code>、<code>.xlsx</code>、<code>.ppt</code>、<code>.pptx</code> 等。</li><li><strong>特点</strong>：支持提取 Office 文档中的文本内容。</li></ul><p>（4）来自 langchain4j-document-parser-apache-tika 模块的Apache Tika文档解析器（ApacheTikaDocumentParser）：</p><ul><li><strong>用途</strong>：通用解析器，支持多种文件格式。</li><li><strong>特点</strong>：能够自动检测文件类型并解析，适用于处理多种格式的文档。</li></ul><h2 id="添加PDF解析依赖"><a href="#添加PDF解析依赖" class="headerlink" title="添加PDF解析依赖"></a>添加PDF解析依赖</h2><p>现在我们希望能解析PDF文档，那么默认的TextDocumentParser类就无法做到了，此时可以使用langchain4j提供的langchain4j-document-parser-apache-pdfbox模块来实现。</p><p>点击 <a href="https://docs.langchain4j.dev/integrations/document-parsers/apache-pdfbox">这里</a>，获取上述模块的依赖信息：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760867837197-a478e834-5e9c-4d72-9a05-3f2131a52272.png"></p><p>在pom文件中新增如下依赖，修改为适合你自己的版本：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- langchain4j文档解析器 --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;langchain4j-document-parser-apache-pdfbox&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.0.0-beta3&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><h2 id="测试文档解析"><a href="#测试文档解析" class="headerlink" title="测试文档解析"></a>测试文档解析</h2><p>这里我们以 langchain4j-document-parser-apache-pdfbox 模块的 Apache PDFBox 文档解析器（ApachePdfBoxDocumentParser），为例进行学习。</p><p>回到FileController的类，在里面定义一个名为parsePdf的方法，里面的代码如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/file&quot;)</span><br><span class="line">public class FileController &#123;</span><br><span class="line">    /**</span><br><span class="line">     *  解析pdf文件</span><br><span class="line">     */</span><br><span class="line">    @GetMapping(&quot;/parsePdf&quot;)</span><br><span class="line">    public String parsePdf()&#123;</span><br><span class="line">        String filePath = &quot;E:/Files/langchain4j/files/rag.pdf&quot;;</span><br><span class="line">        Document document = FileSystemDocumentLoader.loadDocument(filePath, </span><br><span class="line">                                         new ApachePdfBoxDocumentParser());</span><br><span class="line">        return document.text();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>之后启动项目，开始测试。访问如下接口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/file/parsePdf</span><br></pre></td></tr></table></figure><p>页面显示结果如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760868274820-3ab9aa6f-9baf-479b-8ad3-b3d87ef1b2e9.png"></p><p>说明pdf文档已经被成功解析了。</p><h1 id="文档分割器（Document-Splitter）"><a href="#文档分割器（Document-Splitter）" class="headerlink" title="文档分割器（Document Splitter）"></a>文档分割器（Document Splitter）</h1><h2 id="常见的文档分割器"><a href="#常见的文档分割器" class="headerlink" title="常见的文档分割器"></a>常见的文档分割器</h2><p>langchain4j提供了一个 “文档分隔器”（DocumentSplitter）接口，并且提供了几种开箱即用的实现方式：</p><p>（1）<code>DocumentByParagraphSplitter</code>：</p><ul><li><strong>功能</strong>：将<strong>文档按段落进行分割</strong>，段落通常由两个或更多连续的换行符定义。</li><li><strong>特点</strong>：适用于结构清晰、段落分明的文档，如新闻文章、博客等。</li></ul><p>（2）<code>DocumentBySentenceSplitter</code>：</p><ul><li><strong>功能</strong>：<strong>基于句子进行分割，</strong>通常依赖于句子检测器（如 OpenNLP）来识别句子边界。</li><li><strong>特点</strong>：适用于需要精细语义控制的场景，如问答系统、摘要生成等。</li><li><strong>注意</strong>：需要引入相应的句子检测库作为依赖。</li></ul><p>（3）<code>RecursiveCharacterTextSplitte</code>：</p><ul><li><strong>功能</strong>：<strong>递归地按字符进行分割</strong>，优先在自然的分隔符（如段落、句子、空格）处进行分割，以保持语义完整性。</li><li><strong>特点</strong>：推荐的默认分割器，适用于大多数通用文本。</li></ul><p>（4）<code>CharacterTextSplitter</code>：</p><ul><li><strong>功能</strong>：<strong>按固定的字符数进行分割</strong>，适用于结构简单、语义不太复杂的文本。</li><li><strong>特点</strong>：实现简单，但可能会打断语义完整性。</li></ul><p>（5）<code>TokenTextSplitter</code>：</p><ul><li><strong>功能</strong>：<strong>基于标记（Token）进行分割</strong>，适用于需要控制模型输入长度的场景。</li><li><strong>特点</strong>：有助于防止超过语言模型的上下文窗口限制。</li></ul><p>（6）<code>MarkdownHeaderTextSplitter</code>：</p><ul><li><strong>功能</strong>：<strong>基于 Markdown 文档的标题结构进行分割</strong>，保留标题元数据。</li><li><strong>特点</strong>：适用于结构化的 Markdown 文档，便于上下文感知的处理。</li></ul><p>除此之外，还有其他如按行文档分割器（DocumentByLineSplitter）、按单词文档分割器（DocumentByWordSplitter）、按字符文档分割器（DocumentByCharacterSplitter）、按正则表达式文档分割器（DocumentByRegexSplitter）。默认情况下每个文本片段最多不能超过300个token。</p><h2 id="测试文档分隔"><a href="#测试文档分隔" class="headerlink" title="测试文档分隔"></a>测试文档分隔</h2><p>这里我们以DocumentByCharacterSplitter为例，即按字符文档分割进行学习。</p><p>回到FileController的类，在里面定义一个名为testSplitter的方法，里面的代码如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/file&quot;)</span><br><span class="line">public class FileController &#123;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     *  测试文本分块</span><br><span class="line">     */</span><br><span class="line">    @GetMapping(&quot;/testSplitter&quot;)</span><br><span class="line">    public String testSplitter()&#123;</span><br><span class="line">        String filePath = &quot;E:/Files/langchain4j/files/langchain4j.txt&quot;;</span><br><span class="line">        Document document = FileSystemDocumentLoader.loadDocument(filePath, </span><br><span class="line">                                                          new TextDocumentParser());</span><br><span class="line">        // 创建一个文本分块器，将文本分块为多个段落</span><br><span class="line">        DocumentByCharacterSplitter splitter = new DocumentByCharacterSplitter(20,10);</span><br><span class="line">        splitter.split(document);</span><br><span class="line">        // 获取分块后的段落</span><br><span class="line">        List&lt;TextSegment&gt; segments = splitter.split(document);</span><br><span class="line">        return segments.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的DocumentByCharacterSplitter对象，有两个参数：</p><p>（1）maxSegmentSizeInChars：最大分割长度（chunk size）<font style="color:rgba(0, 0, 0, 0.85);">，即每个分割后的文档片段最多包含 20 个字符；</font></p><p>（2）maxOverlapSizeInChars：重叠长度（chunk overlap），即相<font style="color:rgba(0, 0, 0, 0.85);">邻两个片段之间重叠的字符数为 10，用于保持上下文连贯性。</font></p><p><font style="color:rgba(0, 0, 0, 0.85);"></font></p><p>然后修改E:/Files/langchain4j/files/langchain4j.txt文件中的内容为如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">欢迎学习Langchain4j!Langchain4j是Langchain的Java版本！</span><br><span class="line"></span><br><span class="line">Langchain官方只提供了Python和JS版本！</span><br><span class="line"></span><br><span class="line">Javaer只好学习Langchain4j。</span><br></pre></td></tr></table></figure><p>之后启动项目，开始测试。访问如下接口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/file/testSplitter</span><br></pre></td></tr></table></figure><p>页面显示结果如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760873753120-120bf4e5-1a06-471b-942a-a79839373541.png"></p><h2 id="向量生成和向量存储"><a href="#向量生成和向量存储" class="headerlink" title="向量生成和向量存储"></a>向量生成和向量存储</h2><p>（1）Embedding (Vector) Stores，即“嵌入（向量）存储” 。</p><p>（2）在机器学习和自然语言处理领域，Embedding指的是将数据（如文本、图像等）转换为低维稠密向量表示的过程，这些向量能够保留数据的关键特征。</p><p>（3）Stores表示存储，即用于存储这些嵌入向量的系统或工具。它们可以高效地存储和检索向量数据，支持向量相似性搜索，在文本检索、推荐系统、图像识别等任务中发挥着重要作用。</p><p>点击 <a href="https://docs.langchain4j.dev/integrations/embedding-stores/">这里</a>，查看Langchain4j支持的向量存储，如下所示：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760874485395-a94021e5-95eb-47c1-82f9-0caae26093b6.png"></p><p>这里我们先使用<code>langchain4j</code>自带的<code>RAG</code>简单实现，后面会学习<code>embedding</code>模型及向量数据库的选型。在pom文件中新增如下依赖：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--简单的rag实现--&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;langchain4j-easy-rag&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p><code>langchain4j-easy-rag</code>是LangChain4j提供的一个模块，该模块封装了文档解析、分割、嵌入生成和向量存储等复杂流程，使开发者能够更快速地搭建RAG系统。</p><h2 id="测试向量生成及存储"><a href="#测试向量生成及存储" class="headerlink" title="测试向量生成及存储"></a>测试向量生成及存储</h2><p>第一步，在controller包中定义一个名为EmbeddingController的类，在里面定义一个名为readAndStore的方法，里面的代码如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">@Slf4j</span><br><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/embedding&quot;)</span><br><span class="line">public class EmbeddingController &#123;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;/readAndStore&quot;)</span><br><span class="line">    public String readAndStore()&#123;</span><br><span class="line">        String filePath = &quot;E:/Files/langchain4j/files/langchain4j.txt&quot;;</span><br><span class="line">        // 加载文档</span><br><span class="line">        Document document = FileSystemDocumentLoader.loadDocument(filePath);</span><br><span class="line">        // 创建内存向量存储</span><br><span class="line">        InMemoryEmbeddingStore&lt;TextSegment&gt; embeddingStore = </span><br><span class="line">                                                       new InMemoryEmbeddingStore();</span><br><span class="line">        // 文档分割与嵌入生成</span><br><span class="line">        EmbeddingStoreIngestor.ingest(document, embeddingStore);</span><br><span class="line">        // 打印查看向量存储的内容</span><br><span class="line">        log.info(&quot;EmbeddingStore: &#123;&#125;&quot;, embeddingStore);</span><br><span class="line">        return embeddingStore.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>解释一下上述代码的含义：</p><p>（1）FileSystemDocumentLoader.loadDocument(filePath)，表示使用FileSystemDocumentLoader读取指定目录下的知识库文档，并使用默认的文档解析器对文档进行解析(TextDocumentParser)；</p><p>（2）<code>InMemoryEmbeddingStore&lt;TextSegment&gt;</code>是LangChain4j提供的一个轻量级、基于内存的向量存储实现；</p><p>（3）<code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;EmbeddingStoreIngestor.ingest(document, embeddingStore);&lt;/font&gt;</code> 方法执行了以下操作：</p><ol><li><strong>文档分割</strong>：默认使用递归分割器（<code>RecursiveCharacterTextSplitter</code>），将文档分割为多个文本片段（<code>TextSegment</code>）。每个片段的最大长度为 300 个 token，且相邻片段之间有 30 个 token 的重叠，以保持语义连贯性。请注意，当段落长度总和小于设定的最大长度时，就没有重叠的必要。</li><li><strong>嵌入生成</strong>：使用内置的轻量级嵌入模型（如 <code>BgeSmallEnV15QuantizedEmbeddingModel</code>：一个量化的英文嵌入模型，具有较小的向量维度，适合快速处理。）将每个文本片段转换为向量表示。</li><li><strong>向量存储</strong>：将原始文本和生成的向量存储到内存中的向量存储（<code>InMemoryEmbeddingStore</code>）中。</li></ol><p>第二步，启动项目，开始测试。访问如下接口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/file/readAndStore</span><br></pre></td></tr></table></figure><p>页面显示结果如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760875250504-fdd152f6-e507-4bb6-865b-ded30b6d3c0f.png"></p><h2 id="测试文档分隔及存储"><a href="#测试文档分隔及存储" class="headerlink" title="测试文档分隔及存储"></a>测试文档分隔及存储</h2><p>在EmbeddingController类中定义一个名为splitterAndStore的方法，里面的代码如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">@Slf4j</span><br><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/embedding&quot;)</span><br><span class="line">public class EmbeddingController &#123;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;/splitterAndStore&quot;)</span><br><span class="line">    public String splitterAndStore()&#123;</span><br><span class="line">        String filePath = &quot;E:/Files/langchain4j/files/langchain4j.txt&quot;;</span><br><span class="line">        // 加载文档</span><br><span class="line">        Document document = FileSystemDocumentLoader.loadDocument(filePath);</span><br><span class="line">        // 创建内存向量存储</span><br><span class="line">        InMemoryEmbeddingStore&lt;TextSegment&gt; embeddingStore = new InMemoryEmbeddingStore();</span><br><span class="line">        // 创建一个文本分块器，将文本分块为多个段落</span><br><span class="line">        DocumentByLineSplitter splitter = new DocumentByLineSplitter(300, 30);</span><br><span class="line">        // 文档分割与嵌入生成</span><br><span class="line">        EmbeddingStoreIngestor.builder()</span><br><span class="line">                        .embeddingStore(embeddingStore)</span><br><span class="line">                                .documentSplitter(splitter)</span><br><span class="line">                                        .build()</span><br><span class="line">                                              .ingest(document);</span><br><span class="line">        // 打印查看向量存储的内容</span><br><span class="line">        log.info(&quot;EmbeddingStore: &#123;&#125;&quot;, embeddingStore);</span><br><span class="line">        return embeddingStore.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>解释一下上述代码的含义：</p><p>（1）FileSystemDocumentLoader.loadDocument(filePath)，表示使用FileSystemDocumentLoader读取指定目录下的知识库文档，并使用默认的文档解析器对文档进行解析(TextDocumentParser)；</p><p>（2）<code>InMemoryEmbeddingStore&lt;TextSegment&gt;</code>是LangChain4j提供的一个轻量级、基于内存的向量存储实现；</p><p>（3）new DocumentByLineSplitter(300, 30)，表示按照行进行分隔，每个片段包含不超过 300个token，并且有 30个token的重叠部分保证连贯性。请注意，当段落长度总和小于设定的最大长度时，就没有重叠的必要。</p><p>（4）<code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;EmbeddingStoreIngestor.ingest(document, embeddingStore);&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);"> </font>方法执行了以下操作：</p><ol><li><strong>文档分割</strong>：默认使用递归分割器（<code>RecursiveCharacterTextSplitter</code>），将文档分割为多个文本片段（<code>TextSegment</code>）。每个片段的最大长度为 300 个 token，且相邻片段之间有 30 个 token 的重叠，以保持语义连贯性。</li><li><strong>嵌入生成</strong>：使用内置的轻量级嵌入模型（如 <code>BgeSmallEnV15QuantizedEmbeddingModel</code>：一个量化的英文嵌入模型，具有较小的向量维度，适合快速处理。）将每个文本片段转换为向量表示。</li><li><strong>向量存储</strong>：将原始文本和生成的向量存储到内存中的向量存储（<code>InMemoryEmbeddingStore</code>）中。</li></ol><p>第二步，启动项目，开始测试。访问如下接口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/file/splitterAndStore</span><br></pre></td></tr></table></figure><p>页面显示结果如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760876187756-9d817334-cdcf-4a7e-be3a-dce099f5a24a.png"></p><h2 id="token和token计算"><a href="#token和token计算" class="headerlink" title="token和token计算"></a>token和token计算</h2><p>点击 <a href="https://api-docs.deepseek.com/zh-cn/quick_start/token_usage">这里</a>，查看DeepSeek的Token用量计算：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760876505293-aa205d07-082f-4225-bac6-4f267980e515.png"></p><p>点击 <a href="https://bailian.console.aliyun.com/?spm=5176.29597918.J_SEsSjsNv72yRuRFS2VknO.2.18867ca0uXrEFa#/efm/model_experience_center">这里</a>，查看阿里百炼的计费规则。接下来我们在EmbeddingController类中定义一个名为tokenCount的方法，里面的代码如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">@GetMapping(&quot;/tokenCount&quot;)</span><br><span class="line">public String tokenCount()&#123;</span><br><span class="line">    String text = &quot;这是一个示例文本，用于测试 token 长度的计算。&quot;;</span><br><span class="line">    // 创建用户消息</span><br><span class="line">    UserMessage message = UserMessage.userMessage(text);</span><br><span class="line">    // 创建一个 HuggingFaceTokenizer 对象</span><br><span class="line">    HuggingFaceTokenizer  tokenizer = new HuggingFaceTokenizer();</span><br><span class="line">    // 计算文本的 token 长度</span><br><span class="line">    int tokenCount = tokenizer.estimateTokenCountInMessage(message);</span><br><span class="line">    return tokenCount + &quot;&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后启动项目，开始测试。访问如下接口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/file/tokenCount</span><br></pre></td></tr></table></figure><p>页面显示结果如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760877017437-2fb9455f-4406-4baf-8dbb-b03354012d00.png"></p><p>可以看到上述文本的token长度为20。</p><h2 id="工作方式"><a href="#工作方式" class="headerlink" title="工作方式"></a>工作方式</h2><p>（1）实例化一个“文档分割器”（DocumentSplitter），指定所需的“文本片段”（TextSegment）大小，并且可以选择指定characters或token的重叠部分。</p><p>（2）“文档分割器”（DocumentSplitter）将给定的文档（Document）分割成更小的单元，这些单元的性质因分割器而异。举个例子，“按段落分割文档器”（DocumentByParagraphSplitter）将文档分割成段落（由两个或更多连续的换行符定义），而 “按句子分割文档器”（DocumentBySentenceSplitter）使用OpenNLP库的句子检测器将文档分割成句子，依此类推。</p><p>（3）然后“文档分割器”（DocumentSplitter）将这些较小的单元（段落、句子、单词等）组合成“文本片段”（TextSegment），尝试在单个“文本片段”（TextSegment）中包含尽可能多的单元，同时不超过第一步中设置的限制。如果某些单元仍然太大，无法放入一个 “文本片段”（TextSegment）中，它会调用一个子分割器。这是另一个 “文档分割器”（DocumentSplitter），能够将不适合的单元分割成更细粒度的单元。会向每个文本片段添加一个唯一的元数据条目 “index”。第一个 “文本片段”（TextSegment）将包含 <code>index=0</code>，第二个是 <code>index=1</code>，依此类推。</p><p><strong>期望的文本片段大小</strong></p><ol><li><strong>模型上下文窗口</strong>：如果你使用的大语言模型（LLM）有特定的上下文窗口限制，这个值不能超过模型能够处理的最大 token 数。例如，某些模型可能最大只能处理 2048 个 token，那么设置的文本片段大小就需要远小于这个值，为后续的处理（如添加指令、其他输入等）留出空间。通常，在这种情况下，你可以设置为 1000 - 1500 左右，具体根据实际情况调整。<a href="https://bailian.console.aliyun.com/?tab=doc#/doc/?type=model&url=https%3A%2F%2Fhelp.aliyun.com%2Fdocument_detail%2F2840914.html">模型上下文窗口</a>，可以通过模型参数列表查看。</li><li><strong>数据特点</strong>：如果你的文档内容较为复杂，每个段落包含的信息较多，那么可以适当提高这个值，比如设置为 500 - 800 个 token，以便在一个文本片段中包含相对完整的信息块。相反，如果文档段落较短且信息相对独立，设置为 200 - 400 个 token 可能就足够了。</li><li><strong>检索需求</strong>：如果希望在检索时能够更精确地匹配到相关信息，较小的文本片段可能更合适，这样可以提高信息的粒度。例如设置为 200 - 300 个 token。但如果更注重获取完整的上下文信息，较大的文本片段（如 500 - 600 个 token）可能更有助于理解相关内容。</li></ol><p><strong>重叠部分大小</strong></p><ol><li><strong>上下文连贯性</strong>：重叠部分的主要作用是提供上下文连贯性，避免因分割导致信息缺失。如果文档内容之间的逻辑联系紧密，建议设置较大的重叠部分，如 50 - 100 个 token，以确保相邻文本片段之间的过渡自然，模型在处理时能够更好地理解上下文。</li><li><strong>数据冗余</strong>：然而，设置过大的重叠部分会增加数据的冗余度，可能导致处理时间增加和资源浪费。因此，需要在上下文连贯性和数据冗余之间进行平衡。一般来说，20 - 50 个 token 的重叠是比较常见的取值范围。</li><li><strong>模型处理能力</strong>：如果使用的模型对输入的敏感性较高，较小的重叠部分（如 20 - 30 个 token）可能就足够了，因为过多的重叠可能会引入不必要的干扰信息。但如果模型对上下文依赖较大，适当增加重叠部分（如 40 - 60 个 token）可能会提高模型的性能。</li></ol><p>通常来说，在处理一般性的文本资料，且使用的模型上下文窗口较大（如 4096 个 token）时，设置文本片段最大大小为600 - 800个token，重叠部分为30 - 50个token是一个不错的选择。但最终的设置还需要通过实验和实际效果评估来确定，以找到最适合具体应用场景的参数值。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;如何让大模型回答专业领域知识&quot;&gt;&lt;a href=&quot;#如何让大模型回答专业领域知识&quot; class=&quot;headerlink&quot; title=&quot;如何让大模型回答专业领域知识&quot;&gt;&lt;/a&gt;如何让大模型回答专业领域知识&lt;/h1&gt;&lt;p&gt;LLM的知识仅限于它所训练的数据，如果你想让</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>LangChain4j之提示词</title>
    <link href="http://aichating.xyz/2025/08/31/2025-14-lang-chain-4j-5-prompts/"/>
    <id>http://aichating.xyz/2025/08/31/2025-14-lang-chain-4j-5-prompts/</id>
    <published>2025-08-31T11:01:20.000Z</published>
    <updated>2025-08-31T12:31:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="提示词（Prompt）"><a href="#提示词（Prompt）" class="headerlink" title="提示词（Prompt）"></a>提示词（Prompt）</h1><p>所谓的提示词，就是告诉大模型的一些话，分为系统提示词、用户提示词和助理提示词：</p><ul><li>系统提示词（System）：定义模型的整体行为框架，包括角色定位、对话风格、知识范围等。例如设定模型为”专业医疗顾问”，需基于医学研究提供建议但不可替代诊断。</li><li>用户提示词（User）：明确用户的具体需求或问题，如”解释人工智能”。通过背景信息、限制条件等帮助模型精准回应。</li><li>助理提示词（Assistant）：基于用户和系统提示词生成回答，需保持风格一致。例如模型根据用户提问”什么是人工智能”生成解释性内容。</li></ul><p>三者共同作用确保输出符合预期：系统设定基调，用户提供具体指令，助理完成内容生成。</p><h2 id="系统提示词"><a href="#系统提示词" class="headerlink" title="系统提示词"></a>系统提示词</h2><p>系统提示词，即使用@SystemMessage注解来设定角色，塑造AI助手的专业身份，明确助手的能力范围：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)</span><br><span class="line">@Retention(RetentionPolicy.RUNTIME)</span><br><span class="line">public @interface SystemMessage &#123;</span><br><span class="line">    String[] value() default &#123;&quot;&quot;&#125;;  //系统提示词</span><br><span class="line"></span><br><span class="line">    String delimiter() default &quot;\n&quot;;  //分隔符</span><br><span class="line"></span><br><span class="line">    String fromResource() default &quot;&quot;;  //从资源中加载系统提示词</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="配置-SystemMessage"><a href="#配置-SystemMessage" class="headerlink" title="配置@SystemMessage"></a>配置@SystemMessage</h3><p>回到config包内，修改之前SeparateChatAssistant类中的代码为如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">@AiService(wiringMode = AiServiceWiringMode.EXPLICIT,</span><br><span class="line">        chatModel = &quot;ollamaChatModel&quot;, chatMemoryProvider = &quot;chatMemoryProvider&quot;)</span><br><span class="line">public interface SeparateChatAssistant &#123;</span><br><span class="line">    /**</span><br><span class="line">     * 分离聊天记录</span><br><span class="line">     * @param memoryId 聊天id</span><br><span class="line">     * @param userMessage 用户消息</span><br><span class="line">     */</span><br><span class="line">    @SystemMessage(&quot;你是我的好朋友，请用四川话回答问题。&quot;)  //系统消息提示词</span><br><span class="line">    String chat(@MemoryId int memoryId , @UserMessage String userMessage);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>@SystemMessage注解里配置的内容将在后台转换为SystemMessage对象，并与UserMessage一起发送给大语言模型（LLM）。请注意，@SystemMessage注解里的内容只会发送给大模型一次，如果开发者修改了SystemMessage的内容，那么新的SystemMessage会被发送给大模型，同时之前的聊天记忆将会失效（持久化的除外）。</p><h3 id="创建测试接口"><a href="#创建测试接口" class="headerlink" title="创建测试接口"></a>创建测试接口</h3><p>在controller包内创建一个名为PromptController的类，里面的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/prompt&quot;)</span><br><span class="line">public class PromptController &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    private SeparateChatAssistant separateChatAssistant;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 测试系统提示词</span><br><span class="line">     */</span><br><span class="line">    @GetMapping(&quot;/systemPrompt&quot;)</span><br><span class="line">    public String systemPrompt()&#123;</span><br><span class="line">        return separateChatAssistant.chat(3,&quot;吃啥子嘛?&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此时请求体如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">  &quot;model&quot; : &quot;deepseek-r1&quot;,</span><br><span class="line">  &quot;messages&quot; : [ &#123;</span><br><span class="line">    &quot;role&quot; : &quot;system&quot;,</span><br><span class="line">    &quot;content&quot; : &quot;你是我的好朋友，请用四川话回答问题。&quot;</span><br><span class="line">  &#125;, &#123;</span><br><span class="line">    &quot;role&quot; : &quot;user&quot;,</span><br><span class="line">    &quot;content&quot; : &quot;吃啥子嘛?&quot;</span><br><span class="line">  &#125; ],</span><br><span class="line">  &quot;stream&quot; : false</span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure><h3 id="启动项目进行测试"><a href="#启动项目进行测试" class="headerlink" title="启动项目进行测试"></a>启动项目进行测试</h3><p>启动项目，访问如下地址：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/prompt/systemPrompt</span><br></pre></td></tr></table></figure><p>结果如下所示：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760855796517-99ecb3ab-60cd-438a-85cd-48bdbb8c2310.png"></p><p>查看一下数据库，可以发现也存有这条记录了，同时显示了提示词的类型：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760855733451-4ea8ef14-a03d-4af6-a3f7-c016a57b80d6.png"></p><h3 id="添加当前时间"><a href="#添加当前时间" class="headerlink" title="添加当前时间"></a>添加当前时间</h3><p>如果希望显示今天的日期，那么需要在提示词中添加当前日期的占位符。修改SeparateChatAssistant类中的代码为如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">@AiService(wiringMode = AiServiceWiringMode.EXPLICIT,</span><br><span class="line">        chatModel = &quot;ollamaChatModel&quot;, chatMemoryProvider = &quot;chatMemoryProvider&quot;)</span><br><span class="line">public interface SeparateChatAssistant &#123;</span><br><span class="line">    /**</span><br><span class="line">     * 分离聊天记录</span><br><span class="line">     * @param memoryId 聊天id</span><br><span class="line">     * @param userMessage 用户消息</span><br><span class="line">     */</span><br><span class="line">    @SystemMessage(&quot;你是我的好朋友，请用四川话回答问题。今天是&#123;&#123;current_date&#125;&#125;&quot;)  //系统消息提示词</span><br><span class="line">    String chat(@MemoryId int memoryId , @UserMessage String userMessage);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同时PromptController类中的systemPrompt方法也修改为如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/prompt&quot;)</span><br><span class="line">public class PromptController &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    private SeparateChatAssistant separateChatAssistant;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 测试系统提示词</span><br><span class="line">     */</span><br><span class="line">    @GetMapping(&quot;/systemPrompt&quot;)</span><br><span class="line">    public String systemPrompt()&#123;</span><br><span class="line">        return separateChatAssistant.chat(3,&quot;今天几号？应该吃啥子嘛?&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="从资源中加载提示模板"><a href="#从资源中加载提示模板" class="headerlink" title="从资源中加载提示模板"></a>从资源中加载提示模板</h3><p>@SystemMessage注解还可以从资源中加载提示模板。在SeparateChatAssistant中新建一个名为chatFromResource的方法，里面的代码如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@AiService(wiringMode = AiServiceWiringMode.EXPLICIT,</span><br><span class="line">        chatModel = &quot;ollamaChatModel&quot;, chatMemoryProvider = &quot;chatMemoryProvider&quot;)</span><br><span class="line">public interface SeparateChatAssistant &#123;</span><br><span class="line">    /**</span><br><span class="line">     * 分离聊天记录</span><br><span class="line">     * @param memoryId 聊天id</span><br><span class="line">     * @param userMessage 用户消息</span><br><span class="line">     */</span><br><span class="line">    @SystemMessage(&quot;你是我的好朋友，请用四川话回答问题。今天是&#123;&#123;current_date&#125;&#125;&quot;)</span><br><span class="line">    String chat(@MemoryId int memoryId , @UserMessage String userMessage);</span><br><span class="line"></span><br><span class="line">    @SystemMessage(fromResource = &quot;prompts/assistant.txt&quot;)</span><br><span class="line">    String chatFromResource(@MemoryId int memoryId , @UserMessage String userMessage);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后创建 resources/prompts/assistant.txt 文件，里面的内容如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">你是我的好朋友，请用四川话回答问题,回答问题可以调皮一些。</span><br><span class="line">&#123;&#123;current_date&#125;&#125;表示当前的日期</span><br></pre></td></tr></table></figure><p>接着在PromptController类中定义一个名为systemPromptV2的方法，里面的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/prompt&quot;)</span><br><span class="line">public class PromptController &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    private SeparateChatAssistant separateChatAssistant;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 测试系统提示词</span><br><span class="line">     */</span><br><span class="line">    @GetMapping(&quot;/systemPromptV2&quot;)</span><br><span class="line">    public String systemPromptV2()&#123;</span><br><span class="line">        return separateChatAssistant.chatFromResource(3,&quot;今天几号？应该吃啥子嘛?&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动项目，访问如下地址：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/prompt/systemPromptV2</span><br></pre></td></tr></table></figure><p>结果如下所示：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760857011895-95d3c13f-8ca2-4e08-8d4b-6511ab325f32.png"></p><h2 id="用户提示词"><a href="#用户提示词" class="headerlink" title="用户提示词"></a>用户提示词</h2><p>用户提示词，即使用@UserMessage注解来获取用户的输入，代码和之前的SystemMessage注解一样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@Retention(RetentionPolicy.RUNTIME)</span><br><span class="line">@Target(&#123;ElementType.METHOD, ElementType.PARAMETER&#125;)</span><br><span class="line">public @interface UserMessage &#123;</span><br><span class="line">    String[] value() default &#123;&quot;&quot;&#125;;</span><br><span class="line"></span><br><span class="line">    String delimiter() default &quot;\n&quot;;</span><br><span class="line"></span><br><span class="line">    String fromResource() default &quot;&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="配置-UserMessage"><a href="#配置-UserMessage" class="headerlink" title="配置@UserMessage"></a>配置@UserMessage</h3><p>回到config包内，修改之前SeparateChatAssistant类中的代码为如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">@AiService(wiringMode = AiServiceWiringMode.EXPLICIT,</span><br><span class="line">        chatModel = &quot;ollamaChatModel&quot;, chatMemoryProvider = &quot;chatMemoryProvider&quot;)</span><br><span class="line">public interface SeparateChatAssistant &#123;</span><br><span class="line">    @UserMessage(&quot;你是我的好朋友，请用四川话回答问题。我的名字叫：&#123;&#123;myName&#125;&#125;&quot;)</span><br><span class="line">    String chatUser(@MemoryId int memoryId, @V(&quot;myName&quot;)String userMessage);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>@UserMessage注解里配置的内容将在后台转换为UserMessage并发送给大语言模型（LLM）。这里我们在用户提示词中使用了myName变量，然后在chatUser方法参数中使用@V(“myName”)String userMessage)注解指定了属性名称为myName，表示使用当前userMessage变量的值来自动替换用户提示词模板中的对应占位符变量myName。</p><h3 id="创建测试接口-1"><a href="#创建测试接口-1" class="headerlink" title="创建测试接口"></a>创建测试接口</h3><p>接着在PromptController类中定义一个名为userPrompt的方法，里面的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/prompt&quot;)</span><br><span class="line">public class PromptController &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    private SeparateChatAssistant separateChatAssistant;</span><br><span class="line"></span><br><span class="line">   /**</span><br><span class="line">     * 测试用户提示词</span><br><span class="line">     */</span><br><span class="line">    @GetMapping(&quot;/userPrompt&quot;)</span><br><span class="line">    public String userPrompt()&#123;</span><br><span class="line">        return separateChatAssistant.chatUser(4,&quot;张三&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此时请求体如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">  &quot;model&quot; : &quot;deepseek-r1&quot;,</span><br><span class="line">  &quot;messages&quot; : [ &#123;</span><br><span class="line">    &quot;role&quot; : &quot;user&quot;,</span><br><span class="line">    &quot;content&quot; : &quot;你是我的好朋友，请用四川话回答问题。我的名字叫：张三&quot;</span><br><span class="line">  &#125;],</span><br><span class="line">  &quot;stream&quot; : false</span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure><h3 id="启动项目进行测试-1"><a href="#启动项目进行测试-1" class="headerlink" title="启动项目进行测试"></a>启动项目进行测试</h3><p>启动项目，访问如下地址：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/prompt/userPrompt</span><br></pre></td></tr></table></figure><p>结果如下所示：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760857988179-63434310-6d66-485f-975b-c5b39d1293ad.png"></p><p>查看一下数据库，可以发现也存有这条记录了，同时显示了提示词的类型：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760858009540-b6161703-57f0-4d29-8d49-fab8b63db0a3.png"></p><h3 id="指定参数名称"><a href="#指定参数名称" class="headerlink" title="指定参数名称"></a>指定参数名称</h3><p>当需要指定传递参数的名称，那么需要使用@V注解：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">@UserMessage(&quot;你是我的好朋友，请用四川话回答问题。我的名字叫：&#123;&#123;myName&#125;&#125;&quot;)</span><br><span class="line">String chat(@V(&quot;message&quot;) String userMessage);</span><br></pre></td></tr></table></figure><p>如果只有一个参数，那么可以不添加@V注解，但是变量名称要一样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">@UserMessage(&quot;你是我的好朋友，请用四川话回答问题。我的名字叫：&#123;&#123;myName&#125;&#125;&quot;)</span><br><span class="line">String chatUser(String myName);</span><br></pre></td></tr></table></figure><p>如果有两个或两个以上的参数，那么必须使用@V注解来显示指定传递参数的名称：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">@UserMessage(&quot;你是我的好朋友，请用四川话回答问题。我的名字叫：&#123;&#123;myName&#125;&#125;&quot;)</span><br><span class="line">String chatUser(@MemoryId int memoryId, @V(&quot;myName&quot;)String userMessage);</span><br></pre></td></tr></table></figure><p>请注意，@UserMessage注解中的内容每次都会和用户的问题组织在一起发送给大模型。</p><h2 id="SystemMessage和-V结合使用"><a href="#SystemMessage和-V结合使用" class="headerlink" title="@SystemMessage和@V结合使用"></a>@SystemMessage和@V结合使用</h2><p>接下来我们通过一个例子，来综合使用系统提示词和用户提示词。</p><h3 id="配置注解信息"><a href="#配置注解信息" class="headerlink" title="配置注解信息"></a>配置注解信息</h3><p>回到config包内，修改之前SeparateChatAssistant类中的代码为如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@AiService(wiringMode = AiServiceWiringMode.EXPLICIT,</span><br><span class="line">        chatModel = &quot;ollamaChatModel&quot;, chatMemoryProvider = &quot;chatMemoryProvider&quot;)</span><br><span class="line">public interface SeparateChatAssistant &#123;</span><br><span class="line"></span><br><span class="line">    @SystemMessage(fromResource = &quot;prompts/assistantV1.txt&quot;)</span><br><span class="line">    String chatComplex(@MemoryId int memoryId, @UserMessage String userMessage,</span><br><span class="line">                       @V(&quot;username&quot;)String userName, @V(&quot;age&quot;)int age);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>@SystemMessage注解表示当前系统提示词来源于prompts/assistantV1.txt文件，然后使用@V(“username”)注解作用在userName变量上，@V(“age”)作用在age变量上，意思就是使用当前的userName和age变量的值来替换prompts/assistantV1.txt文中占位用的username和age变量。</p><h3 id="创建资源文件"><a href="#创建资源文件" class="headerlink" title="创建资源文件"></a>创建资源文件</h3><p>在resources目录下创建prompts/assistantV1.txt文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">你是我的好朋友，我叫&#123;&#123;username&#125;&#125;，我的年龄是&#123;&#123;age&#125;&#125;,</span><br><span class="line">请用四川话回答问题,回答问题可以调皮一些。</span><br><span class="line">今天是：&#123;&#123;current_date&#125;&#125;</span><br></pre></td></tr></table></figure><h3 id="创建测试接口-2"><a href="#创建测试接口-2" class="headerlink" title="创建测试接口"></a>创建测试接口</h3><p>接着在PromptController类中定义一个名为promptAll的方法，里面的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/prompt&quot;)</span><br><span class="line">public class PromptController &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    private SeparateChatAssistant separateChatAssistant;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 测试提示词综合使用</span><br><span class="line">     */</span><br><span class="line">    @GetMapping(&quot;/promptAll&quot;)</span><br><span class="line">    public String promptAll()&#123;</span><br><span class="line">        return separateChatAssistant.chatComplex(5,&quot;我是谁，多大了？&quot;,&quot;王五&quot;,20);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="启动项目进行测试-2"><a href="#启动项目进行测试-2" class="headerlink" title="启动项目进行测试"></a>启动项目进行测试</h3><p>启动项目，访问如下地址：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/prompt/promptAll</span><br></pre></td></tr></table></figure><p>结果如下所示：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760859371128-e100b8d5-8c7b-44fd-a562-c6ae87137cd1.png"></p><p>查看一下数据库，可以发现也存有这条记录了，同时显示了提示词的类型：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760859388129-d97fa28b-c2ad-412e-aac6-0ebec24b723e.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;提示词（Prompt）&quot;&gt;&lt;a href=&quot;#提示词（Prompt）&quot; class=&quot;headerlink&quot; title=&quot;提示词（Prompt）&quot;&gt;&lt;/a&gt;提示词（Prompt）&lt;/h1&gt;&lt;p&gt;所谓的提示词，就是告诉大模型的一些话，分为系统提示词、用户提示词和助</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>LangChain4j之聊天记忆持久化</title>
    <link href="http://aichating.xyz/2025/08/10/2025-13-lang-chain-4j-4-chat-memory-persistence/"/>
    <id>http://aichating.xyz/2025/08/10/2025-13-lang-chain-4j-4-chat-memory-persistence/</id>
    <published>2025-08-10T06:01:20.000Z</published>
    <updated>2025-08-10T12:31:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="聊天记忆持久化（Persistence）"><a href="#聊天记忆持久化（Persistence）" class="headerlink" title="聊天记忆持久化（Persistence）"></a>聊天记忆持久化（Persistence）</h1><p>默认情况下，聊天记忆存储在内存中。如果需要持久化存储，可以实现一个自定义的聊天记忆存储类，以便将聊天消息存储在你选择的任何持久化存储介质中。</p><h2 id="存储介质的选择"><a href="#存储介质的选择" class="headerlink" title="存储介质的选择"></a>存储介质的选择</h2><p>大模型中聊天记忆的存储选择哪种数据库，需要综合考虑数据特点、应用场景和性能要求等因素，以下是一些常见的选择及其特点：</p><p>（1）MySQL：</p><ul><li><strong>特点</strong>：关系型数据库。支持事务处理，确保数据的一致性和完整性，适用于结构化数据的存储和查询。</li><li><strong>适用场景</strong>：如果聊天记忆数据结构较为规整，例如包含固定的字段如对话 ID、用户 ID、时间戳、消息内容等，且需要进行复杂的查询和统计分析，如按用户统计对话次数、按时间范围查询特定对话等，MySQL是不错的选择。</li></ul><p>（2）Redis：</p><ul><li><strong>特点</strong>：内存数据库，读写速度极高。它适用于存储热点数据，并且支持多种数据结构，如字符串、哈希表、列表等，方便对不同类型的聊天记忆数据进行处理。</li><li><strong>适用场景</strong>：对于实时性要求极高的聊天应用，如在线客服系统或即时通讯工具，Redis可以快速存储和获取最新的聊天记录，以提供流畅的聊天体验。</li></ul><p>（3）MongoDB：</p><ul><li><strong>特点</strong>：文档型数据库，数据以JSON - like的文档形式存储，具有高度的灵活性和可扩展性。它不需要预先定义严格的表结构，适合存储半结构化或非结构化的数据。</li><li><strong>适用场景</strong>：当聊天记忆中包含多样化的信息，如文本消息、图片、语音等多媒体数据，或者消息格式可能会频繁变化时，MongoDB能很好地适应这种灵活性。例如，一些社交应用中用户可能会发送各种格式的消息，使用MongoDB可以方便地存储和管理这些不同类型的数据。</li></ul><p>（4）Cassandra：</p><ul><li><strong>特点</strong>：是一种分布式的 NoSQL 数据库，具有高可扩展性和高可用性，能够处理大规模的分布式数据存储和读写请求。适合存储海量的、时间序列相关的数据。</li><li><strong>适用场景</strong>：对于大型的聊天应用，尤其是用户量众多、聊天数据量巨大且需要分布式存储和处理的场景，Cassandra 能够有效地应对高并发的读写操作。例如，一些面向全球用户的社交媒体平台，其聊天数据需要在多个节点上进行分布式存储和管理，Cassandra可以提供强大的支持。</li></ul><h2 id="MongoDB"><a href="#MongoDB" class="headerlink" title="MongoDB"></a>MongoDB</h2><h3 id="MongoDB简介"><a href="#MongoDB简介" class="headerlink" title="MongoDB简介"></a>MongoDB简介</h3><p>（1）MongoDB是一个基于文档的NoSQL数据库，由MongoDB Inc.开发。NoSQL指的是非关系型的数据库。NoSQL有时也称作Not Only SQL的缩写，是对不同于传统的关系型数据库的数据库管理系统的统称。</p><p>（2）MongoDB的设计理念是为了应对大数据量、高性能和灵活性需求。</p><p>（3）MongoDB使用集合（Collections）来组织文档（Documents），每个文档都是由键值对组成：</p><ul><li><strong>数据库（Database）</strong>：存储数据的容器，类似于关系型数据库中的数据库。</li><li><strong>集合（Collection）</strong>：数据库中的一个集合，类似于关系型数据库中的表。</li><li><strong>文档（Document）</strong>：集合中的一个数据记录，类似于关系型数据库中的行（row），以 BSON 格式存储。</li></ul><p>（4）MongoDB 将数据存储为一个文档，数据结构由键值(key=&gt;value)对组成，文档类似于JSON对象，字段值可以包含其他文档，数组及文档数组：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760838738424-d6e1644a-34f8-4d94-af7e-9e58a0f8fe7f.png"></p><h3 id="MongoDB本地安装及使用"><a href="#MongoDB本地安装及使用" class="headerlink" title="MongoDB本地安装及使用"></a>MongoDB本地安装及使用</h3><p>【传统方式安装】</p><p>第一步，安装 <a href="https://www.mongodb.com/try/download/community">mongodb-windows-x86_64-8.0.6-signed.msi</a>，这是服务端；</p><p>第二步，安装 <a href="https://www.mongodb.com/try/download/shell">mongosh-2.5.0-win32-x64.zip</a>，这是命令行客户端；</p><p>第三步，安装 <a href="https://www.mongodb.com/try/download/compass">mongodb-compass-1.39.3-win32-x64.exe</a>，这是图形客户端，方便操作MongoDB。</p><p>接下来介绍如何使用mongosh，具体的步骤如下：</p><p>第一步，启动 MongoDB Shell。在命令行中输入 mongosh 命令，启动 MongoDB Shell，如果 MongoDB 服务器运行在本地默认端口（27017），则可以直接连接。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mongosh</span><br></pre></td></tr></table></figure><p>第二步，连接到 MongoDB 服务器。如果 MongoDB 服务器运行在非默认端口或者远程服务器上，可以使用以下命令连接：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mongosh --host &lt;hostname&gt;:&lt;port&gt;</span><br></pre></td></tr></table></figure><p>其中<hostname>是MongoDB服务器的主机名或 IP 地址，<port>是 MongoDB 服务器的端口号。</p><p>第三步，执行基本操作。连接成功后，可以执行各种 MongoDB 数据库操作，如：</p><ul><li>查看当前数据库：<code>db</code></li><li>显示数据库列表：<code>show dbs</code></li><li>切换到指定数据库：<code>use &lt;database_name&gt;</code></li><li>执行查询操作：<code>db.&lt;collection_name&gt;.find()</code></li><li>插入文档：<code>db.&lt;collection_name&gt;.insertOne(&#123; ... &#125;)</code></li><li>更新文档：<code>db.&lt;collection_name&gt;.updateOne(&#123; ... &#125;)</code></li><li>删除文档：<code>db.&lt;collection_name&gt;.deleteOne(&#123; ... &#125;)</code></li><li>退出 MongoDB Shell：<code>quit()</code> 或者 <code>exit</code></li></ul><p>第四步，执行一些CRUD操作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">插入文档</span></span><br><span class="line"><span class="meta prompt_">test&gt; </span><span class="language-bash">db.mycollection.insertOne(&#123; name: <span class="string">&quot;Alice&quot;</span>, age: 30 &#125;)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查询文档</span></span><br><span class="line"><span class="meta prompt_">test&gt; </span><span class="language-bash">db.mycollection.find()</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">更新文档</span></span><br><span class="line"><span class="meta prompt_">test&gt; </span><span class="language-bash">db.mycollection.updateOne(&#123; name: <span class="string">&quot;Alice&quot;</span> &#125;, &#123; <span class="variable">$set</span>: &#123; age: 31 &#125; &#125;)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除文档</span></span><br><span class="line"><span class="meta prompt_">test&gt; </span><span class="language-bash">db.mycollection.deleteOne(&#123; name: <span class="string">&quot;Alice&quot;</span> &#125;)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">退出 MongoDB Shell</span></span><br><span class="line"><span class="meta prompt_">test&gt; </span><span class="language-bash">quit()</span></span><br></pre></td></tr></table></figure><h3 id="Docker安装MongoDB"><a href="#Docker安装MongoDB" class="headerlink" title="Docker安装MongoDB"></a>Docker安装MongoDB</h3><p>第一步，在本地创建数据持久化目录：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">E:/DockerVolume/mongo</span><br></pre></td></tr></table></figure><p>第二步，执行如下命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name my-mongo7 -p 27117:27017 -e MONGO_INITDB_ROOT_USERNAME=admin -e MONGO_INITDB_ROOT_PASSWORD=123456 -v E:/DockerVolume/mongo7.0:/data/db mongo:7.0</span><br></pre></td></tr></table></figure><p>解释一下上述命令的含义：</p><p>（1）-d表示后台运行；</p><p>（2）–name my-mongo7表示指定容器名称为my-mongo7；</p><p>（3）-p 27117:27017表示将虚拟机的27017端口映射到宿主机的27117端口；</p><p>（4）-e MONGO_INITDB_ROOT_USERNAME=admin表示设置超级管理员用户名；</p><p>（5）-e MONGO_INITDB_ROOT_PASSWORD=123456表示设置超级管理员密码；</p><p>（6）-v E:/DockerVolume/mongo7.0:/data/db表示将容器的/data/db目录挂载到宿主机的E:/DockerVolume/mongo7.0目录。</p><p>第三步，验证连接。执行如下命令进入到Docker容器中：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it my-mongo7 bash</span><br></pre></td></tr></table></figure><p>之后切换到bin目录：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd bin</span><br></pre></td></tr></table></figure><p>执行如下命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mongosh -u root -p 123456 --authenticationDatabase admin</span><br></pre></td></tr></table></figure><p>出现下面的信息，则表示连接成功：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760848477700-fe343b59-1f76-46fe-ab84-d7cd52f484ae.png"></p><p>第四步，使用Navicat进行连接：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760848655100-c8b0bd7a-a98b-4519-a053-8cfb255c827d.png"></p><h2 id="SpringBoot整合MongoDB"><a href="#SpringBoot整合MongoDB" class="headerlink" title="SpringBoot整合MongoDB"></a>SpringBoot整合MongoDB</h2><p>第一步，在项目POM文件引入mongodb依赖：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- Spring Boot Starter Data MongoDB --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>第二步，在application.properties配置文件中新增如下配置：（这里使用了Docker安装的MongoDB，端口有变化）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># mongodb数据库配置</span><br><span class="line">spring.data.mongodb.host=127.0.0.1</span><br><span class="line">spring.data.mongodb.port=27217</span><br><span class="line">spring.data.mongodb.username=root</span><br><span class="line">spring.data.mongodb.password=123456</span><br><span class="line">spring.data.mongodb.authentication-database=admin</span><br><span class="line">spring.data.mongodb.database=chat_memory_db</span><br></pre></td></tr></table></figure><p>第三步，新建一个名为pojo的包，并在里面定义一个名为MyChatMessage的类：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">@Data</span><br><span class="line">@AllArgsConstructor</span><br><span class="line">@NoArgsConstructor</span><br><span class="line">@Document(&quot;my_chat_message&quot;)</span><br><span class="line">public class MyChatMessage &#123;</span><br><span class="line">    //唯一标识，映射到 MongoDB 文档的 _id 字段</span><br><span class="line">    @Id</span><br><span class="line">    private ObjectId messageId;</span><br><span class="line"></span><br><span class="line">    //存储当前聊天记录列表的json字符串</span><br><span class="line">    private String content;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>请注意，这里的messageId是唯一标识，用于映射到MongoDB文档的_id字段，它的类型是<code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;ObjectId&lt;/font&gt;</code>，不可以是字符串。</p><p><font style="color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);"></font></p><p><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;ObjectId&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);">是</font><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;MongoDB&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);">默认使用的主键类型，它是一个 </font><strong><font style="color:rgb(64, 72, 91);">12 字节</font></strong><font style="color:rgb(64, 72, 91);">的</font><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;BSON&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);">类型，通常用作</font><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;_id&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);">字段。</font><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;ObjectId&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);">的值是一个有效的</font><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;24 字符&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);">的十六进制字符串。</font><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;12*8=24*4=96&lt;/font&gt;</code></p><p><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;ObjectId&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);"> </font><font style="color:rgb(64, 72, 91);">的值由以下部分组成：</font></p><p><strong><font style="color:rgb(64, 72, 91);">4 字节</font></strong><font style="color:rgb(64, 72, 91);">：当前时间戳（秒级，表示创建的时间）</font></p><p><strong><font style="color:rgb(64, 72, 91);">5 字节</font></strong><font style="color:rgb(64, 72, 91);">：机器标识符和进程ID（唯一）</font></p><p><strong><font style="color:rgb(64, 72, 91);">3 字节</font></strong><font style="color:rgb(64, 72, 91);">：计数器（递增值，用于确保在同一毫秒内创建多个 </font><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;ObjectId&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);"> 时的唯一性）</font></p><p><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;new ObjectId()&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);">默认使用当前时间戳，当然开发者也可以传入一个时间戳。</font></p><p><font style="color:rgb(64, 72, 91);"></font></p><p>第四步，在controller包内定义一个名为MongoController的类，用于测试Mongo的增删改查操作：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/mongo&quot;)</span><br><span class="line">public class MongoController &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    private MongoTemplate mongoTemplate;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;/create&quot;)</span><br><span class="line">    public String create()&#123;</span><br><span class="line">        MyChatMessage message = new MyChatMessage();</span><br><span class="line">        message.setMessageId(new ObjectId());</span><br><span class="line">        message.setContent(&quot;&#123;\&quot;message\&quot;:\&quot;Hello, world!\&quot;&#125;&quot;);</span><br><span class="line"></span><br><span class="line">        MyChatMessage saveMessage = mongoTemplate.save(message);</span><br><span class="line">        return saveMessage.toString();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;/read&quot;)</span><br><span class="line">    public String read()&#123;</span><br><span class="line">        //假设存在一个id为objectId的记录</span><br><span class="line">        ObjectId id = new ObjectId(&quot;68f46b6133a9f889676511a5&quot;);</span><br><span class="line">        MyChatMessage readMessage = mongoTemplate.findById(id, MyChatMessage.class);</span><br><span class="line">        return readMessage.toString();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;/update&quot;)</span><br><span class="line">    public String update()&#123;</span><br><span class="line">        //假设存在一个id为objectId的记录</span><br><span class="line">        ObjectId id = new ObjectId(&quot;68f46b6133a9f889676511a5&quot;);</span><br><span class="line">        MyChatMessage readMessage = mongoTemplate.findById(id, MyChatMessage.class);</span><br><span class="line"></span><br><span class="line">        readMessage.setContent(&quot;&#123;\&quot;message\&quot;:\&quot;Updated content!\&quot;&#125;&quot;);</span><br><span class="line"></span><br><span class="line">        MyChatMessage updateMessage = mongoTemplate.save(readMessage);</span><br><span class="line">        return updateMessage.toString();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;/delete&quot;)</span><br><span class="line">    public String delete()&#123;</span><br><span class="line">        //假设存在一个id为objectId的记录</span><br><span class="line">        ObjectId id = new ObjectId(&quot;68f46b6133a9f889676511a5&quot;);</span><br><span class="line">        MyChatMessage readMessage = mongoTemplate.findById(id, MyChatMessage.class);</span><br><span class="line"></span><br><span class="line">        if(readMessage != null)&#123;</span><br><span class="line">            mongoTemplate.remove(readMessage);</span><br><span class="line">        &#125;</span><br><span class="line">        MyChatMessage deleteMessage = mongoTemplate.findById(id, MyChatMessage.class);</span><br><span class="line">        if(deleteMessage == null)&#123;</span><br><span class="line">            return &quot;删除成功&quot;;</span><br><span class="line">        &#125;</span><br><span class="line">        return &quot;删除失败&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第五步，启动项目，访问如下地址来往MongoDB中插入一条数据：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/mongo/create</span><br></pre></td></tr></table></figure><p>页面显示结果如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760850504106-401e0a3f-e184-4e42-8ac2-fc07260c77a5.png"></p><p>说明数据已经添加成功，查看一下MongoDB数据库：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760850535077-302de9d5-7221-4c8b-974f-758b3f033528.png"></p><p>在read方法中传入之前创建数据的id，之后访问如下地址：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/mongo/read</span><br></pre></td></tr></table></figure><p>页面显示结果如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760850591469-89794004-0995-479d-a2e0-543a0f617368.png"></p><p>说明我们已经可以根据id来查询对应数据了。在update方法中添加数据的id以及更新后的内容，之后访问如下地址：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/mongo/update</span><br></pre></td></tr></table></figure><p>页面显示结果如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760850644174-a662479b-ba7e-48ff-85c4-0d90d537958b.png"></p><p>说明此时数据被更新了，查看一下MongoDB数据库：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760850669805-7b2ff8f0-3851-4fd9-82bd-d491ded48a71.png"></p><p>说明数据确实被更新。最后我们在update方法中传入对应数据的id，然后访问如下地址：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/mongo/delete</span><br></pre></td></tr></table></figure><p>页面显示结果如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760850718283-da6c1b1f-028e-4992-a415-3d4a10303330.png"></p><p>说明数据被成功删除了，这样我们就实现了使用SpringBoot来操作MongoDB的目的。</p><h2 id="聊天持久化"><a href="#聊天持久化" class="headerlink" title="聊天持久化"></a>聊天持久化</h2><h3 id="优化消息实体类"><a href="#优化消息实体类" class="headerlink" title="优化消息实体类"></a>优化消息实体类</h3><p>回到MyChatMessage类中，我们修改一下消息实体类：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@Data</span><br><span class="line">@AllArgsConstructor</span><br><span class="line">@NoArgsConstructor</span><br><span class="line">@Document(&quot;my_chat_message&quot;)</span><br><span class="line">public class MyChatMessage &#123;</span><br><span class="line">    //唯一标识，映射到 MongoDB 文档的 _id 字段</span><br><span class="line">    @Id</span><br><span class="line">    private ObjectId id;</span><br><span class="line"></span><br><span class="line">    private int messageId;</span><br><span class="line"></span><br><span class="line">    //存储当前聊天记录列表的json字符串</span><br><span class="line">    private String content;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里我们使用id属性作为与MongoDB文档的_id字段进行映射，然后messageId作为备用字段。</p><h3 id="创建持久化类"><a href="#创建持久化类" class="headerlink" title="创建持久化类"></a>创建持久化类</h3><p>创建一个名为store的包，并在里面定义一个名为MongoChatMemoryStore的类，这个类需要实现ChatMemoryStore接口。这个ChatMemoryStore接口中的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public interface ChatMemoryStore &#123;</span><br><span class="line">    //检索对应的聊天消息列表</span><br><span class="line">    List&lt;ChatMessage&gt; getMessages(Object memoryId);</span><br><span class="line"></span><br><span class="line">    //更新指定memoryId的聊天消息列表</span><br><span class="line">    void updateMessages(Object memoryId, List&lt;ChatMessage&gt; messages);</span><br><span class="line"></span><br><span class="line">    //删除指定memoryId的所有聊天消息</span><br><span class="line">    void deleteMessages(Object memoryId);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到这个<code>ChatMemoryStore</code> 接口定义了三个方法：</p><ol><li><code>List&lt;ChatMessage&gt; getMessages(Object memoryId)</code>，根据<code>memoryId</code>（通常是用户 ID 或会话 ID）检索对应的聊天消息列表。</li><li><code>void updateMessages(Object memoryId, List&lt;ChatMessage&gt; messages)</code>，更新指定<code>memoryId</code>的聊天消息列表。每当有新的消息添加到聊天内存中时，<code>LangChain4j</code>会调用此方法。</li><li><code>void deleteMessages(Object memoryId)</code>，删除指定<code>memoryId</code>的所有聊天消息。</li></ol><p>这些方法允许开发者实现自定义的持久化逻辑，以满足特定的存储需求。</p><p>MongoChatMemoryStore类中的代码如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">@Component</span><br><span class="line">public class MongoChatMemoryStore implements ChatMemoryStore &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    private MongoTemplate mongoTemplate;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 获取聊天记录</span><br><span class="line">     * @param memoryId</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public List&lt;ChatMessage&gt; getMessages(Object memoryId) &#123;</span><br><span class="line">        Criteria criteria = Criteria.where(&quot;memoryId&quot;).is(memoryId);</span><br><span class="line">        Query query = new Query(criteria);</span><br><span class="line">        MyChatMessage chatMessage = mongoTemplate.findOne(query, MyChatMessage.class);</span><br><span class="line">        if(chatMessage == null)&#123;</span><br><span class="line">            return List.of();</span><br><span class="line">        &#125;</span><br><span class="line">        return ChatMessageDeserializer.messagesFromJson(chatMessage.getContent());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 更新聊天记录</span><br><span class="line">     * @param memoryId</span><br><span class="line">     * @param messages</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public void updateMessages(Object memoryId, List&lt;ChatMessage&gt; messages) &#123;</span><br><span class="line">        Criteria criteria = Criteria.where(&quot;memoryId&quot;).is(memoryId);</span><br><span class="line">        Query query = new Query(criteria);</span><br><span class="line"></span><br><span class="line">        Update update = new Update();</span><br><span class="line">        update.set(&quot;content&quot;, ChatMessageSerializer.messagesToJson(messages));</span><br><span class="line">        //根据query条件能查询出文档，则修改文档；否则新增文档</span><br><span class="line">        mongoTemplate.upsert(query, update, MyChatMessage.class);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 删除聊天记录</span><br><span class="line">     * @param memoryId</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public void deleteMessages(Object memoryId) &#123;</span><br><span class="line">        Criteria criteria = Criteria.where(&quot;memoryId&quot;).is(memoryId);</span><br><span class="line">        Query query = new Query(criteria);</span><br><span class="line">        mongoTemplate.remove(query, MyChatMessage.class);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>简单解释其中的代码含义：</p><p>（1）Criteria用于构造查询条件，即where是memoryId等于传入的memoryId；</p><p>（2）Query用于封装查询请求，如条件、分页、排序等；</p><p>（3）ChatMessageDeserializer.messagesFromJson()，该方法是LangChain4j中的工具类，用于将JSON字符串反序列化为聊天消息对象；</p><p>（4）ChatMessageSerializer.messagesToJson()，该方法是LangChain4j中的工具类，用于将聊天消息对象序列化为JSON字符串。</p><h3 id="更新配置类信息"><a href="#更新配置类信息" class="headerlink" title="更新配置类信息"></a>更新配置类信息</h3><p>回到config包中，之前我们使用SeparateChatAssistantConfig实现了隔离聊天，接下来我们在里面注入持久化对象，并进行配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">public class SeparateChatAssistantConfig &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    private MongoChatMemoryStore mongoChatMemoryStore;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 创建一个ChatMemoryProvider,实现会话隔离</span><br><span class="line">     */</span><br><span class="line">    @Bean</span><br><span class="line">    ChatMemoryProvider chatMemoryProvider()&#123;</span><br><span class="line">        return memoryId -&gt; MessageWindowChatMemory.builder()</span><br><span class="line">                .id(memoryId)</span><br><span class="line">                .maxMessages(10)</span><br><span class="line">                .chatMemoryStore(mongoChatMemoryStore)</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，这里使用MongoChatMemoryStore来存储会话，实现聊天消息持久化功能。</p><h3 id="启动项目进行测试"><a href="#启动项目进行测试" class="headerlink" title="启动项目进行测试"></a>启动项目进行测试</h3><p>启动项目，访问如下地址：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/test/testChatMemoryV4</span><br></pre></td></tr></table></figure><p>然后查看一下MongoDB数据库，可以看到聊天记录已经存储了：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760853581993-7705ce5e-f77d-42ef-b47c-68330a26a440.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;聊天记忆持久化（Persistence）&quot;&gt;&lt;a href=&quot;#聊天记忆持久化（Persistence）&quot; class=&quot;headerlink&quot; title=&quot;聊天记忆持久化（Persistence）&quot;&gt;&lt;/a&gt;聊天记忆持久化（Persistence）&lt;/h1&gt;&lt;</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>LangChain4j之聊天记忆</title>
    <link href="http://aichating.xyz/2025/07/27/2025-12-lang-chain-4j-3-chat-memory/"/>
    <id>http://aichating.xyz/2025/07/27/2025-12-lang-chain-4j-3-chat-memory/</id>
    <published>2025-07-27T10:01:20.000Z</published>
    <updated>2025-07-27T14:31:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="AIService（人工智能服务）"><a href="#AIService（人工智能服务）" class="headerlink" title="AIService（人工智能服务）"></a>AIService（人工智能服务）</h1><h2 id="什么是AIService"><a href="#什么是AIService" class="headerlink" title="什么是AIService"></a>什么是AIService</h2><p>其实在前面我们在阅读langchain4j的文档中，就看到了这个AIService，只是没有提到：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760782489677-17ec84c5-0083-4ac1-9523-156ccd99427b.png"></p><p><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;AiService&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);"></font>是一个注解，定义如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@Service</span><br><span class="line">@Target(&#123;ElementType.TYPE&#125;)</span><br><span class="line">@Retention(RetentionPolicy.RUNTIME)</span><br><span class="line">public @interface AiService &#123;</span><br><span class="line">    AiServiceWiringMode wiringMode() default AiServiceWiringMode.AUTOMATIC;</span><br><span class="line">    String chatModel() default &quot;&quot;;  //绑定聊天模型</span><br><span class="line">    String streamingChatModel() default &quot;&quot;;</span><br><span class="line">    String chatMemory() default &quot;&quot;;  //绑定聊天记忆</span><br><span class="line">    String chatMemoryProvider() default &quot;&quot;;  //绑定聊天记忆隔离和持久化</span><br><span class="line">    String contentRetriever() default &quot;&quot;;  //绑定内容检索器</span><br><span class="line">    String retrievalAugmentor() default &quot;&quot;;</span><br><span class="line">    String moderationModel() default &quot;&quot;;</span><br><span class="line">    String[] tools() default &#123;&#125;;  //绑定工具</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;@AiService&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);">注解，用于标记一个接口，使其被框架（如 </font><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;langchain4j&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);">）自动处理，生成AI服务的实现：</font></p><ul><li><strong><font style="color:rgb(64, 72, 91);">动态代理</font></strong><font style="color:rgb(64, 72, 91);">：框架会基于该接口生成代理类，处理方法调用（如</font><font style="color:rgb(64, 72, 91);"> </font><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;chat(String message)&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);">）。</font></li><li><strong><font style="color:rgb(64, 72, 91);">依赖注入</font></strong><font style="color:rgb(64, 72, 91);">：标记的接口会被 Spring 容器管理，允许通过</font><font style="color:rgb(64, 72, 91);"> </font><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;@Autowired&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);"> </font><font style="color:rgb(64, 72, 91);">或其他方式注入。</font></li><li><strong><font style="color:rgb(64, 72, 91);">AI 功能集成</font></strong><font style="color:rgb(64, 72, 91);">：注解会将接口与 AI 模型（如 OpenAI 或其他语言模型）绑定，自动处理请求和响应。</font></li></ul><p>举个例子，这里我们定义了一个名为Assistant的接口，然后使用<code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;@AiService&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);">注解标记它，这样这个接口就会被自动处理，生成AI服务的实现：</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">@AiService</span><br><span class="line">//如果你有很多AI模型实例，可用自定义绑定哪个模型</span><br><span class="line">//@AiService(AiServiceWiringMode.EXPLICIT, chatModel = &quot;ollamaChatModel&quot;)</span><br><span class="line">public interface Assistant &#123;</span><br><span class="line">    String chat(String message);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;AiService&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);"></font>使用面向接口和动态代理的方式来完成程序的编写，以更灵活的实现高级功能。</p><h2 id="链-Chain（旧版）"><a href="#链-Chain（旧版）" class="headerlink" title="链 Chain（旧版）"></a>链 Chain（旧版）</h2><p>链的概念源自Python中的LangChain，其理念是针对每个常见的用例都设置一条链，比如聊天机器人、检索增强生成（RAG）等。链将多个底层组件组合起来，并协调它们之间的交互。链存在的主要问题是不灵活。</p><h2 id="AIService的作用"><a href="#AIService的作用" class="headerlink" title="AIService的作用"></a>AIService的作用</h2><p>在LangChain4j中，我们可以使用AIService来完成复杂操作，它的底层组件将由AIService进行组装。</p><p>AIService可处理最常见的操作，如为大语言模型格式化输入内容、解析大语言模型的输出结果，同时还支持更高级的功能，如聊天记忆（Chat Memory）、工具（Tools）和检索增强生成（RAG）。</p><h2 id="创建AIService"><a href="#创建AIService" class="headerlink" title="创建AIService"></a>创建AIService</h2><p>点击 <a href="https://docs.langchain4j.dev/tutorials/spring-boot-integration">这里</a>，查看与SpringBoot的集成，这是langchain4j的高级功能：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760782864832-cd70f4f7-1017-4b43-aa88-edcab383c8f4.png"></p><p>第一步，在pom文件中新增如下依赖：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--langchain4j高级功能--&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;langchain4j-spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>第二步，新建一个名为assistant的包，并在该包内定义一个名为Assistant的接口，里面定义一个chat方法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public interface Assistant &#123;</span><br><span class="line">    String chat(String message);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第三步，新建一个名为controller的包，并在该包内定义一个名为TestController的类，里面定义一个testChat方法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/test&quot;)</span><br><span class="line">public class TestController &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    private OllamaChatModel ollamaChatModel;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;/testChat&quot;)</span><br><span class="line">    public String testChat()&#123;</span><br><span class="line">        //创建AIService</span><br><span class="line">        Assistant assistant = AiServices.create(Assistant.class, ollamaChatModel);</span><br><span class="line">        //调用service的接口</span><br><span class="line">        return assistant.chat(&quot;你好,你是谁？&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这我们通过注入OllamaChatModel对象，然后调用AiServices的create方法，传入Assistant类以及OllamaChatModel对象，这样让返回的Assistant具备Ai功能。</p><p>第四步，启动项目，访问如下接口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/test/testChat</span><br></pre></td></tr></table></figure><p>页面显示内容如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760789411658-a3faaf01-be05-4e49-b85e-d5c060141fd0.png"></p><p>实际上我们可以直接在自定义的Assistant接口上添加@AiService注解，由于我们在配置文件中同时配置了多个大语言模型，所以需要在这里明确指定（EXPLICIT）模型的beanName，即此处为ollamaChatModel：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">@AiService(wiringMode = AiServiceWiringMode.EXPLICIT, chatModel = &quot;ollamaChatModel&quot;)</span><br><span class="line">public interface Assistant &#123;</span><br><span class="line">    String chat(String message);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后我们修改TestController类中的代码为如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/test&quot;)</span><br><span class="line">public class TestController &#123;</span><br><span class="line">    </span><br><span class="line">    @Autowired</span><br><span class="line">    private Assistant assistant;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;/testChat&quot;)</span><br><span class="line">    public String testChat()&#123;</span><br><span class="line">        //调用service的接口</span><br><span class="line">        return assistant.chat(&quot;你好,你是谁？&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>重启项目，访问之前的接口，也是能得到之前的结果，毫无疑问，第二种方式更简单方便。</p><h2 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h2><p>实际上AiService会<strong>组装Assistant接口以及其他组件</strong>，并使用反射机制创建一个实现Assistant接口的代理对象。这个代理对象会处理输入和输出的所有转换工作，即<strong>代理对象的作用是输入转换和输出转换</strong>。</p><p>在上述例子中，chat方法的输入是一个字符串，但是大模型需要一个UserMessage对象。所以，代理对象将这个字符串转换为UserMessage，并调用聊天语言模型。chat方法的输出类型也是字符串，但是大模型返回的是 AiMessage对象，代理对象会将其转换为字符串。</p><h1 id="ChatMemory（聊天记忆）"><a href="#ChatMemory（聊天记忆）" class="headerlink" title="ChatMemory（聊天记忆）"></a>ChatMemory（聊天记忆）</h1><p>点击 <a href="https://docs.langchain4j.dev/tutorials/chat-memory">这里</a>，阅读langchain4j关于chat memory相关的部分介绍：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760790891650-5f2daf57-ff1c-4c8d-87ab-22f674210aaa.png"></p><h2 id="测试对话是否有记忆"><a href="#测试对话是否有记忆" class="headerlink" title="测试对话是否有记忆"></a>测试对话是否有记忆</h2><p>在TestController类中新增一个名为testChatMemory的方法，代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">@GetMapping(&quot;/testChatMemory&quot;)</span><br><span class="line">public String testChatMemory()&#123;</span><br><span class="line">    String answer = assistant.chat(&quot;我是张三！&quot;);</span><br><span class="line">    log.info(answer);</span><br><span class="line">    return assistant.chat(&quot;我是谁？&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动项目，访问如下接口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/test/testChatMemory</span><br></pre></td></tr></table></figure><p>页面显示内容如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760791284514-e1547461-508f-4796-b17d-f228fc9649aa.png"></p><p>由此可见，当前的接入方式，大模型是没有记忆的。</p><p>控制台输出如下信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">你好！我是一个由深度求索公司独立开发的智能助手DeepSeek-R1，如果你有任何任何问题，我会尽我所能为您提供帮助。</span><br></pre></td></tr></table></figure><h2 id="使用ChatMemory实现聊天记忆"><a href="#使用ChatMemory实现聊天记忆" class="headerlink" title="使用ChatMemory实现聊天记忆"></a>使用ChatMemory实现聊天记忆</h2><p>ChatMemory是一个接口，代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">public interface ChatMemory &#123;</span><br><span class="line">    //ID</span><br><span class="line">    Object id();</span><br><span class="line">    </span><br><span class="line">    //添加消息</span><br><span class="line">    void add(ChatMessage var1);</span><br><span class="line">    </span><br><span class="line">    //消息集合，存储历史消息</span><br><span class="line">    List&lt;ChatMessage&gt; messages();</span><br><span class="line">    </span><br><span class="line">    //清空消息</span><br><span class="line">    void clear();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个ChatMemory接口有两个实现类：MessageWindowChatMemory和TokenWindowChatMemory，区别如下：</p><p>（1）MessageWindowChatMemory：基于消息数量的滑动窗口，保留最近的 <code>N</code> 条消息；</p><p>（2）TokenWindowChatMemory：基于<code>token</code>数量的滑动窗口，保留最近的 <code>N</code>个<code>token</code>。</p><p>接下来我们尝试使用MessageWindowChatMemory来实现聊天记忆。回到TestController类中，新增一个名为testChatMemoryV2的方法，里面的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@GetMapping(&quot;/testChatMemoryV2&quot;)</span><br><span class="line">public String testChatMemoryV2()&#123;</span><br><span class="line">    //创建Memory</span><br><span class="line">    MessageWindowChatMemory chatMemory = MessageWindowChatMemory.withMaxMessages(10);</span><br><span class="line">    //创建AIService</span><br><span class="line">    Assistant assistant = AiServices.builder(Assistant.class)</span><br><span class="line">            .chatLanguageModel(ollamaChatModel)</span><br><span class="line">            .chatMemory(chatMemory)</span><br><span class="line">            .build();</span><br><span class="line">    //调用service的接口</span><br><span class="line">    String answer = assistant.chat(&quot;我是张三&quot;);</span><br><span class="line">    log.info(answer);</span><br><span class="line">    return assistant.chat(&quot;我是谁&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动项目，访问如下接口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/test/testChatMemoryV2</span><br></pre></td></tr></table></figure><p>页面显示内容如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760792753149-a6d49af6-4acf-4eeb-9389-3792046677c9.png"></p><p>说明大模型目前是具备聊天记忆功能了。</p><h2 id="使用AIService实现聊天记忆"><a href="#使用AIService实现聊天记忆" class="headerlink" title="使用AIService实现聊天记忆"></a>使用AIService实现聊天记忆</h2><h3 id="创建记忆对话智能体"><a href="#创建记忆对话智能体" class="headerlink" title="创建记忆对话智能体"></a>创建记忆对话智能体</h3><p>当AIService由多个组件（如大模型，聊天记忆等）组成时，我们就可以称它为智能体。</p><p>在assistant包内定义一个名为MemoryChatAssistant的接口，里面的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">@AiService(wiringMode = AiServiceWiringMode.EXPLICIT,</span><br><span class="line">chatModel = &quot;ollamaChatModel&quot;, chatMemory = &quot;chatMemory&quot;)</span><br><span class="line">public interface MemoryChatAssistant &#123;</span><br><span class="line">    String chat(String message);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于此处的chatMemory属性使用的是chatMemory，因此需要提供一个名为chatMemory的Bean对象，可在配置类中提供。</p><h3 id="配置ChatMemory"><a href="#配置ChatMemory" class="headerlink" title="配置ChatMemory"></a>配置ChatMemory</h3><p>新建一个名为config的包，并在该包内定义一个名为MemoryChatAssistantConfig的配置类，里面的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">public class MemoryChatAssistantConfig &#123;</span><br><span class="line">    @Bean</span><br><span class="line">    ChatMemory chatMemory() &#123;</span><br><span class="line">        //设置聊天记忆记录的message数量</span><br><span class="line">        return MessageWindowChatMemory.withMaxMessages(10);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="聊天测试"><a href="#聊天测试" class="headerlink" title="聊天测试"></a>聊天测试</h3><p>回到TestController类中，新增一个名为testChatMemoryV3的方法，里面的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">@Autowired</span><br><span class="line">private MemoryChatAssistant memoryChatAssistant;</span><br><span class="line"></span><br><span class="line">@GetMapping(&quot;/testChatMemoryV3&quot;)</span><br><span class="line">public String testChatMemoryV3()&#123;</span><br><span class="line">    String answer1 = memoryChatAssistant.chat(&quot;我是张三&quot;);</span><br><span class="line">    log.info(answer1);</span><br><span class="line">    String answer2 = memoryChatAssistant.chat(&quot;我是谁&quot;);</span><br><span class="line">    log.info(answer2);</span><br><span class="line">    return answer2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动项目，访问如下接口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/test/testChatMemoryV3</span><br></pre></td></tr></table></figure><p>页面显示内容如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760793469431-98c7bcfe-efb2-4393-882a-ee7d01bf498c.png"></p><p>说明大模型目前是具备聊天记忆功能了。</p><h2 id="隔离聊天记忆"><a href="#隔离聊天记忆" class="headerlink" title="隔离聊天记忆"></a>隔离聊天记忆</h2><p>所谓的隔离聊天记忆，就是为每个用户的新聊天或者不同的用户区分聊天记忆。</p><p>实际上我们之前使用的<code>ChatMemory</code>是单一会话内存，而<code>ChatMemoryProvider</code>是多会话内存，因此我们需要使用<code>ChatMemoryProvider</code>给每个用户或会话提供独立的<code>ChatMemory</code>实例，并根据提供的<code>memoryId</code>（通常是用户 ID 或会话 ID）返回对应的 <code>ChatMemory</code> 实例。</p><ul><li><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;@MemoryId&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);"> 注解用于标识方法参数，该参数的值将作为 </font><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;memoryId&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);"> 传递给 </font><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;chatMemoryProvider&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);">，以获取对应的</font><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;ChatMemory&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);">实例。</font></li><li><code>&lt;font style=&quot;color:rgba(0, 0, 0, 0.8);background-color:rgb(247, 247, 249);&quot;&gt;@UserMessage&lt;/font&gt;</code><font style="color:rgb(64, 72, 91);">注解用于标识方法参数，该参数的值将作为用户消息发送给大语言模型（LLM）。</font></li></ul><h3 id="创建记忆隔离对话智能体"><a href="#创建记忆隔离对话智能体" class="headerlink" title="创建记忆隔离对话智能体"></a>创建记忆隔离对话智能体</h3><p>在assistant包内定义一个名为SeparateChatAssistant的接口，里面的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@AiService(wiringMode = AiServiceWiringMode.EXPLICIT,</span><br><span class="line">        chatModel = &quot;ollamaChatModel&quot;, chatMemoryProvider = &quot;chatMemoryProvider&quot;)</span><br><span class="line">public interface SeparateChatAssistant &#123;</span><br><span class="line">    /**</span><br><span class="line">     * 分离聊天记录</span><br><span class="line">     * @param memoryId 聊天id</span><br><span class="line">     * @param userMessage 用户消息</span><br><span class="line">     */</span><br><span class="line">    String chat(@MemoryId int memoryId , @UserMessage String userMessage);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于此处的chatMemoryProvider属性使用的是chatMemoryProvider，因此需要提供一个名为chatMemoryProvider的Bean对象，可在配置类中提供。</p><h3 id="配置ChatMemoryProvider"><a href="#配置ChatMemoryProvider" class="headerlink" title="配置ChatMemoryProvider"></a>配置ChatMemoryProvider</h3><p>在config包内定义一个名为SeparateChatAssistantConfig的配置类，里面的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">public class SeparateChatAssistantConfig &#123;</span><br><span class="line">    @Bean</span><br><span class="line">    ChatMemoryProvider chatMemoryProvider()&#123;</span><br><span class="line">        return memoryId -&gt; MessageWindowChatMemory.builder()</span><br><span class="line">                .id(memoryId)</span><br><span class="line">                .maxMessages(10)</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到这个ChatMemoryProvider是一个函数式接口，定义了如何根据<code>memoryId</code>（通常是用户 ID 或会话 ID）提供对应的<code>ChatMemory</code>实例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">@FunctionalInterface</span><br><span class="line">public interface ChatMemoryProvider &#123;</span><br><span class="line">    ChatMemory get(Object var1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样每当有新的对话请求时，LangChain4j会调用<code>chatMemoryProvider</code>的<code>get</code>方法，传入当前的<code>memoryId</code>，以获取对应的<code>ChatMemory</code>实例。</p><p>这意味着，对于每个不同的<code>memoryId</code>，都会有一个独立的对话记忆实例，确保多用户或多会话场景下的对话上下文不会混淆。</p><h3 id="测试对话助手"><a href="#测试对话助手" class="headerlink" title="测试对话助手"></a>测试对话助手</h3><p>接下来我们将尝试使用两个不同的memoryId，来测试聊天记忆的隔离效果。</p><p>回到TestController类中，新增一个名为testChatMemoryV4的方法，里面的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">@Autowired</span><br><span class="line">private SeparateChatAssistant separateChatAssistant;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">* 隔离聊天记忆</span><br><span class="line">*/</span><br><span class="line">@GetMapping(&quot;/testChatMemoryV4&quot;)</span><br><span class="line">public String testChatMemoryV4()&#123;</span><br><span class="line">    String answer1 = separateChatAssistant.chat(1,&quot;我是张三&quot;);</span><br><span class="line">    log.info(&quot;answer1:&#123;&#125;&quot;,answer1);</span><br><span class="line">    String answer2 = separateChatAssistant.chat(1,&quot;我是谁&quot;);</span><br><span class="line">    log.info(&quot;answer2:&#123;&#125;&quot;,answer2);</span><br><span class="line">    String answer3 = separateChatAssistant.chat(2,&quot;我是谁&quot;);</span><br><span class="line">    log.info(&quot;answer3:&#123;&#125;&quot;,answer3);</span><br><span class="line">    return answer3;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动项目，访问如下接口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/test/testChatMemoryV4</span><br></pre></td></tr></table></figure><p>页面显示内容如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760795909582-2f7a170f-9e8b-47a8-a30e-38ad7c199c3c.png"></p><p>说明大模型目前是具备隔离聊天记忆功能了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;AIService（人工智能服务）&quot;&gt;&lt;a href=&quot;#AIService（人工智能服务）&quot; class=&quot;headerlink&quot; title=&quot;AIService（人工智能服务）&quot;&gt;&lt;/a&gt;AIService（人工智能服务）&lt;/h1&gt;&lt;h2 id=&quot;什么是AI</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>LangChain4j之接入大模型</title>
    <link href="http://aichating.xyz/2025/07/19/2025-11-lang-chain-4j-2-model-integrate/"/>
    <id>http://aichating.xyz/2025/07/19/2025-11-lang-chain-4j-2-model-integrate/</id>
    <published>2025-07-19T06:02:20.000Z</published>
    <updated>2025-07-19T13:31:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>本篇介绍LangChain4j如何接入大模型，具体包括DeepSeek和阿里百炼。</p><h1 id="接入DeepSeek"><a href="#接入DeepSeek" class="headerlink" title="接入DeepSeek"></a>接入DeepSeek</h1><h2 id="获取开发参数"><a href="#获取开发参数" class="headerlink" title="获取开发参数"></a>获取开发参数</h2><p>点击 <a href="https://www.deepseek.com/">这里</a> 访问DeepSeek官网，注册账号，然后充值，并获取对应的base_url和api_key：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760773671673-fe8f1a79-2076-4422-a5d3-8b3e068d6be1.png"></p><h2 id="配置开发参数"><a href="#配置开发参数" class="headerlink" title="配置开发参数"></a>配置开发参数</h2><p>为了apikay的安全，建议将其配置在服务器的环境变量中，变量名自定义即可，如 DEEP_SEEK_API_KEY：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760773887479-188279f4-d67a-432e-a089-dbe5b2507213.png"></p><h2 id="配置模型参数"><a href="#配置模型参数" class="headerlink" title="配置模型参数"></a>配置模型参数</h2><p>点击 <a href="https://api-docs.deepseek.com/zh-cn/">这里</a> 访问DeepSeek接口文档，首次调用需要进行设置：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760774006483-501bd34a-ffa0-4f37-ba0a-172e32e11893.png"></p><p>在LangChain4j中，DeepSeek和GPT一样也使用了OpenAI的接口标准，因此也使用OpenAiChatModel进行接入。</p><p>修改项目的application.properties配置文件中关于大模型的配置信息为如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#DeepSeek</span><br><span class="line">langchain4j.open-ai.chat-model.base-url=https://api.deepseek.com</span><br><span class="line">langchain4j.open-ai.chat-model.api-key=$&#123;DEEP_SEEK_API_KEY&#125;</span><br><span class="line">#DeepSeek-V3</span><br><span class="line">langchain4j.open-ai.chat-model.model-name=deepseek-chat</span><br><span class="line">#DeepSeek-R1 推理模型</span><br><span class="line">#langchain4j.open-ai.chat-model.model-name=deepseek-reasoner</span><br></pre></td></tr></table></figure><h2 id="启动测试类"><a href="#启动测试类" class="headerlink" title="启动测试类"></a>启动测试类</h2><p>继续使用之前在测试类中创建的contextChatModel方法，执行结果如下所示：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760774533817-7beb8e8b-fa78-4c45-8eb9-5c51d22fec02.png"></p><h1 id="接入阿里百炼"><a href="#接入阿里百炼" class="headerlink" title="接入阿里百炼"></a>接入阿里百炼</h1><h2 id="阿里百炼简介"><a href="#阿里百炼简介" class="headerlink" title="阿里百炼简介"></a>阿里百炼简介</h2><p> 阿里云百炼是 2023 年 10 月推出的，它集成了阿里的通义系列大模型和第三方大模型，涵盖文本、图像、音视频等不同模态。</p><p>阿里云百炼的优势如下：</p><p>（1）集成超百款大模型 API，模型选择丰富；</p><p>（2）5-10 分钟就能低代码快速构建智能体，应用构建高效；</p><p>（3）提供全链路模型训练、评估工具及全套应用开发工具，模型服务多元；</p><p>（4）在线部署可按需扩缩容，新用户有千万 token 免费送，业务落地成本低。</p><p>支持接入的模型列表，可以点击 <a href="https://help.aliyun.com/zh/model-studio/models">这里</a> ：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760778147553-d3e5c434-3925-4018-9e85-1e03465d07dc.png"></p><p>以及 <a href="https://bailian.console.aliyun.com/?productCode=p_efm#/model-market">模型广场</a>：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760778121364-16f8661a-0dc5-450d-b9a7-a5f9d823207e.png"></p><h2 id="申请免费体验"><a href="#申请免费体验" class="headerlink" title="申请免费体验"></a>申请免费体验</h2><p>第一步，点击进入免费体验页面：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760778200501-b4c56606-3490-44b6-9c94-10ee3eef853b.png"></p><p>第二步，点击免费体验：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760778219055-3ab59e02-9001-4446-81ee-4a7708209aa3.png"></p><p>第三步，点击开通服务：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760778233350-bf81dff8-e191-49ac-942a-12999d5407fe.png"></p><p>第四步，确认开通：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760778255872-09d3075e-6f9c-430e-8d1f-7ab8bba15b44.png"></p><h2 id="获取开发参数-1"><a href="#获取开发参数-1" class="headerlink" title="获取开发参数"></a>获取开发参数</h2><p>点击 <a href="https://bailian.console.aliyun.com/">这里</a> 访问阿里百炼官网，注册账号，然后充值，并获取对应的base_url和api_key：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760774825221-bb59ba98-e3f1-4ca3-ae56-eb0341435795.png"></p><h2 id="配置开发参数-1"><a href="#配置开发参数-1" class="headerlink" title="配置开发参数"></a>配置开发参数</h2><p>为了apikay的安全，建议将其配置在服务器的环境变量中，变量名自定义即可，如 DASH_SCOPE_API_KEY。</p><h2 id="添加对应依赖"><a href="#添加对应依赖" class="headerlink" title="添加对应依赖"></a>添加对应依赖</h2><p>点击 <a href="https://bailian.console.aliyun.com/tab=doc#/doc/?type=model&url=2840915">这里</a> 访问阿里百炼接口文档，首次调用需要进行设置：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760774948972-ccd3bdd3-f3e1-4c65-84d7-9bc333956fa4.png"></p><p>在LangChain4j中，阿里百炼使用的不是标准的OpenAI接口，是社区版所以需要单独进行配置。</p><p>第一步，在项目的pom文件中新增对应的依赖：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 接入阿里云百炼平台 --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;langchain4j-community-dashscope-spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependencyManagement&gt;</span><br><span class="line">    &lt;!--引入阿里云百炼平台管理清单--&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;langchain4j-community-bom&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;langchain4j.version&#125;&lt;/version&gt;</span><br><span class="line">        &lt;type&gt;pom&lt;/type&gt;</span><br><span class="line">        &lt;scope&gt;import&lt;/scope&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">&lt;/dependencyManagement&gt;</span><br></pre></td></tr></table></figure><p>第二步，在项目的application.properties配置文件中新增如下配置信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#阿里百炼平台</span><br><span class="line">langchain4j.community.dashscope.chat-model.api-key=$&#123;DASH_SCOPE_API_KEY&#125;</span><br><span class="line">langchain4j.community.dashscope.chat-model.model-name=qwen-plus</span><br></pre></td></tr></table></figure><h2 id="启动测试类-1"><a href="#启动测试类-1" class="headerlink" title="启动测试类"></a>启动测试类</h2><p>在之前的测试类中创建一个名为contextQwen的方法，里面的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">@SpringBootTest</span><br><span class="line">class YusiAiLangchain4jApplicationTests &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    private QwenChatModel qwenChatModel;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * Qwen语言模型接入测试</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    void contextQwen() &#123;</span><br><span class="line">        //向模型提问</span><br><span class="line">        String answer = qwenChatModel.chat(&quot;你好，你是谁？&quot;);</span><br><span class="line">        //输出结果</span><br><span class="line">        System.out.println(answer);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行结果如下所示：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760779540224-41b904cb-4388-4c7e-b6e4-e9fcfc3cbca4.png"></p><h2 id="测试通义万相"><a href="#测试通义万相" class="headerlink" title="测试通义万相"></a>测试通义万相</h2><p>在之前的测试类中创建一个名为testDashScopeWanx的方法，里面的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 生成图片测试</span><br><span class="line"> */</span><br><span class="line">@Test</span><br><span class="line">void testDashScopeWanx() &#123;</span><br><span class="line">    WanxImageModel wanxImageModel = WanxImageModel.builder()</span><br><span class="line">            .modelName(&quot;wanx2.1-t2i-plus&quot;)</span><br><span class="line">            .apiKey(&quot;sk-85c1140b2220426ab78fc2a8948f3116&quot;)</span><br><span class="line">            .build();</span><br><span class="line">    Response&lt;Image&gt; response = wanxImageModel.generate(&quot;奇幻森林精灵：在一片弥漫着轻柔薄雾的古老森林深处，阳光透过茂密枝叶洒下金色光斑。一位身材娇小、长着透明薄翼的精灵少女站在一朵硕大的蘑菇上。她有着海藻般的绿色长发，发间点缀着蓝色的小花，皮肤泛着珍珠般的微光。身上穿着由翠绿树叶和白色藤蔓编织而成的连衣裙，手中捧着一颗散发着柔和光芒的水晶球，周围环绕着五彩斑斓的蝴蝶，脚下是铺满苔藓的地面，蘑菇和蕨类植物丛生，营造出神秘而梦幻的氛围。&quot;);</span><br><span class="line">    System.out.println(response.content().url());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>之后运行上述代码，将会输出一张照片的地址，访问该地址，照片如下所示：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760780274687-4a59db34-aa84-4e0a-828b-261643517c57.png"></p><h2 id="测试DeepSeek"><a href="#测试DeepSeek" class="headerlink" title="测试DeepSeek"></a>测试DeepSeek</h2><p>也可以在阿里百炼上集成第三方大模型，如DeepSeek，只需将配置参数上的base-url参数指定到百炼平台，使用百炼上的大模型名称和apiKey即可。如集成百炼-deepseek，此时添加的参数如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#集成百炼-deepseek</span><br><span class="line">langchain4j.open-ai.chat-model.base-url=https://dashscope.aliyuncs.com/compatible-mode/v1</span><br><span class="line">langchain4j.open-ai.chat-model.api-key=$&#123;DASH_SCOPE_API_KEY&#125;</span><br><span class="line">langchain4j.open-ai.chat-model.model-name=deepseek-v3</span><br><span class="line">langchain4j.open-ai.chat-model.temperature=0.9</span><br></pre></td></tr></table></figure><p>temperature是温度系数，取值范围通常在 0 到 1 之间。值越高，模型的输出越随机、富有创造性；值越低，输出越确定、保守。这里设置为 0.9，意味着模型会有一定的随机性，生成的回复可能会比较多样化。</p><h1 id="Ollama本地部署"><a href="#Ollama本地部署" class="headerlink" title="Ollama本地部署"></a>Ollama本地部署</h1><h2 id="为什么要本地部署"><a href="#为什么要本地部署" class="headerlink" title="为什么要本地部署"></a>为什么要本地部署</h2><p><a href="https://ollama.com/">Ollama</a> 是一个本地部署大模型的工具，使用 Ollama 进行本地部署有以下多方面的原因：</p><ul><li>数据隐私与安全：对于金融、医疗、法律等涉及大量敏感数据的行业，数据安全至关重要；</li><li>离线可用性：在网络不稳定或无法联网的环境中，本地部署的 Ollama 模型仍可正常运行；</li><li>降低成本：云服务通常按使用量收费，长期使用下来费用较高。而 Ollama 本地部署，只需一次性投入硬件成本，对于需要频繁使用大语言模型且对成本敏感的用户或企业来说，能有效节约成本；</li><li>部署流程简单：只需通过简单的命令 “ollama run &lt; 模型名&gt;”，就可以自动下载并运行所需的模型；</li><li>灵活扩展与定制：可对模型微调，以适配垂直领域需求。</li></ul><h2 id="在ollama上部署DeepSeek"><a href="#在ollama上部署DeepSeek" class="headerlink" title="在ollama上部署DeepSeek"></a>在ollama上部署DeepSeek</h2><p>第一步，下载并安装ollama：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760780734847-7cc173dd-f142-4874-99ce-efa18ed8a5b5.png"></p><p>第二步，查看<a href="https://ollama.com/search">模型列表</a>，选择要部署的模型：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760780811384-f66d24cc-46a8-4b59-b4f7-5319587bae95.png"></p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760781028469-707678c4-44ad-43de-9c0b-ec0df1a4b15f.png"></p><p>第三步，执行命令“ollama run deepseek-r1:1.5b”运行大模型，如果是第一次运行则会先下载大模型：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760781125891-e610125a-5b8f-4068-baff-9d0e6e73109b.png"></p><h2 id="Ollama常用命令"><a href="#Ollama常用命令" class="headerlink" title="Ollama常用命令"></a>Ollama常用命令</h2><p>下图是Ollama的常用命令：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760781185609-8aa39545-6e55-475d-9ac8-db3dc5458dd7.png"></p><p>举个例子，查看一下当前已经下载的模型：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\gutsy&gt;ollama list</span><br><span class="line">NAME                ID              SIZE      MODIFIED</span><br><span class="line">deepseek-r1:1.5b    e0979632db5a    1.1 GB    4 months ago</span><br><span class="line">qwen3:1.7b          8f68893c685c    1.4 GB    4 months ago</span><br></pre></td></tr></table></figure><h1 id="langchain4j集成Ollama"><a href="#langchain4j集成Ollama" class="headerlink" title="langchain4j集成Ollama"></a>langchain4j集成Ollama</h1><h2 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h2><p>点击 <a href="https://docs.langchain4j.dev/integrations/language-models/ollama#get-started">这里</a> 阅读langchain4j对于Ollama的支持文档：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760781346891-bd9f762d-8415-4d76-8fe9-00b6337eab26.png"></p><p>由于我们使用的是SpringBoot，因此在项目的pom文件中新增如下依赖：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 接入ollama --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;langchain4j-ollama-spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><h2 id="配置模型参数-1"><a href="#配置模型参数-1" class="headerlink" title="配置模型参数"></a>配置模型参数</h2><p>请注意通过Ollama部署的模型的端口都是11434，因此在其application.properties配置文件新增对应配置项信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#ollama</span><br><span class="line">langchain4j.ollama.chat-model.base-url=http://localhost:11434</span><br><span class="line">langchain4j.ollama.chat-model.model-name=deepseek-r1:1.5b</span><br><span class="line"># 创造性控制</span><br><span class="line"># 0.7到1.2‌：适用于需要较高创造性的场景，如诗歌生成或头脑风暴</span><br><span class="line"># 0.3到1.0‌：适用于需要较高稳定性和多样性的场景，如技术文档或法律文书的生成</span><br><span class="line">langchain4j.ollama.chat-model.temperature=0.8</span><br><span class="line"># 模型进行通信的超时时间为60秒</span><br><span class="line">langchain4j.ollama.chat-model.timeout=PT60S</span><br><span class="line">langchain4j.ollama.chat-model.log-requests=true</span><br><span class="line">langchain4j.ollama.chat-model.log-responses=true</span><br></pre></td></tr></table></figure><h2 id="创建测试用例"><a href="#创建测试用例" class="headerlink" title="创建测试用例"></a>创建测试用例</h2><p>我们可以在测试类中新建一个名为testOllama的方法，然后测试我们刚才下载本地部署的deepseek-r1模型：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">@SpringBootTest</span><br><span class="line">class YusiAiLangchain4jApplicationTests &#123;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private OllamaChatModel ollamaChatModel;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 测试Ollama</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    public void testOllama() &#123;</span><br><span class="line">        //向模型提问</span><br><span class="line">        String answer = ollamaChatModel.chat(&quot;你好，你是谁？&quot;);</span><br><span class="line">        //输出结果</span><br><span class="line">        System.out.println(answer);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行上述测试类，结果如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供帮助。</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h1&gt;&lt;p&gt;本篇介绍LangChain4j如何接入大模型，具体包括DeepSeek和阿里百炼。&lt;/p&gt;
&lt;h1 id=&quot;接入DeepSe</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>LangChain4j之快速入门</title>
    <link href="http://aichating.xyz/2025/07/05/2025-10-lang-chain-4j-1-qucik-start/"/>
    <id>http://aichating.xyz/2025/07/05/2025-10-lang-chain-4j-1-qucik-start/</id>
    <published>2025-07-05T06:01:20.000Z</published>
    <updated>2025-07-06T12:31:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="LangChain4j入门"><a href="#LangChain4j入门" class="headerlink" title="LangChain4j入门"></a>LangChain4j入门</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>LangChain4j的目标，是简化将大语言模型（LLM - Large Language Model）集成到 Java 应用程序中的过程。</p><h2 id="历史背景"><a href="#历史背景" class="headerlink" title="历史背景"></a>历史背景</h2><p>2022年11月30日OpenAI发布了Chat GPT（GPT-3.5)，而在同年10月，Harrison Chase 发布了基于Python的LangChain，随后同时包含了Python版和JavaScript（LangChain.js）版的LangChain 也发布了，直到2023年 11 月，Quarkus 发布了 <a href="https://docs.langchain4j.dev/">LangChain4j</a> 的0.1版本，2025年2月发布了1.0 - Beta1 版本，4月发布了1.0 - Beta4 版本，截止到10月18日，最新版本为1.7.1。</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760766992041-02b7f4d0-8556-43b0-b744-93429c9ecd48.png"></p><h2 id="主要功能"><a href="#主要功能" class="headerlink" title="主要功能"></a>主要功能</h2><p>（1）与大型语言模型和向量数据库的便捷交互。</p><p>通过统一的应用程序编程接口（API），可以轻松访问所有主要的商业和开源大型语言模型以及向量数据库，使你能够构建聊天机器人、智能助手等应用。</p><p>（2）专为Java打造。</p><p>借助SpringBoot集成，能够将大模型集成到java 应用程序中。大型语言模型与Java之间实现了双向集成，即你可以从Java中调用大型语言模型，同时也允许大型语言模型反过来调用你的Java代码。</p><p>（3）智能代理（Agent）、工具（Tools）、检索增强生成（RAG）。</p><h2 id="应用示例"><a href="#应用示例" class="headerlink" title="应用示例"></a>应用示例</h2><p>（1）你想要实现一个自定义的由人工智能驱动的聊天机器人，它可以访问你的数据，并按照你期望的方式运行：</p><ul><li>客户支持聊天机器人，它可以礼貌地回答客户问题；</li><li>处理 / 更改 / 取消订单；</li><li>教育助手，它可以教授各种学科，解释不清楚的部分，评估用户的理解/知识水平。</li></ul><p>（2）你想要处理大量的非结构化数据（文件、网页等），并从中提取结构化信息，如：</p><ul><li>从客户评价和支持聊天记录中提取有效评价；</li><li>从竞争对手的网站上提取有趣的信息；</li><li>从求职者的简历中提取有效信息。</li></ul><p>（3）你想要生成信息，如：</p><ul><li>为你的每个客户量身定制的电子邮件；</li><li>为你的应用程序/网站生成内容，如博客文章或者故事、</li></ul><p>（4）你想要转换信息，如：</p><ul><li>总结；</li><li>校对和修改；</li><li>翻译。</li></ul><h1 id="创建SpringBoot项目"><a href="#创建SpringBoot项目" class="headerlink" title="创建SpringBoot项目"></a>创建SpringBoot项目</h1><p>本项目基于JDK17、SpringBoot3.5、LangChain4j1.0.0-beta3搭建，这是主要版本说明。</p><p>第一步，创建一个名为yusi-ai-langchain4j的项目：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760769629542-270ecdfc-cc0e-4042-ba16-40b99672b0d5.png"></p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760769654786-a408c077-8ada-4930-8a93-b7dec0c19e23.png"></p><p>第二步，在其pom文件的project节点中新增如下依赖：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">&lt;properties&gt;</span><br><span class="line">    &lt;maven.compiler.source&gt;17&lt;/maven.compiler.source&gt;</span><br><span class="line">    &lt;maven.compiler.target&gt;17&lt;/maven.compiler.target&gt;</span><br><span class="line">    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;</span><br><span class="line">    &lt;spring-boot.version&gt;3.5.6&lt;/spring-boot.version&gt;</span><br><span class="line">    &lt;knife4j.version&gt;4.3.0&lt;/knife4j.version&gt;</span><br><span class="line">&lt;/properties&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;dependencies&gt;</span><br><span class="line">    &lt;!-- web应用程序核心依赖 --&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;!-- 编写和运行测试用例 --&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</span><br><span class="line">        &lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;!-- 前后端分离中的后端接口测试工具 --&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;knife4j-openapi3-jakarta-spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;knife4j.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">&lt;/dependencies&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependencyManagement&gt;</span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;!--引入SpringBoot依赖管理清单--&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;$&#123;spring-boot.version&#125;&lt;/version&gt;</span><br><span class="line">            &lt;type&gt;pom&lt;/type&gt;</span><br><span class="line">            &lt;scope&gt;import&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line">&lt;/dependencyManagement&gt;</span><br></pre></td></tr></table></figure><p>第三步，修改项目配置文件application.properties为如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spring.application.name=yusi-ai-langchain4j</span><br><span class="line"># web服务访问端口</span><br><span class="line">server.port=8080</span><br></pre></td></tr></table></figure><p>第四步，启动项目，访问如下地址：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/doc.html</span><br></pre></td></tr></table></figure><p>页面效果如下所示，则说明项目配置成功：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760770310200-9c41615c-3c9a-41a0-a2f2-3e0ef600f3cc.png"></p><p>出现这个页面是因为我们使用了<code>Knife4j</code> ，它是一个 增强版的<code>Swagger UI</code>，用于在 <code>Java</code> 项目（尤其是 <code>Spring Boot</code>）中自动生成 接口文档。</p><h1 id="开始使用"><a href="#开始使用" class="headerlink" title="开始使用"></a>开始使用</h1><p>点击 <a href="https://docs.langchain4j.dev/get-started">这里</a> 阅读对接文档，本部分内容就是对于该文档的学习和记录，注意这里先介绍的是与普通Maven项目的集成，后续会介绍与SpringBoot项目的集成。</p><h2 id="LangChain4j的库结构"><a href="#LangChain4j的库结构" class="headerlink" title="LangChain4j的库结构"></a>LangChain4j的库结构</h2><p>LangChain4j 具有模块化设计，包括三个模块，分别是langchain4j-core模块、主langchain4j模块以及集成模块：</p><p>（1）langchain4j-core模块：定义了核心抽象概念（如聊天语言模型和嵌入存储）及其 API；</p><p>（2）主langchain4j模块：包含很多工具，如文档加载器、聊天记忆实现，以及诸如人工智能服务等高层功能；</p><p>（3）大量的langchain4j-{集成}模块：每个模块都将各种大语言模型提供商和嵌入存储集成到LangChain4j中。开发者可以独立使用langchain4j-{集成}模块，如需更多功能，只需导入主langchain4j依赖项即可。</p><h2 id="添加LangChain4j相关依赖"><a href="#添加LangChain4j相关依赖" class="headerlink" title="添加LangChain4j相关依赖"></a>添加LangChain4j相关依赖</h2><p>在项目的pom文件中新增如下依赖：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;properties&gt;</span><br><span class="line">    &lt;langchain4j.version&gt;1.0.0-beta3&lt;/langchain4j.version&gt;</span><br><span class="line">&lt;/properties&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependencies&gt;</span><br><span class="line">    &lt;!-- 基于open-ai的langchain4j接口：ChatGPT、deepseek都是open-ai标准下的大模型 --&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;langchain4j-open-ai&lt;/artifactId&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">&lt;/dependencies&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependencyManagement&gt;</span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;!--引入langchain4j依赖管理清单--&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;langchain4j-bom&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;$&#123;langchain4j.version&#125;&lt;/version&gt;</span><br><span class="line">            &lt;type&gt;pom&lt;/type&gt;</span><br><span class="line">            &lt;scope&gt;import&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line">&lt;/dependencyManagement&gt;</span><br></pre></td></tr></table></figure><h2 id="创建测试用例"><a href="#创建测试用例" class="headerlink" title="创建测试用例"></a>创建测试用例</h2><p>请注意，接入任何一个大模型都需要先去申请apiKey，如果你暂时没有密钥，也可以使用LangChain4j 提供的演示密钥，这个密钥是免费的，有使用配额限制，且仅限于gpt-4o-mini模型。</p><p>回到项目中，在其测试类的contextLoads方法中接入gpt-4o-mini模型进行测试：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">@SpringBootTest</span><br><span class="line">class YusiAiLangchain4jApplicationTests &#123;</span><br><span class="line">    /**</span><br><span class="line">     * gpt-4o-mini语言模型接入测试</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    void contextLoads() &#123;</span><br><span class="line">        //初始化模型</span><br><span class="line">        OpenAiChatModel model = OpenAiChatModel.builder()</span><br><span class="line">                .baseUrl(&quot;http://langchain4j.dev/demo/openai/v1&quot;)</span><br><span class="line">                .apiKey(&quot;demo&quot;)  //设置模型apiKey</span><br><span class="line">                .modelName(&quot;gpt-4o-mini&quot;)  //设置模型名称</span><br><span class="line">                .build();</span><br><span class="line">        //向模型提问</span><br><span class="line">        String answer = model.chat(&quot;你好，你是谁？&quot;);</span><br><span class="line">        //输出结果</span><br><span class="line">        System.out.println(answer);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行上述测试类，结果如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">你好！我是一个人工智能助手，旨在回答问题和提供信息。有什么我可以帮助你的吗？</span><br></pre></td></tr></table></figure><p>上面我们使用的是LangChain4j提供的代理服务器，该代理服务器会将演示密钥替换成真实密钥，再将请求转发给OpenAI API，所以需要设置baseUrl，实际上如果你的apiKey为demo，则可省略baseUrl的配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">OpenAiChatModel model = OpenAiChatModel.builder()</span><br><span class="line">    .apiKey(&quot;demo&quot;)</span><br><span class="line">    .modelName(&quot;gpt-4o-mini&quot;)</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure><h1 id="与SpringBoot整合"><a href="#与SpringBoot整合" class="headerlink" title="与SpringBoot整合"></a>与SpringBoot整合</h1><p>点击 <a href="https://docs.langchain4j.dev/tutorials/spring-boot-integration">这里</a> 阅读相关文档，学习任何新技术，必须得阅读对应的文档，不然学的不够系统和全面。</p><h2 id="替换依赖"><a href="#替换依赖" class="headerlink" title="替换依赖"></a>替换依赖</h2><p>将langchain4j-open-ai 替换成 langchain4j-open-ai-spring-boot-starter，更新依赖信息：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760772187606-6a5a1d0c-4d8f-4141-a1c7-cacd50e84eba.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 基于open-ai的langchain4j接口：ChatGPT、deepseek都是open-ai标准下的大模型 --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;langchain4j-open-ai-spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><h2 id="配置模型参数"><a href="#配置模型参数" class="headerlink" title="配置模型参数"></a>配置模型参数</h2><p>在项目的application.properties配置文件中，新增如下配置信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#langchain4j测试模型</span><br><span class="line">langchain4j.open-ai.chat-model.base-url=http://langchain4j.dev/demo/openai/v1</span><br><span class="line">langchain4j.open-ai.chat-model.api-key=demo</span><br><span class="line">langchain4j.open-ai.chat-model.model-name=gpt-4o-mini</span><br><span class="line"></span><br><span class="line">#请求和响应日志</span><br><span class="line">langchain4j.open-ai.chat-model.log-requests=true</span><br><span class="line">langchain4j.open-ai.chat-model.log-responses=true</span><br><span class="line">#启用日志debug级别</span><br><span class="line">logging.level.root=debug</span><br></pre></td></tr></table></figure><h2 id="创建测试用例-1"><a href="#创建测试用例-1" class="headerlink" title="创建测试用例"></a>创建测试用例</h2><p>在这种情况下，将自动创建一个实例<code>OpenAiChatModel</code>，开发者可以在需要的地方注入该实例，示例代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@Autowired</span><br><span class="line">private OpenAiChatModel openAiChatModel;</span><br><span class="line"></span><br><span class="line">@Test</span><br><span class="line">public void testSpringBoot() &#123;</span><br><span class="line">    //向模型提问</span><br><span class="line">    String answer = openAiChatModel.chat(&quot;你好，你是谁？&quot;);</span><br><span class="line">    //输出结果</span><br><span class="line">    System.out.println(answer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们可以在测试类的contextChatModel方法中接入gpt-4o-mini模型进行测试：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">@SpringBootTest</span><br><span class="line">class YusiAiLangchain4jApplicationTests &#123;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private OpenAiChatModel openAiChatModel;</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * gpt-4o-mini语言模型接入测试</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    void contextChatModel() &#123;</span><br><span class="line">        //向模型提问</span><br><span class="line">        String answer = openAiChatModel.chat(&quot;你好，你是谁？&quot;);</span><br><span class="line">        //输出结果</span><br><span class="line">        System.out.println(answer);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行上述测试类，结果如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">你好！我是一个人工智能助手，旨在回答你的问题和提供帮助。你有什么需要了解的呢？</span><br></pre></td></tr></table></figure><h1 id="大模型评测基准"><a href="#大模型评测基准" class="headerlink" title="大模型评测基准"></a>大模型评测基准</h1><p><a href="https://superclueai.com/">SuperCLUE</a> 是由国内 CLUE 学术社区于 2023 年 5 月推出的中文通用大模型综合性评测基准：</p><p>（1）<strong>评测目的</strong>。全面评估中文大模型在语义理解、逻辑推理、代码生成等 10 项基础能力，以及涵盖数学、物理、社科等 50 多学科的专业能力，旨在回答在通用大模型发展背景下，中文大模型的效果情况，包括不同任务效果、与国际代表性模型的差距、与人类的效果对比等问题。</p><p>（2）<strong>特色优势</strong>。针对中文特性任务，如成语、诗歌、字形等设立专项评测，使评测更符合中文语言特点。通过 3700 多道客观题和匿名对战机制，动态追踪国内外主流模型，如 GPT-4、文心一言、通义千问等的表现差异，保证评测的客观性和时效性。</p><p>（3）<strong>行业影响</strong>。作为中文领域权威测评社区，其评测结果被学界和产业界广泛引用，例如商汤 “日日新 5.0” 和百度文心大模型均通过 SuperCLUE 验证技术突破，推动了中文 NLP 技术生态的迭代，为中文大模型的发展和优化提供了重要的参考依据，促进了中文大模型技术的不断进步和应用。</p><p>如果开发者想知道LangChain4j所支持接入的大模型，则可以点击 <a href="https://docs.langchain4j.dev/integrations/language-models/">这里</a> 进行查阅：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1760773549373-42e19632-5cdc-4aa8-8b32-845d29ba21ad.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;LangChain4j入门&quot;&gt;&lt;a href=&quot;#LangChain4j入门&quot; class=&quot;headerlink&quot; title=&quot;LangChain4j入门&quot;&gt;&lt;/a&gt;LangChain4j入门&lt;/h1&gt;&lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; cla</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>SpringAi学习之ChatModel API</title>
    <link href="http://aichating.xyz/2025/06/02/2025-9-spring-ai-5-chat-model-API/"/>
    <id>http://aichating.xyz/2025/06/02/2025-9-spring-ai-5-chat-model-API/</id>
    <published>2025-06-02T06:01:20.000Z</published>
    <updated>2025-06-02T14:31:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>ChatClient API为开发者提供了将人工智能驱动的聊天补全功能集成到其应用程序中的能力。它利用预训练的语言模型（如GPT，即生成式预训练转换器），以自然语言生成类人化的用户输入响应。</p><p>API的工作原理通常是向AI模型发送提示或部分对话，然后AI模型会根据其训练数据和对自然语言模式的理解生成对话的补全或延续内容。之后，生成的完整响应会返回给应用程序，应用程序可以将其呈现给用户，或用于进一步处理。</p><p><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Spring AI ChatModel API&lt;/font&gt;</code> 旨在成为一个简单且可移植的接口，用于与各种 AI 模型 交互，使开发人员能够以最少的代码更改在不同模型之间切换。这种设计符合 Spring 的模块化和可互换性理念。</p><p>此外，借助诸如用于输入封装的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Prompt&lt;/font&gt;</code>和用于输出处理的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatResponse&lt;/font&gt;</code>等配套类，聊天模型API统一了与AI模型的通信。它管理着请求准备和响应解析的复杂性，提供了直接且简化的API交互方式。</p><h1 id="API概述"><a href="#API概述" class="headerlink" title="API概述"></a>API概述</h1><p>接下来我们开始学习Spring AI聊天模型API接口及相关类的说明。</p><h2 id="聊天模型-ChatModel"><a href="#聊天模型-ChatModel" class="headerlink" title="聊天模型(ChatModel)"></a>聊天模型(ChatModel)</h2><p>以下是ChatModel接口的定义：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public interface ChatModel extends Model&lt;Prompt, ChatResponse&gt;, StreamingChatModel &#123;</span><br><span class="line"></span><br><span class="line">default String call(String message) &#123;...&#125;</span><br><span class="line"></span><br><span class="line">  @Override</span><br><span class="line">ChatResponse call(Prompt prompt);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>带有<code>String</code>参数的<code>call()</code>方法简化了初始使用，避免了更复杂的<code>Prompt</code>和<code>ChatResponse</code>类的复杂性。在实际应用中，更常见的是使用接收<code>Prompt</code>实例并返回<code>ChatResponse</code>的<code>call()</code>方法。</p><h2 id="流式聊天模型-StreamingChatModel"><a href="#流式聊天模型-StreamingChatModel" class="headerlink" title="流式聊天模型(StreamingChatModel)"></a>流式聊天模型(StreamingChatModel)</h2><p><font style="color:rgb(25, 30, 30);">以</font>下是StreamingChatModel接口的定义：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public interface StreamingChatModel extends StreamingModel&lt;Prompt, ChatResponse&gt; &#123;</span><br><span class="line"></span><br><span class="line">    default Flux&lt;String&gt; stream(String message) &#123;...&#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">  Flux&lt;ChatResponse&gt; stream(Prompt prompt);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;stream()&lt;/font&gt;</code>方法接受与<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatModel&lt;/font&gt;</code>类似的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;String&lt;/font&gt;</code>或<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Prompt&lt;/font&gt;</code>参数，但它使用响应式Flux API来流式传输响应。</p><h2 id="提示词-Prompt"><a href="#提示词-Prompt" class="headerlink" title="提示词(Prompt)"></a><font style="color:rgb(25, 30, 30);">提示词(Prompt)</font></h2><h3 id="提示词"><a href="#提示词" class="headerlink" title="提示词"></a>提示词</h3><p><font style="color:rgb(25, 30, 30);">Prompt是一种</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ModelRequest&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">，它封装了一个</font><a href="https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/messages/Message.java"><font style="color:rgb(25, 30, 30);">消息</font></a><font style="color:rgb(25, 30, 30);">对象列表和可选的模型请求选项。以下列表展示了</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Prompt&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">类的简化版本，不包含构造函数和其他实用方法：</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public class Prompt implements ModelRequest&lt;List&lt;Message&gt;&gt; &#123;</span><br><span class="line"></span><br><span class="line">    private final List&lt;Message&gt; messages;</span><br><span class="line"></span><br><span class="line">    private ChatOptions modelOptions;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public ChatOptions getOptions() &#123;...&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public List&lt;Message&gt; getInstructions() &#123;...&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="消息"><a href="#消息" class="headerlink" title="消息"></a><font style="color:rgb(25, 30, 30);">消息</font></h3><p><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Message&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">接口封装了</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Prompt&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">文本内容、一组元数据属性以及一种称为</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;MessageType&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">的分类。该接口的定义如下：</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public interface Content &#123;</span><br><span class="line">String getText();</span><br><span class="line">Map&lt;String, Object&gt; getMetadata();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">public interface Message extends Content &#123;</span><br><span class="line">MessageType getMessageType();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><font style="color:rgb(25, 30, 30);">多模态消息类型还实现了</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;MediaContent&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">接口，该接口提供了一个</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Media&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">内容对象列表：</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public interface MediaContent extends Content &#123;</span><br><span class="line">Collection&lt;Media&gt; getMedia();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Message&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">接口有多种实现，对应AI模型可以处理的消息类别：</font></p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762590520452-bb149a64-c892-47ac-8cb0-d72cf293f0a9.png"></p><p><font style="color:rgb(25, 30, 30);">聊天补全端点会根据对话角色区分消息类别，这通过</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;MessageType&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">得到有效映射。</font></p><p><font style="color:rgb(25, 30, 30);"></font></p><p><font style="color:rgb(25, 30, 30);">举个例子，OpenAI识别了不同对话角色的消息类别，如</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;system&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">、</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;user&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">、</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;function&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);"> 或 </font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;assistant&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">。虽然“MessageType”一词可能暗示特定的消息格式，但在此语境中，它实际上指的是消息在对话中所扮演的角色。对于不使用特定角色的AI模型，</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;UserMessage&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">的实现充当标准类别，通常代表用户生成的查询或指令。要了解</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Prompt&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">和</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Message&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">的实际应用及其关系，尤其是在这些角色或消息类别的背景下，需要参阅</font><a href="https://docs.spring.io/spring-ai/reference/api/prompt.html"><font style="color:rgb(21, 101, 192);">提示词（Prompts）</font></a><font style="color:rgb(25, 30, 30);">部分的详细解释。</font></p><h3 id="聊天选项-chat-Options"><a href="#聊天选项-chat-Options" class="headerlink" title="聊天选项(chat Options)"></a><font style="color:rgb(25, 30, 30);">聊天选项(chat Options)</font></h3><p><font style="color:rgb(25, 30, 30);">所谓的聊天选项，其实就是可以传递给AI模型的选项。</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatOptions&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">类是</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ModelOptions&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">的子类，用于定义可传递给AI模型的少量可移植选项。</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatOptions&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">类的定义如下：</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">public interface ChatOptions extends ModelOptions &#123;</span><br><span class="line">String getModel();</span><br><span class="line">Float getFrequencyPenalty();</span><br><span class="line">Integer getMaxTokens();</span><br><span class="line">Float getPresencePenalty();</span><br><span class="line">List&lt;String&gt; getStopSequences();</span><br><span class="line">Float getTemperature();</span><br><span class="line">Integer getTopK();</span><br><span class="line">Float getTopP();</span><br><span class="line">ChatOptions copy();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><font style="color:rgb(25, 30, 30);">此外，每个特定于模型的ChatModel/StreamingChatModel实现都可以有自己的选项，这些选项可以传递给AI模型。例如，OpenAI聊天补全模型有其自身的选项，如</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;logitBias&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">、</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;seed&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">和</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;user&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">。</font></p><p><font style="color:rgb(25, 30, 30);"></font></p><p><font style="color:rgb(25, 30, 30);">这是一项强大的功能，允许开发人员在启动应用程序时使用特定于模型的选项，然后在运行时通过</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Prompt&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">请求覆盖这些选项。</font></p><p><font style="color:rgb(25, 30, 30);"></font></p><p><font style="color:rgb(25, 30, 30);">Spring AI 提供了一个复杂的系统，用于配置和使用聊天模型。它允许在启动时设置默认配置，同时也能灵活地在每个请求的基础上覆盖这些设置。这种方法使开发人员能够轻松使用不同的人工智能模型，并根据需要调整参数，所有这些都在 Spring AI 框架提供的统一接口内完成。</font></p><p><font style="color:rgb(25, 30, 30);"></font></p><p><font style="color:rgb(25, 30, 30);">以下流程图展示了Spring AI如何处理聊天模型的配置和执行，它结合了启动和运行时选项：</font></p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762590745794-318d8622-a798-4a7f-8247-ba48046519f5.png"></p><ol><li><font style="color:rgb(25, 30, 30);">启动配置 - ChatModel/StreamingChatModel 会使用“启动”聊天选项进行初始化。这些选项在 ChatModel 初始化期间设置，旨在提供默认配置。</font></li><li><font style="color:rgb(25, 30, 30);">运行时配置 - 对于每个请求，提示词可以包含运行时聊天选项：这些选项可以覆盖启动选项。</font></li><li><font style="color:rgb(25, 30, 30);">选项合并过程 - “合并选项”步骤会将启动选项和运行时选项结合起来。如果提供了运行时选项，它们的优先级高于启动选项。</font></li><li><font style="color:rgb(25, 30, 30);">输入处理——“转换输入”步骤将输入指令转换为原生的、特定于模型的格式。</font></li><li><font style="color:rgb(25, 30, 30);">输出处理——“转换输出”步骤将模型的响应转换为标准化的</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatResponse&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">格式。</font></li></ol><p><font style="color:rgb(25, 30, 30);">将启动选项和运行时选项分开，既可以进行全局配置，也能针对特定请求进行调整。</font></p><h2 id="聊天响应-ChatResponse"><a href="#聊天响应-ChatResponse" class="headerlink" title="聊天响应(ChatResponse)"></a>聊天响应(ChatResponse)</h2><p><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatResponse&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">类的源码如下：</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">public class ChatResponse implements ModelResponse&lt;Generation&gt; &#123;</span><br><span class="line"></span><br><span class="line">  private final ChatResponseMetadata chatResponseMetadata;</span><br><span class="line">private final List&lt;Generation&gt; generations;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public ChatResponseMetadata getMetadata() &#123;...&#125;</span><br><span class="line"></span><br><span class="line">  @Override</span><br><span class="line">public List&lt;Generation&gt; getResults() &#123;...&#125;</span><br><span class="line"></span><br><span class="line">  // other methods omitted</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><font style="color:rgb(25, 30, 30);">ChatResponse 类包含AI模型的输出，每个</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Generation&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">实例包含单个提示可能产生的多个输出之一，同时还包含关于AI模型响应的</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatResponseMe&lt;/font&gt;&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;tadata&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">元数据。</font></p><h2 id="生成结果-Generation"><a href="#生成结果-Generation" class="headerlink" title="生成结果(Generation)"></a>生成结果(Generation)</h2><p><font style="color:rgb(25, 30, 30);">最后</font><font style="color:rgb(25, 30, 30);">，Generation 类继承自</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ModelResult&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">，用于表示模型输出（助手消息）及相关元数据：</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">public class Generation implements ModelResult&lt;AssistantMessage&gt; &#123;</span><br><span class="line"></span><br><span class="line">private final AssistantMessage assistantMessage;</span><br><span class="line">private ChatGenerationMetadata chatGenerationMetadata;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public AssistantMessage getOutput() &#123;...&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public ChatGenerationMetadata getMetadata() &#123;...&#125;</span><br><span class="line"></span><br><span class="line">  // other methods omitted</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="可用实现"><a href="#可用实现" class="headerlink" title="可用实现"></a>可用实现</h1><p><font style="color:rgb(25, 30, 30);">下图展示了统一接口，即</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatModel&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">和</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;StreamingChatModel&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">，这些接口用于与来自不同提供商的各种人工智能聊天模型进行交互，能够轻松集成和切换不同的人工智能服务，同时为客户端应用程序保持一致的应用程序编程接口：</font></p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762591099785-17118063-c76e-41b3-84d5-58739efe3ea6.png"></p><ul><li><font style="color:rgb(25, 30, 30);">OpenAI Chat Completion（支持流式传输、多模态和函数调用）</font></li><li><font style="color:rgb(25, 30, 30);">Microsoft Azure Open AI Chat Completion</font><font style="color:rgb(25, 30, 30);">（支持流式传输和函数调用）</font></li><li><font style="color:rgb(25, 30, 30);">Ollama Chat Completion</font><font style="color:rgb(25, 30, 30);">（支持流式传输、多模态和函数调用）</font></li><li><font style="color:rgb(25, 30, 30);">Hugging Face Chat Completion</font><font style="color:rgb(25, 30, 30);">（不支持流式传输）</font></li><li><font style="color:rgb(25, 30, 30);">Google Vertex AI Gemini Chat Completion</font><font style="color:rgb(25, 30, 30);">（支持流式传输、多模态和函数调用）</font></li><li><font style="color:rgb(25, 30, 30);">Amazon Bedrock</font><ul><li><font style="color:rgb(25, 30, 30);">Cohere Chat Completion</font></li><li><font style="color:rgb(25, 30, 30);">Llama Chat Completion</font></li><li><font style="color:rgb(25, 30, 30);">Titan Chat Completion</font></li><li><font style="color:rgb(25, 30, 30);">Anthropic Chat Completion</font></li><li><font style="color:rgb(25, 30, 30);">Jurassic2 Chat Completion</font></li></ul></li><li><font style="color:rgb(25, 30, 30);">Mistral AI Chat Completion</font><font style="color:rgb(25, 30, 30);">（支持流式传输和函数调用）</font></li><li><font style="color:rgb(25, 30, 30);">Anthropic Chat Completion（支持流式传输和函数调用）</font></li></ul><h1 id="ChatModel-API"><a href="#ChatModel-API" class="headerlink" title="ChatModel API"></a>ChatModel API</h1><p><font style="color:rgb(25, 30, 30);">Spring AI Chat Model API 建立在 Spring AI 通用模型 API 之上，提供聊天特定的抽象和实现。这允许轻松集成和切换不同的 AI 服务，同时保持客户端应用程序的一致 API。以下类图说明了 Spring AI Chat Model API 的主要类和接口：</font></p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762591225361-b8893271-cd30-43ec-86ea-23bcf81836ce.png"></p><h1 id="ChatModels-Comparison"><a href="#ChatModels-Comparison" class="headerlink" title="ChatModels Comparison"></a>ChatModels Comparison</h1><p><font style="color:rgb(25, 30, 30);">下图比较了 Spring AI 支持的各种 Chat Models，详细说明了它们的能力：</font></p><ul><li><font style="color:rgb(25, 30, 30);">多模态</font><font style="color:rgb(25, 30, 30);">：模型可以处理的输入类型（例如，文本、图像、音频、视频）。</font></li><li><font style="color:rgb(25, 30, 30);">工具/功能</font><font style="color:rgb(25, 30, 30);">：模型是否支持函数调用或工具使用。</font></li><li><font style="color:rgb(25, 30, 30);">流式传输：模型是否提供流式响应。</font></li><li><font style="color:rgb(25, 30, 30);">重试：对重试机制的支持。</font></li><li><font style="color:rgb(25, 30, 30);">可观测性</font><font style="color:rgb(25, 30, 30);">：监控和调试的功能。</font></li><li><font style="color:rgb(25, 30, 30);">内置 JSON</font><font style="color:rgb(25, 30, 30);">：对 JSON 输出的原生支持。</font></li><li><font style="color:rgb(25, 30, 30);">本地部署：模型是否可以在本地运行。</font></li><li><font style="color:rgb(25, 30, 30);">与 OpenAI API 兼容：模型是否与 OpenAI 的 API 兼容。</font></li></ul><table><thead><tr><th align="left"><strong><font style="color:rgb(0, 0, 0);">提供商</font></strong></th><th align="left"><strong><font style="color:rgb(0, 0, 0);">多模态</font></strong></th><th align="left"><strong><font style="color:rgb(0, 0, 0);">工具/功能</font></strong></th><th align="left"><strong><font style="color:rgb(0, 0, 0);">流式传输</font></strong></th><th align="left"><strong><font style="color:rgb(0, 0, 0);">重试</font></strong></th><th align="left"><strong><font style="color:rgb(0, 0, 0);">可观测性</font></strong></th><th align="left"><strong><font style="color:rgb(0, 0, 0);">内置JSON</font></strong></th><th align="left"><strong><font style="color:rgb(0, 0, 0);">本地</font></strong></th><th align="left"><strong><font style="color:rgb(0, 0, 0);">与OpenAI API 兼容</font></strong></th></tr></thead><tbody><tr><td align="left"><font style="color:rgb(0, 0, 0);">Anthropic Claude</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text, pdf, image</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">Azure OpenAI</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text, image</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">Google VertexAI Gemini</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text, pdf, image, audio, video</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">Groq (OpenAI-proxy)</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text, image</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">HuggingFace</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">Mistral AI</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">MiniMax</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">Moonshot AI</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">NVIDIA (OpenAI-proxy)</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text, image</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">OCI GenAI/Cohere</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">Ollama</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text, image</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">OpenAI</font></td><td align="left"><font style="color:rgb(0, 0, 0);">In: text, image Out: text, audio</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">Perplexity (OpenAI-proxy)</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">QianFan</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">ZhiPu AI</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">Watsonx.AI</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">Amazon Bedrock Converse</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text, image, video, docs (pdf, html, md, docx …)</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">是</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">Amazon Bedrock/Cohere</font><br/><font style="color:rgb(0, 0, 0);"> (已弃用，转而使用 Bedrock Converse)</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">Amazon Bedrock/Jurassic</font><br/><font style="color:rgb(0, 0, 0);"> (已弃用，转而使用 Bedrock Converse)</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">Amazon Bedrock/Llama</font><br/><font style="color:rgb(0, 0, 0);"> (已弃用，转而使用 Bedrock Converse)</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">Amazon Bedrock/Titan</font><br/><font style="color:rgb(0, 0, 0);"> (已弃用，转而使用 Bedrock Converse)</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td></tr><tr><td align="left"><font style="color:rgb(0, 0, 0);">Amazon Bedrock/Anthropic 3</font><br/><font style="color:rgb(0, 0, 0);"> (已弃用，转而使用 Bedrock Converse)</font></td><td align="left"><font style="color:rgb(0, 0, 0);">text</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td><td align="left"><font style="color:rgb(0, 0, 0);">否</font></td></tr></tbody></table><p><font style="color:rgb(25, 30, 30);">请注意，表格中的“已弃用，转而使用 Bedrock Converse”表示该服务已被 Amazon Bedrock Converse 替代。这个表格为您提供了不同 Chat Models 的功能对比，方便您根据需求选择合适的模型。</font></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h1&gt;&lt;p&gt;ChatClient API为开发者提供了将人工智能驱动的聊天补全功能集成到其应用程序中的能力。它利用预训练的语言模型（如G</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>SpringAi学习之Advisors API</title>
    <link href="http://aichating.xyz/2025/05/24/2025-8-spring-ai-4-advisors-API/"/>
    <id>http://aichating.xyz/2025/05/24/2025-8-spring-ai-4-advisors-API/</id>
    <published>2025-05-24T11:01:20.000Z</published>
    <updated>2025-05-24T14:31:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="顾问-API"><a href="#顾问-API" class="headerlink" title="顾问 API"></a><font style="color:rgb(25, 30, 30);">顾问</font> API</h1><p>Spring AI Advisors API 提供了一种灵活且强大的方式，用于拦截、修改和增强 Spring 应用程序中由 AI 驱动的交互。通过利用 Advisors API，开发人员能够创建更复杂、可重用且易于维护的 AI 组件。</p><p>其主要优势包括封装重复出现的生成式人工智能模式、转换与大型语言模型（LLMs）之间发送和接收的数据，以及在各种模型和用例中提供可移植性。</p><p>开发者可以使用ChatClient API配置现有的顾问，如下例所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">ChatMemory chatMemory = ... // Initialize your chat memory store</span><br><span class="line">VectorStore vectorStore = ... // Initialize your vector store</span><br><span class="line"></span><br><span class="line">var chatClient = ChatClient.builder(chatModel)</span><br><span class="line">    .defaultAdvisors(</span><br><span class="line">        MessageChatMemoryAdvisor.builder(chatMemory).build(), // chat-memory advisor</span><br><span class="line">        QuestionAnswerAdvisor.builder(vectorStore).build()    // RAG advisor</span><br><span class="line">    )</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">var conversationId = &quot;678&quot;;</span><br><span class="line"></span><br><span class="line">String response = this.chatClient.prompt()</span><br><span class="line">    // Set advisor parameters at runtime</span><br><span class="line">    .advisors(advisor -&gt; advisor.param(ChatMemory.CONVERSATION_ID, conversationId))</span><br><span class="line">    .user(userText)</span><br><span class="line">    .call()</span><br><span class="line">.content();</span><br></pre></td></tr></table></figure><p>建议在构建时使用构建器的<code>defaultAdvisors()</code>方法注册顾问。顾问也参与可观测性堆栈，因此开发者可以查看与其执行相关的指标和轨迹。</p><h2 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h2><p>Advisors API 包含用于非流式场景的<code>CallAdvisor</code>和<code>CallAdvisorChain</code>，以及用于流式场景的<code>StreamAdvisor</code>和<code>StreamAdvisorChain</code>。它还包括用于表示未封装的提示词请求的ChatClientRequest，以及用于聊天补全响应的<code>ChatClientResponse</code>。两者都包含一个<code>advise-context</code>，用于在顾问链之间共享状态。</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762586061638-b0d41a4d-1490-44b1-92a9-e2739ddd76a7.png"></p><p><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;adviseCall()&lt;/font&gt;</code>和<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;adviseStream()&lt;/font&gt;</code>是关键的顾问方法，通常会执行一些操作，例如检查未密封的提示数据、定制和扩充提示数据、调用顾问链中的下一个实体、选择性地阻止请求、检查聊天完成响应，以及抛出异常以指示处理错误。</p><p><font style="color:rgb(25, 30, 30);"></font></p><p>此外，<code>getOrder()</code>方法确定链中顾问的顺序，而<code>getName()</code>提供唯一的顾问名称。</p><p><font style="color:rgb(25, 30, 30);"></font></p><p>由Spring AI框架创建的Advisor Chain（顾问链）允许按多个顾问的<code>getOrder()</code>值排序来依次调用它们。值越小，执行得越早。最后一个顾问会被自动添加，它负责将请求发送给大语言模型。</p><p>以下流程图展示了顾问链与聊天模型之间的交互：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762586153790-ba023059-f99d-4dbc-9f2c-0d086b75b2a0.png"></p><ol><li>Spring AI框架根据用户的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Prompt&lt;/font&gt;</code>以及一个空的顾问<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;context&lt;/font&gt;</code>对象创建一个<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatClientRequest&lt;/font&gt;</code>。</li><li>链中的每个顾问都会处理请求，并可能对其进行修改。或者，顾问也可以选择不调用下一个实体来阻止请求。在后一种情况下，该顾问负责完成响应。</li><li>框架提供的最后一个顾问会将请求发送至<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Chat Model&lt;/font&gt;</code>。</li><li>然后，聊天模型的响应会通过顾问链传回，并转换为<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatClientResponse&lt;/font&gt;</code>。其包含共享的顾问<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;context&lt;/font&gt;</code>实例。</li><li>每个顾问都可以处理或修改响应。</li><li>最终的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatClientResponse&lt;/font&gt;</code>通过提取<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatCompletion&lt;/font&gt;</code>返回给客户端。</li></ol><h2 id="顾问顺序-Advisor-Order"><a href="#顾问顺序-Advisor-Order" class="headerlink" title="顾问顺序(Advisor Order)"></a><font style="color:rgb(25, 30, 30);">顾问顺序(Advisor Order)</font></h2><p>链中顾问的执行顺序由<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;getOrder()&lt;/font&gt;</code>方法决定。需要理解的关键点有如下所示：</p><ul><li>顺序值较低的顾问会先执行。</li><li>顾问链以栈的方式运作：<ul><li>链中的第一个顾问会首先处理请求。</li><li>它也是最后一个处理响应的。</li></ul></li><li>控制执行顺序：<ul><li>将顺序设置为接近<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Ordered.HIGHEST_PRECEDENCE&lt;/font&gt;</code>，以确保顾问在链中首先执行（请求处理时首先执行，响应处理时最后执行）。</li><li>将顺序设置为接近<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Ordered.LOWEST_PRECEDENCE&lt;/font&gt;</code>，以确保顾问在链中最后执行（请求处理时最后执行，响应处理时最先执行）。</li></ul></li><li>值越高，表示优先级越低。</li><li>如果多个顾问具有相同的顺序值，它们的执行顺序无法保证。</li></ul><blockquote><p>顺序和执行顺序之间的表面矛盾是由于顾问链的栈式特性： 具有最高优先级（顺序值最低）的顾问被添加到栈的顶部。随着栈的展开，它将是第一个处理请求的。 随着栈的回卷，它将是最后一个处理响应的。</p></blockquote><p>作为提醒，以下是Spring <code>Ordered</code>接口的语义：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">public interface Ordered &#123;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 最高优先级值的常量。</span><br><span class="line">     * @see java.lang.Integer#MIN_VALUE</span><br><span class="line">     */</span><br><span class="line">    int HIGHEST_PRECEDENCE = Integer.MIN_VALUE;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 最低优先级值的常量。</span><br><span class="line">     * @see java.lang.Integer#MAX_VALUE</span><br><span class="line">     */</span><br><span class="line">    int LOWEST_PRECEDENCE = Integer.MAX_VALUE;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 获取此对象的顺序值。</span><br><span class="line">     * &lt;p&gt;较高的值被解释为较低的优先级。因此，</span><br><span class="line">     * 值最低的对象具有最高的优先级（与 Servlet 的 &#123;@code load-on-startup&#125; 值有些类似）。</span><br><span class="line">     * &lt;p&gt;相同的顺序值将导致受影响对象的任意排序位置。</span><br><span class="line">     * @return 顺序值</span><br><span class="line">     * @see #HIGHEST_PRECEDENCE</span><br><span class="line">     * @see #LOWEST_PRECEDENCE</span><br><span class="line">     */</span><br><span class="line">    int getOrder();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p><font style="color:rgb(25, 30, 30);">对于需要在输入侧和输出侧都处于链中首位的用例：</font></p><ol><li><font style="color:rgb(25, 30, 30);">为每一侧使用单独的顾问。</font></li><li><font style="color:rgb(25, 30, 30);">为它们配置不同的顺序值。</font></li><li><font style="color:rgb(25, 30, 30);">使用顾问上下文在它们之间共享状态。</font></li></ol></blockquote><h1 id="API概览"><a href="#API概览" class="headerlink" title="API概览"></a>API概览</h1><p>主要的Advisor接口位于<code>org.springframework.ai.chat.client.advisor.api</code>包中。以下是开发者自定义自己的advisor时会遇到的关键接口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public interface Advisor extends Ordered &#123;</span><br><span class="line">String getName();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这是顾问的基本接口，它扩展了 <code>Ordered</code> 接口，意味着顾问具有顺序和名称。</p><p>对于同步和响应式顾问的两个子接口分别是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public interface CallAdvisor extends Advisor &#123;</span><br><span class="line"></span><br><span class="line">ChatClientResponse adviseCall(</span><br><span class="line">ChatClientRequest chatClientRequest, CallAdvisorChain callAdvisorChain);</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>和</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public interface StreamAdvisor extends Advisor &#123;</span><br><span class="line"></span><br><span class="line">Flux&lt;ChatClientResponse&gt; adviseStream(</span><br><span class="line">ChatClientRequest chatClientRequest, StreamAdvisorChain streamAdvisorChain);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>为了继续顾问链的执行，开发者可以在顾问实现中使用<code>CallAdvisorChain</code>和<code>StreamAdvisorChain</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public interface CallAdvisorChain extends AdvisorChain &#123;</span><br><span class="line"></span><br><span class="line">ChatClientResponse nextCall(ChatClientRequest chatClientRequest);</span><br><span class="line"></span><br><span class="line">List&lt;CallAdvisor&gt; getCallAdvisors();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>和</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public interface StreamAdvisorChain extends AdvisorChain &#123;</span><br><span class="line"></span><br><span class="line">Flux&lt;ChatClientResponse&gt; nextStream(ChatClientRequest chatClientRequest);</span><br><span class="line"></span><br><span class="line">List&lt;StreamAdvisor&gt; getStreamAdvisors();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="实现顾问"><a href="#实现顾问" class="headerlink" title="实现顾问"></a>实现顾问</h1><p>要创建一个顾问，需实现<code>CallAdvisor</code>或<code>StreamAdvisor</code>（或两者都实现）。对于非流式顾问，要实现的关键方法是<code>nextCall()</code>；对于流式顾问，则是<code>nextStream()</code>。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>我们将提供几个实际操作示例，以说明如何为观察和增强用例实现顾问功能。</p><h3 id="日志顾问"><a href="#日志顾问" class="headerlink" title="日志顾问"></a>日志顾问</h3><p>我们可以实现一个简单的日志通知器，在调用链中下一个通知器之前记录<code>ChatClientRequest</code>，之后记录<code>ChatClientResponse</code>。请注意，该通知器仅观察请求和响应，不会对其进行修改。此实现同时支持非流式和流式场景。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">public class SimpleLoggerAdvisor implements CallAdvisor, StreamAdvisor &#123;</span><br><span class="line"></span><br><span class="line">private static final Logger log = LoggerFactory.getLogger(SimpleLoggerAdvisor.class);</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public String getName() &#123;  //1</span><br><span class="line">return this.getClass().getSimpleName();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public int getOrder() &#123;  //2</span><br><span class="line">return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public ChatClientResponse adviseCall(ChatClientRequest chatClientRequest, </span><br><span class="line">                                       CallAdvisorChain callAdvisorChain) &#123;</span><br><span class="line">logRequest(chatClientRequest);</span><br><span class="line"></span><br><span class="line">ChatClientResponse chatClientResponse = callAdvisorChain</span><br><span class="line">                                                          .nextCall(chatClientRequest);</span><br><span class="line"></span><br><span class="line">logResponse(chatClientResponse);</span><br><span class="line"></span><br><span class="line">return chatClientResponse;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public Flux&lt;ChatClientResponse&gt; adviseStream(ChatClientRequest chatClientRequest,</span><br><span class="line">StreamAdvisorChain streamAdvisorChain) &#123;</span><br><span class="line">logRequest(chatClientRequest);</span><br><span class="line"></span><br><span class="line">Flux&lt;ChatClientResponse&gt; chatClientResponses = streamAdvisorChain</span><br><span class="line">                                                         .nextStream(chatClientRequest);</span><br><span class="line"></span><br><span class="line">return new ChatClientMessageAggregator()</span><br><span class="line">            .aggregateChatClientResponse(chatClientResponses, this::logResponse); // 3</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void logRequest(ChatClientRequest request) &#123;</span><br><span class="line">logg.debug(&quot;request: &#123;&#125;&quot;, request);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void logResponse(ChatClientResponse chatClientResponse) &#123;</span><br><span class="line">logg.debug(&quot;response: &#123;&#125;&quot;, chatClientResponse);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>提供顾问的唯一名称。</li><li>您可以通过设置顺序值来控制执行顺序。值越低，越早执行。</li><li><font style="color:rgb(25, 30, 30);background-color:rgba(177, 209, 241, 0.15);">MessageAggregator </font>是一个实用工具类，它能将多个Flux 响应聚合成单个<font style="color:rgb(25, 30, 30);">ChatClientResponse</font>。这对于记录整个响应而不是流中的单个项目非常有用。请注意，您不能在 <font style="color:rgb(25, 30, 30);background-color:rgba(177, 209, 241, 0.15);">MessageAggregator </font>中更改响应，因为它是只读操作。</li></ol><h3 id="重读-Re2-顾问"><a href="#重读-Re2-顾问" class="headerlink" title="重读(Re2)顾问"></a><font style="color:rgb(20, 24, 24);">重读(Re2)顾问</font></h3><p><font style="color:rgb(25, 30, 30);">《“</font><a href="https://arxiv.org/pdf/2309.06275">重新阅读提升大型语言模型的推理能力</a>”》一文介绍了一种名为“重新阅读（Re2）”的技术，该技术可增强大型语言模型的推理能力。Re2技术需要对输入提示进行如下增强：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;Input_Query&#125;再读一遍问题：&#123;Input_Query&#125;</span><br></pre></td></tr></table></figure><p>实现一个将Re2技术应用于用户输入查询的顾问可以这样做：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">public class ReReadingAdvisor implements BaseAdvisor &#123;</span><br><span class="line"></span><br><span class="line">private static final String DEFAULT_RE2_ADVISE_TEMPLATE = &quot;&quot;&quot;</span><br><span class="line">&#123;re2_input_query&#125;</span><br><span class="line">Read the question again: &#123;re2_input_query&#125;</span><br><span class="line">&quot;&quot;&quot;;</span><br><span class="line"></span><br><span class="line">private final String re2AdviseTemplate;</span><br><span class="line"></span><br><span class="line">private int order = 0;</span><br><span class="line"></span><br><span class="line">public ReReadingAdvisor() &#123;</span><br><span class="line">this(DEFAULT_RE2_ADVISE_TEMPLATE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public ReReadingAdvisor(String re2AdviseTemplate) &#123;</span><br><span class="line">this.re2AdviseTemplate = re2AdviseTemplate;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public ChatClientRequest before(ChatClientRequest chatClientRequest, </span><br><span class="line">                                       AdvisorChain advisorChain) &#123;  //1</span><br><span class="line">String augmentedUserText = PromptTemplate.builder()</span><br><span class="line">.template(this.re2AdviseTemplate)</span><br><span class="line">.variables(Map.of(&quot;re2_input_query&quot;, chatClientRequest.prompt()</span><br><span class="line">                                                    .getUserMessage().getText()))</span><br><span class="line">.build()</span><br><span class="line">.render();</span><br><span class="line"></span><br><span class="line">return chatClientRequest.mutate()</span><br><span class="line">.prompt(chatClientRequest.prompt().augmentUserMessage(augmentedUserText))</span><br><span class="line">.build();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public ChatClientResponse after(ChatClientResponse chatClientResponse, </span><br><span class="line">                                                       AdvisorChain advisorChain) &#123;</span><br><span class="line">return chatClientResponse;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public int getOrder() &#123;  //2</span><br><span class="line">return this.order;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public ReReadingAdvisor withOrder(int order) &#123;</span><br><span class="line">this.order = order;</span><br><span class="line">return this;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>1、<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;before&lt;/font&gt;</code>方法通过应用重读技术来增强用户的输入查询。</p><p>2、开发者可以通过设置order值来控制执行顺序。值越小，执行越早。</p><h3 id="Spring-AI-内置顾问"><a href="#Spring-AI-内置顾问" class="headerlink" title="Spring AI 内置顾问"></a><font style="color:rgb(20, 24, 24);">Spring AI 内置顾问</font></h3><p>Spring AI框架提供了几个内置的顾问来增强您的AI交互。以下是可用顾问的概述：</p><h5 id="聊天记忆顾问"><a href="#聊天记忆顾问" class="headerlink" title="聊天记忆顾问"></a><font style="color:rgb(20, 24, 24);">聊天记忆顾问</font></h5><p>这些顾问在聊天记忆存储中管理对话历史：</p><ul><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;MessageChatMemoryAdvisor&lt;/font&gt;</code></li></ul><p>检索记忆并将其作为消息集合添加到提示中。这种方法能保持对话历史的结构。请注意，并非所有人工智能模型都支持这种方法。</p><ul><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;PromptChatMemoryAdvisor&lt;/font&gt;</code></li></ul><p>检索记忆并将其整合到提示词的系统文本中。</p><ul><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;VectorStoreChatMemoryAdvisor&lt;/font&gt;</code></li></ul><p>从向量存储中检索记忆并将其添加到提示词的系统文本中。该辅助工具有助于高效地从大型数据集中搜索和检索相关信息。</p><h5 id="问答顾问"><a href="#问答顾问" class="headerlink" title="问答顾问"></a><font style="color:rgb(20, 24, 24);">问答顾问</font></h5><ul><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;QuestionAnswerAdvisor&lt;/font&gt;</code></li></ul><p>该顾问使用向量存储来提供问答功能，采用了简单的检索增强生成（RAG）模式。</p><p><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;RetrievalAugmentationAdvisor&lt;/font&gt;</code></p><ul><li>该顾问使用org.springframework.ai.rag包中定义的构建块并遵循模块化RAG架构，实现了常见的检索增强生成（RAG）流程。</li></ul><h5 id="推理顾问"><a href="#推理顾问" class="headerlink" title="推理顾问"></a><font style="color:rgb(20, 24, 24);">推理顾问</font></h5><ul><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ReReadingAdvisor&lt;/font&gt;</code></li></ul><p>实现了一种用于大语言模型推理的重读策略，称为RE2，以增强输入阶段的理解。基于文章：《重读提升大语言模型的推理能力》（arxiv.org/pdf/2309.06275）。</p><h5 id="内容安全顾问"><a href="#内容安全顾问" class="headerlink" title="内容安全顾问"></a><font style="color:rgb(20, 24, 24);">内容安全顾问</font></h5><ul><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;SafeGuardAdvisor&lt;/font&gt;</code></li></ul><p>一个简单的顾问，旨在防止模型生成有害或不当内容。</p><h2 id="流式与非流式"><a href="#流式与非流式" class="headerlink" title="流式与非流式"></a><font style="color:rgb(20, 24, 24);">流式与非流式</font></h2><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762587685362-73fcb9dc-a3a9-470d-9029-ac8ea81776b4.png"></p><ul><li>非流式顾问处理完整的请求和响应。</li><li>流式顾问将请求和响应作为连续流来处理，采用响应式编程概念（例如，使用Flux处理响应）。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public Flux&lt;ChatClientResponse&gt; adviseStream(ChatClientRequest chatClientRequest, </span><br><span class="line">                                             StreamAdvisorChain chain) &#123;</span><br><span class="line"></span><br><span class="line">    return  Mono.just(chatClientRequest)</span><br><span class="line">            .publishOn(Schedulers.boundedElastic())</span><br><span class="line">            .map(request -&gt; &#123;</span><br><span class="line">                // This can be executed by blocking and non-blocking Threads.</span><br><span class="line">                // Advisor before next section</span><br><span class="line">            &#125;)</span><br><span class="line">            .flatMapMany(request -&gt; chain.nextStream(request))</span><br><span class="line">            .map(response -&gt; &#123;</span><br><span class="line">                // Advisor after next section</span><br><span class="line">            &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><ol><li>让顾问专注于特定任务，以实现更好的模块化。</li><li>必要时，使用<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;adviseContext&lt;/font&gt;</code>在顾问之间共享状态。</li><li>实现顾问的流式和非流式版本，以获得最大的灵活性。</li><li>仔细考虑链中顾问的顺序，以确保数据的正确流转。</li></ol><h1 id="API重大变更"><a href="#API重大变更" class="headerlink" title="API重大变更"></a>API重大变更</h1><h2 id="顾问接口"><a href="#顾问接口" class="headerlink" title="顾问接口"></a><font style="color:rgb(20, 24, 24);">顾问接口</font></h2><ul><li>在1.0 M2中，存在独立的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;RequestAdvisor&lt;/font&gt;</code>和<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ResponseAdvisor&lt;/font&gt;</code>接口。<ul><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;RequestAdvisor&lt;/font&gt;</code> 在 <code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatModel.call&lt;/font&gt;</code> 和 <code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatModel.stream&lt;/font&gt;</code> 方法之前被调用。</li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ResponseAdvisor&lt;/font&gt;</code>是在这些方法之后被调用的。</li></ul></li><li>在1.0 M3中，这些接口已被替换为：<ul><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;CallAroundAdvisor&lt;/font&gt;</code></li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;StreamAroundAdvisor&lt;/font&gt;</code></li></ul></li><li>此前属于<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ResponseAdvisor&lt;/font&gt;</code>的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;StreamResponseMode&lt;/font&gt;</code>已被移除。</li><li>在1.0.0版本中，这些接口已被替换：<ul><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;CallAroundAdvisor&lt;/font&gt;</code> → <code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;CallAdvisor&lt;/font&gt;</code>、<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;StreamAroundAdvisor&lt;/font&gt;</code> → <code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;StreamAdvisor&lt;/font&gt;</code>、<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;CallAroundAdvisorChain&lt;/font&gt;</code> → <code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;CallAdvisorChain&lt;/font&gt;</code> 以及 <code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;StreamAroundAdvisorChain&lt;/font&gt;</code> → <code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;StreamAdvisorChain&lt;/font&gt;</code>。</li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;AdvisedRequest&lt;/font&gt;</code> → <code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatClientRequest&lt;/font&gt;</code> 是 <code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;AdivsedResponse&lt;/font&gt;</code> → <code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatClientResponse&lt;/font&gt;</code>。</li></ul></li></ul><h2 id="上下文映射处理"><a href="#上下文映射处理" class="headerlink" title="上下文映射处理"></a><font style="color:rgb(20, 24, 24);">上下文映射处理</font></h2><ul><li>在1.0 M2中：<ul><li>上下文映射是一个单独的方法参数。</li><li>该映射是可变的，并在链中传递。</li></ul></li><li>在1.0 M3中：<ul><li>上下文映射现在是<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;AdvisedRequest&lt;/font&gt;</code>和<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;AdvisedResponse&lt;/font&gt;</code>记录的一部分。</li><li>该映射是不可变的。</li><li>要更新上下文，请使用<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;updateContext&lt;/font&gt;</code>方法，该方法会创建一个包含更新内容的新的不可修改映射。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;顾问-API&quot;&gt;&lt;a href=&quot;#顾问-API&quot; class=&quot;headerlink&quot; title=&quot;顾问 API&quot;&gt;&lt;/a&gt;&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;顾问&lt;/font&gt; API&lt;/h1&gt;&lt;p&gt;Spring AI </summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>SpringAi学习之ChatClient API</title>
    <link href="http://aichating.xyz/2025/05/18/2025-7-spring-ai-3-chat-client-API/"/>
    <id>http://aichating.xyz/2025/05/18/2025-7-spring-ai-3-chat-client-API/</id>
    <published>2025-05-18T08:01:20.000Z</published>
    <updated>2025-05-18T13:31:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>本篇开始学习学习Spring Ai提供的Chat Client Api，通过它可以很轻松的与大模型进行交互。</p><h1 id="ChatClient-API"><a href="#ChatClient-API" class="headerlink" title="ChatClient API"></a><font style="color:rgb(20, 24, 24);">ChatClient API</font></h1><p><code>**ChatClient**</code><strong>为与AI模型进行通信，提供了一个流畅的API。它同时支持同步和流式编程模型。</strong></p><p>流畅的API具有构建提示词组成部分的方法，该提示词会作为输入传递给AI模型。<code>Prompt</code>包含用于指导AI模型输出和行为的指令性文本。从API的角度来看，提示词由一系列消息组成。</p><p><strong>AI模型处理两种主要类型的消息：</strong></p><ol><li><strong>用户消息</strong>，即用户的直接输入。</li><li><strong>系统消息</strong>，由系统生成以指导对话。</li></ol><p>这些消息通常包含占位符，这些占位符在运行时会根据用户输入进行替换，以自定义AI模型对用户输入的响应。</p><p>还可以指定一些提示选项，如：</p><ul><li><strong>AI模型的名称</strong>，即要使用的AI模型的名称。</li><li><strong>温度设置</strong>，控制生成输出的随机性或创造性。</li></ul><p>这些功能使得ChatClient成为一个强大的工具，允许开发者以灵活的方式与AI模型进行交互，并通过定制化的提示和消息来优化AI模型的响应。</p><h2 id="创建ChatClient"><a href="#创建ChatClient" class="headerlink" title="创建ChatClient"></a><font style="color:rgb(20, 24, 24);">创建ChatClient</font></h2><p><code>ChatClient</code>是使用<code>ChatClient.Builder</code>对象创建的。你可以为任何ChatModel Spring Boot自动配置获取自动配置的<code>ChatClient.Builder</code> 实例，或者通过编程方式创建一个。</p><h2 id="使用自动配置的ChatClient-Builder"><a href="#使用自动配置的ChatClient-Builder" class="headerlink" title="使用自动配置的ChatClient.Builder"></a><strong><font style="color:rgb(20, 24, 24);">使用自动配置的ChatClient.Builder</font></strong></h2><p>Spring AI提供Spring Boot自动配置，会创建一个原型<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatClient.Builder&lt;/font&gt;</code>bean，供开发者注入到自己的类中。</p><p><font style="color:rgb(25, 30, 30);"></font></p><p>以下是一个简单的示例，用于检索对简单用户请求的字符串响应。新建一个名为controller的包，并在里面定义一个名为MyController的类：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">public class MyController &#123;</span><br><span class="line">    private ChatClient chatClient;</span><br><span class="line"></span><br><span class="line">    public MyController(ChatClient.Builder chatClientBuilder) &#123;</span><br><span class="line">        this.chatClient = chatClientBuilder.build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @GetMapping(&quot;/ai&quot;)</span><br><span class="line">    public String generation(@RequestParam String userInput) &#123;</span><br><span class="line">        return this.chatClient.prompt()</span><br><span class="line">                .user(userInput)</span><br><span class="line">                .call()</span><br><span class="line">                .content();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行项目，访问对应地址，返回信息如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762574949505-27451ffd-e079-4fe1-97d7-733dcd2b79ae.png"></p><p>用户传入了消息，之后调用call()方法向 AI 模型发送请求，content()方法将AI模型的响应作为字符串返回。</p><h2 id="手动创建ChatClient"><a href="#手动创建ChatClient" class="headerlink" title="手动创建ChatClient"></a><strong><font style="color:rgb(0, 0, 0);">手动创建ChatClient</font></strong></h2><p>默认情况下，Spring AI会自动配置一个<code>ChatClient.Builder</code> bean。不过，当你的应用程序中需要使用多个聊天模型时，就需要手动创建ChatClient。首先必须通过设置属性<code>spring.ai.chat.client.enabled=false</code>来禁用<code>ChatClient.Builder</code>的自动配置，之后才允许开发者手动创建多个<code>ChatClient</code>实例。</p><h3 id="单一模型类型的多个-ChatClient"><a href="#单一模型类型的多个-ChatClient" class="headerlink" title="单一模型类型的多个****ChatClient"></a><strong><font style="color:rgb(20, 24, 24);">单一模型类型的多个</font>****<font style="color:rgb(0, 0, 0);">ChatClient</font></strong></h3><p>一个常见的使用场景，比如开发者需要创建多个ChatClient实例，但这些实例都使用相同的基础模型类型，只是配置不同：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ChatModel myChatModel = ... // 通常通过自动装配获得</span><br><span class="line">ChatClient chatClient = ChatClient.create(myChatModel);</span><br><span class="line"></span><br><span class="line">//或者使用默认构建器设置创建一个ChatClient</span><br><span class="line">ChatClient.Builder builder = ChatClient.builder(myChatModel);</span><br><span class="line">ChatClient customChatClient = builder</span><br><span class="line">    .defaultSystemPrompt(&quot;一些默认的系统提示词&quot;)</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure><h3 id="不同模型类型的-ChatClient"><a href="#不同模型类型的-ChatClient" class="headerlink" title="不同模型类型的****ChatClient"></a><strong><font style="color:rgb(20, 24, 24);">不同模型类型的</font>****<font style="color:rgb(0, 0, 0);">ChatClient</font></strong></h3><p>当你需要使用多个AI模型时，可以为每个模型定义单独的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatClient&lt;/font&gt;</code> bean：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import org.springframework.ai.chat.ChatClient;</span><br><span class="line">import org.springframework.context.annotation.Bean;</span><br><span class="line">import org.springframework.context.annotation.Configuration;</span><br><span class="line"></span><br><span class="line">@Configuration</span><br><span class="line">public class ChatClientConfig &#123;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    public ChatClient openAiChatClient(OpenAiChatModel chatModel) &#123;</span><br><span class="line">        return ChatClient.create(chatModel);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    public ChatClient anthropicChatClient(AnthropicChatModel chatModel) &#123;</span><br><span class="line">        return ChatClient.create(chatModel);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>之后开发者就可以使用<code>@Qualifier</code>注解将这些bean注入到自己的应用组件中：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">public class ChatClientExample &#123;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    CommandLineRunner cli(</span><br><span class="line">            @Qualifier(&quot;openAiChatClient&quot;) ChatClient openAiChatClient,</span><br><span class="line">            @Qualifier(&quot;anthropicChatClient&quot;) ChatClient anthropicChatClient) &#123;</span><br><span class="line"></span><br><span class="line">        return args -&gt; &#123;</span><br><span class="line">            var scanner = new Scanner(System.in);</span><br><span class="line">            ChatClient chat;</span><br><span class="line"></span><br><span class="line">            // Model selection</span><br><span class="line">            System.out.println(&quot;\nSelect your AI model:&quot;);</span><br><span class="line">            System.out.println(&quot;1. OpenAI&quot;);</span><br><span class="line">            System.out.println(&quot;2. Anthropic&quot;);</span><br><span class="line">            System.out.print(&quot;Enter your choice (1 or 2): &quot;);</span><br><span class="line"></span><br><span class="line">            String choice = scanner.nextLine().trim();</span><br><span class="line"></span><br><span class="line">            if (choice.equals(&quot;1&quot;)) &#123;</span><br><span class="line">                chat = openAiChatClient;</span><br><span class="line">                System.out.println(&quot;Using OpenAI model&quot;);</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                chat = anthropicChatClient;</span><br><span class="line">                System.out.println(&quot;Using Anthropic model&quot;);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            // Use the selected chat client</span><br><span class="line">            System.out.print(&quot;\nEnter your question: &quot;);</span><br><span class="line">            String input = scanner.nextLine();</span><br><span class="line">            String response = chat.prompt(input).call().content();</span><br><span class="line">            System.out.println(&quot;ASSISTANT: &quot; + response);</span><br><span class="line"></span><br><span class="line">            scanner.close();</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="多个兼容OpenAI的API端点"><a href="#多个兼容OpenAI的API端点" class="headerlink" title="多个兼容OpenAI的API端点"></a><strong><font style="color:rgb(20, 24, 24);">多个兼容OpenAI的API端点</font></strong></h3><p><code>OpenAiApi</code>和<code>OpenAiChatModel</code>类提供了一个<code>mutate()</code>方法，该方法允许开发者创建具有不同属性的现有实例的变体。当需要使用多个与OpenAI兼容的API时，这一点特别有用：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">@Service</span><br><span class="line">@Slf4j</span><br><span class="line">public class MultiModelService &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    private OpenAiChatModel baseChatModel;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private OpenAiApi baseOpenAiApi;</span><br><span class="line"></span><br><span class="line">    public void multiClientFlow() &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            // Derive a new OpenAiApi for Groq (Llama3)</span><br><span class="line">            OpenAiApi groqApi = baseOpenAiApi.mutate()</span><br><span class="line">                .baseUrl(&quot;https://api.groq.com/openai&quot;)</span><br><span class="line">                .apiKey(System.getenv(&quot;GROQ_API_KEY&quot;))</span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">            // Derive a new OpenAiApi for OpenAI GPT-4</span><br><span class="line">            OpenAiApi gpt4Api = baseOpenAiApi.mutate()</span><br><span class="line">                .baseUrl(&quot;https://api.openai.com&quot;)</span><br><span class="line">                .apiKey(System.getenv(&quot;OPENAI_API_KEY&quot;))</span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">            // Derive a new OpenAiChatModel for Groq</span><br><span class="line">            OpenAiChatModel groqModel = baseChatModel.mutate()</span><br><span class="line">                .openAiApi(groqApi)</span><br><span class="line">                .defaultOptions(OpenAiChatOptions.builder()</span><br><span class="line">                                 .model(&quot;llama3-70b-8192&quot;).temperature(0.5).build())</span><br><span class="line">                                 .build();</span><br><span class="line"></span><br><span class="line">            // Derive a new OpenAiChatModel for GPT-4</span><br><span class="line">            OpenAiChatModel gpt4Model = baseChatModel.mutate()</span><br><span class="line">                .openAiApi(gpt4Api)</span><br><span class="line">                .defaultOptions(OpenAiChatOptions.builder()</span><br><span class="line">                                  .model(&quot;gpt-4&quot;).temperature(0.7).build())</span><br><span class="line">                                  .build();</span><br><span class="line"></span><br><span class="line">            // Simple prompt for both models</span><br><span class="line">            String prompt = &quot;What is the capital of France?&quot;;</span><br><span class="line"></span><br><span class="line">            String groqResponse = ChatClient.builder(groqModel)</span><br><span class="line">                                            .build().prompt(prompt).call().content();</span><br><span class="line">            String gpt4Response = ChatClient.builder(gpt4Model)</span><br><span class="line">                                            .build().prompt(prompt).call().content();</span><br><span class="line"></span><br><span class="line">            log.info(&quot;Groq (Llama3) response: &#123;&#125;&quot;, groqResponse);</span><br><span class="line">            log.info(&quot;OpenAI GPT-4 response: &#123;&#125;&quot;, gpt4Response);</span><br><span class="line">        &#125;</span><br><span class="line">        catch (Exception e) &#123;</span><br><span class="line">            log.error(&quot;Error in multi-client flow&quot;, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="ChatClient流畅API-ChatClient-Fluent-API"><a href="#ChatClient流畅API-ChatClient-Fluent-API" class="headerlink" title="ChatClient流畅API(ChatClient Fluent API)"></a><font style="color:rgb(20, 24, 24);">ChatClient流畅API(ChatClient Fluent API)</font></h1><p><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatClient&lt;/font&gt;</code>流畅 PI允许开发者通过重载的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;prompt&lt;/font&gt;</code>方法来启动流畅 API，从而以三种不同的方式创建提示词：</p><ul><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;prompt()&lt;/font&gt;</code>：此无参数方法可让您开始使用流式 API，从而构建提示词的用户部分、系统部分和其他部分。</li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;prompt(Prompt prompt)&lt;/font&gt;</code>：此方法接受一个<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Prompt&lt;/font&gt;</code>参数，允许你传入一个使用Prompt的非流式API创建的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Prompt&lt;/font&gt;</code>实例。</li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;prompt(String content)&lt;/font&gt;</code>：这是一个与之前的重载类似的便捷方法。它接收用户的文本内容。</li></ul><h1 id="ChatClient响应"><a href="#ChatClient响应" class="headerlink" title="ChatClient响应"></a>ChatClient响应</h1><p><code>ChatClient</code> API 提供了多种使用流式API 来格式化 AI 模型响应的方法。</p><h3 id="返回ChatResponse"><a href="#返回ChatResponse" class="headerlink" title="返回ChatResponse"></a><font style="color:rgb(20, 24, 24);">返回ChatResponse</font></h3><p>AI模型的响应是一种由<code>ChatResponse</code>类型定义的丰富结构。它包含关于响应生成方式的元数据，还可以包含多个响应（称为Generation），每个响应都有自己的元数据。元数据包括用于生成响应的令牌数量（每个令牌大约相当于一个单词的3/4）。这一信息很重要，因为托管的人工智能模型会根据每个请求所使用的令牌数量来收费。</p><p>下面展示了一个在调用<code>call()</code>方法后，通过调用<code>chatResponse()</code>来返回包含元数据的<code>ChatResponse</code>对象的示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ChatResponse chatResponse = chatClient.prompt()</span><br><span class="line">    .user(&quot;Tell me a joke&quot;)</span><br><span class="line">    .call()</span><br><span class="line">    .chatResponse();</span><br></pre></td></tr></table></figure><h3 id="返回实体"><a href="#返回实体" class="headerlink" title="返回实体"></a><font style="color:rgb(20, 24, 24);">返回实体</font></h3><p>开发者如果希望返回一个从返回的<code>String</code>映射而来的实体类。<code>entity()</code>方法就提供了这一功能。</p><p>举个例子，给定以下Java记录：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">record ActorFilms(String actor, List&lt;String&gt; movies) &#123;&#125;</span><br></pre></td></tr></table></figure><p>开发者可以使用<code>entity()</code>方法轻松地将AI模型的输出映射到此记录，如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ActorFilms actorFilms = chatClient.prompt()</span><br><span class="line">    .user(&quot;Generate the filmography for a random actor.&quot;)</span><br><span class="line">    .call()</span><br><span class="line">    .entity(ActorFilms.class);</span><br></pre></td></tr></table></figure><p>还有一个重载的<code>entity</code>方法，其签名为<code>entity(ParameterizedTypeReference&lt;T&gt; type)</code>，可让你指定诸如泛型列表之类的类型：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">List&lt;ActorFilms&gt; actorFilms = chatClient.prompt()</span><br><span class="line">    .user(&quot;Generate the filmography of 5 movies for Tom Hanks and Bill Murray.&quot;)</span><br><span class="line">    .call()</span><br><span class="line">    .entity(new ParameterizedTypeReference&lt;List&lt;ActorFilms&gt;&gt;() &#123;&#125;);</span><br></pre></td></tr></table></figure><h3 id="流式响应"><a href="#流式响应" class="headerlink" title="流式响应"></a><font style="color:rgb(20, 24, 24);">流式响应</font></h3><p><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;strea&lt;/font&gt;m()</code>方法可让你获取异步响应，如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Flux&lt;String&gt; output = chatClient.prompt()</span><br><span class="line">    .user(&quot;Tell me a joke&quot;)</span><br><span class="line">    .stream()</span><br><span class="line">    .content();</span><br></pre></td></tr></table></figure><p>您也可以使用<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Flux&lt;ChatResponse&gt; chatResponse()&lt;/font&gt;</code>方法来流式传输<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatResponse&lt;/font&gt;</code>。</p><p>未来，我们将提供一种便捷方法，让您能够使用响应式的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;stream()&lt;/font&gt;</code>方法返回Java实体。在此期间，您应该像下面所示的那样，使用结构化输出转换器来显式转换聚合响应。如下所示。这也展示了流畅 API 中参数的使用，我们将在文档的后续部分详细讨论。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">var converter = new BeanOutputConverter&lt;&gt;(</span><br><span class="line">                                new ParameterizedTypeReference&lt;List&lt;ActorsFilms&gt;&gt;()&#123;&#125;);</span><br><span class="line"></span><br><span class="line">Flux&lt;String&gt; flux = this.chatClient.prompt()</span><br><span class="line">    .user(u -&gt; u.text(&quot;&quot;&quot;</span><br><span class="line">                        Generate the filmography for a random actor.</span><br><span class="line">                        &#123;format&#125;</span><br><span class="line">                      &quot;&quot;&quot;)</span><br><span class="line">            .param(&quot;format&quot;, this.converter.getFormat()))</span><br><span class="line">    .stream()</span><br><span class="line">    .content();</span><br><span class="line"></span><br><span class="line">String content = this.flux.collectList().block().stream().collect(Collectors.joining());</span><br><span class="line"></span><br><span class="line">List&lt;ActorsFilms&gt; actorFilms = this.converter.convert(this.content);</span><br></pre></td></tr></table></figure><h2 id="提示模板-Prompt-Templates"><a href="#提示模板-Prompt-Templates" class="headerlink" title="提示模板(Prompt Templates)"></a><font style="color:rgb(20, 24, 24);">提示模板(Prompt Templates)</font></h2><p><code>ChatClient</code>的流畅API允许开发者将用户和系统文本作为带有变量的模板提供，这些变量会在运行时被替换：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">String answer = ChatClient.create(chatModel).prompt()</span><br><span class="line">    .user(u -&gt; u</span><br><span class="line">        .text(&quot;Tell me the names of 5 movies whose soundtrack was composed by &#123;composer&#125;&quot;)</span><br><span class="line">        .param(&quot;composer&quot;, &quot;John Williams&quot;))</span><br><span class="line">    .call()</span><br><span class="line">    .content();</span><br></pre></td></tr></table></figure><p>在内部，ChatClient 使用<code>PromptTemplate</code>类来处理用户和系统文本，并依靠给定的<code>TemplateRenderer</code>实现，在运行时用提供的值替换变量。默认情况下，Spring AI 使用<code>StTemplateRenderer</code>实现，该实现基于 Terence Parr 开发的开源StringTemplate引擎。</p><p><font style="color:rgb(25, 30, 30);"></font></p><p>Spring AI 还提供了一个 <code>NoOpTemplateRenderer</code>，用于不需要模板处理的情况。</p><table><thead><tr><th>直接在<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatClient&lt;/font&gt;</code>上配置（通过<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;.templateRenderer()&lt;/font&gt;</code>）的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;TemplateRenderer&lt;/font&gt;</code>仅适用于在<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatClient&lt;/font&gt;</code>构建器链中直接定义的提示内容（例如，通过<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;.user()&lt;/font&gt;</code>、<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;.system()&lt;/font&gt;</code>）。它不会影响Advisors（如<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;QuestionAnswerAdvisor&lt;/font&gt;</code>）内部使用的模板，这些模板有自己的模板自定义机制（参见 Custom Advisor Templates）。</th></tr></thead></table><p>如果您更愿意使用不同的模板引擎，可以直接向ChatClient提供<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;TemplateRenderer&lt;/font&gt;</code>接口的自定义实现。您也可以继续使用默认的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;StTemplateRenderer&lt;/font&gt;</code>，但需采用自定义配置。</p><p>例如，默认情况下，模板变量通过<code>&#123;&#125;</code>语法来标识。如果您计划在提示词中包含JSON，可能需要使用不同的语法以避免与JSON语法冲突。比如使用<code>&lt;</code>和<code>&gt;</code>分隔符。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">String answer = ChatClient.create(chatModel).prompt()</span><br><span class="line">    .user(u -&gt; u</span><br><span class="line">            .text(&quot;Tell me the names of 5 movies whose soundtrack was composed by &lt;composer&gt;&quot;)</span><br><span class="line">            .param(&quot;composer&quot;, &quot;John Williams&quot;))</span><br><span class="line">    .templateRenderer(StTemplateRenderer.builder().startDelimiterToken(&#x27;&lt;&#x27;).endDelimiterToken(&#x27;&gt;&#x27;).build())</span><br><span class="line">    .call()</span><br><span class="line">    .content();</span><br></pre></td></tr></table></figure><h1 id="Call-返回值"><a href="#Call-返回值" class="headerlink" title="Call()返回值"></a>Call()返回值</h1><p>在<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatClient&lt;/font&gt;</code>上指定<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;call()&lt;/font&gt;</code>方法后，响应类型有几种不同的选项：</p><ul><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;String content()&lt;/font&gt;</code>：返回响应的字符串内容。</li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatResponse chatResponse()&lt;/font&gt;</code>：返回包含多个生成内容以及响应元数据（例如创建响应所用的令牌数量）的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatResponse&lt;/font&gt;</code>对象。</li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatClientResponse chatClientResponse()&lt;/font&gt;</code>：返回一个<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatClientResponse&lt;/font&gt;</code>对象，该对象包含<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatResponse&lt;/font&gt;</code>对象和ChatClient的执行上下文，使您能够访问顾问执行期间使用的额外数据（例如，在RAG流程中检索到的相关文档）。</li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ResponseEntity&lt;?&gt; responseEntity()&lt;/font&gt;</code>：返回一个包含完整HTTP响应的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ResponseEntity&lt;/font&gt;</code>，包括状态码、头部和正文。当你需要访问响应的低级HTTP细节时，这很有用。</li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;entity()&lt;/font&gt;</code> 返回一个Java类型。<ul><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;entity(ParameterizedTypeReference&lt;T&gt; type)&lt;/font&gt;</code>：用于返回实体类型的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Collection&lt;/font&gt;</code>。</li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;entity(Class&lt;T&gt; type)&lt;/font&gt;</code>：用于返回特定的实体类型。</li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;entity(StructuredOutputConverter&lt;T&gt; structuredOutputConverter)&lt;/font&gt;</code>：用于指定一个<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;StructuredOutputConverter&lt;/font&gt;</code>实例，将<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;String&lt;/font&gt;</code>转换为实体类型。</li></ul></li></ul><p>开发者也可以调用<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;stream()&lt;/font&gt;</code>方法来替代<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;call()&lt;/font&gt;</code>方法。</p><blockquote><p>调用<code>call()</code>方法并不会实际触发AI模型的执行。相反，它只是指示Spring AI是使用同步调用还是流式调用。实际的AI模型调用会在调用<code>content()</code>、<code>chatResponse()</code>和<code>responseEntity()</code>等方法时发生。</p></blockquote><h1 id="stream-返回值"><a href="#stream-返回值" class="headerlink" title="stream()返回值"></a><font style="color:rgb(20, 24, 24);">stream()返回值</font></h1><p>在<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatClient&lt;/font&gt;</code>上指定<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;stream()&lt;/font&gt;</code>方法后，响应类型有几个选项：</p><ul><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Flux&lt;String&gt; content()&lt;/font&gt;</code>：返回由AI模型生成的字符串的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Flux&lt;/font&gt;</code>。</li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Flux&lt;ChatResponse&gt; chatResponse()&lt;/font&gt;</code>：返回<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Flux&lt;/font&gt;</code>类型的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatResponse&lt;/font&gt;</code>对象，该对象包含有关响应的附加元数据。</li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Flux&lt;ChatClientResponse&gt; chatClientResponse()&lt;/font&gt;</code>：返回一个<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Flux&lt;/font&gt;</code>类型的<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatClientResponse&lt;/font&gt;</code>对象，该对象包含<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatResponse&lt;/font&gt;</code>对象和ChatClient的执行上下文，使你能够访问在顾问执行过程中使用的额外数据（例如，在RAG流程中检索到的相关文档）。</li></ul><h1 id="使用默认值-using-defaults"><a href="#使用默认值-using-defaults" class="headerlink" title="使用默认值(using defaults)"></a><font style="color:rgb(20, 24, 24);">使用默认值(using defaults)</font></h1><p>在<code>@Configuration</code>类中创建带有默认系统文本的<code>ChatClient</code>，可以简化运行时代码。通过设置默认值，调用<code>ChatClient</code>时只需指定用户文本，无需在运行时代码路径中为每个请求设置系统文本。</p><h2 id="默认系统文本"><a href="#默认系统文本" class="headerlink" title="默认系统文本"></a>默认系统文本</h2><p>在下面的示例中，我们将把系统文本配置为始终以海盗的语气回复。为避免在运行时代码中重复系统文本，我们将在一个<code>@Configuration</code>类中创建一个<code>ChatClient</code>实例。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">class Config &#123;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    ChatClient chatClient(ChatClient.Builder builder) &#123;</span><br><span class="line">        return builder.defaultSystem(&quot;你是一个友好的聊天机器人，会用海盗的语气来回答问题&quot;)</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一个<code>@RestController</code>来调用它：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">class AIController &#123;</span><br><span class="line"></span><br><span class="line">private final ChatClient chatClient;</span><br><span class="line"></span><br><span class="line">AIController(ChatClient chatClient) &#123;</span><br><span class="line">this.chatClient = chatClient;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@GetMapping(&quot;/ai/simple&quot;)</span><br><span class="line">public Map&lt;String, String&gt; completion(@RequestParam(value = &quot;message&quot;, </span><br><span class="line">                                       defaultValue = &quot;讲个笑话&quot;) String message) &#123;</span><br><span class="line">return Map.of(&quot;completion&quot;, this.chatClient.prompt().user(message).call().content());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><font style="color:rgb(25, 30, 30);">通过curl调用应用程序端点时，结果如下：</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">❯ curl localhost:8080/ai/simple</span><br><span class="line">&#123;&quot;completion&quot;:&quot;海盗为什么去喜剧俱乐部？为了听一些 “海盗级” 笑话呀！哈哈，伙计！&quot;&#125;</span><br></pre></td></tr></table></figure><h2 id="带参数的默认系统文本"><a href="#带参数的默认系统文本" class="headerlink" title="带参数的默认系统文本"></a><font style="color:rgb(20, 24, 24);">带参数的默认系统文本</font></h2><p>在下面的示例中，我们将在系统文本中使用占位符，以在运行时而非设计时指定补全内容的语气：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">class Config &#123;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    ChatClient chatClient(ChatClient.Builder builder) &#123;</span><br><span class="line">        return builder.defaultSystem(&quot;你是一个友好的聊天机器人，会用&#123;voice&#125;的语气来回答问题&quot;)</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">@RestController</span><br><span class="line">class AIController &#123;</span><br><span class="line">private final ChatClient chatClient;</span><br><span class="line"></span><br><span class="line">AIController(ChatClient chatClient) &#123;</span><br><span class="line">this.chatClient = chatClient;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@GetMapping(&quot;/ai&quot;)</span><br><span class="line">Map&lt;String, String&gt; completion(@RequestParam(value = &quot;message&quot;, </span><br><span class="line">                     defaultValue = &quot;讲个笑话&quot;) String message, String voice) &#123;</span><br><span class="line">return Map.of(&quot;completion&quot;,</span><br><span class="line">this.chatClient.prompt()</span><br><span class="line">.system(sp -&gt; sp.param(&quot;voice&quot;, voice))</span><br><span class="line">.user(message)</span><br><span class="line">.call()</span><br><span class="line">.content());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用httpie调用应用程序端点时，结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">http localhost:8080/ai voice==&#x27;海盗&#x27;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;completion&quot;: &quot;你在跟我说话吗？好，给你讲个笑话：为什么自行车自己站不起来？因为它 “太疲惫” 了！这可是经典笑话，对吧？&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="其他默认值"><a href="#其他默认值" class="headerlink" title="其他默认值"></a>其他默认值</h2><p>在<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatClient.Builder&lt;/font&gt;</code>级别，您可以指定默认的提示配置。</p><ul><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;defaultOptions(ChatOptions chatOptions)&lt;/font&gt;</code>：传入ChatOptions类中定义的可移植选项，或特定于模型的选项（如OpenAiChatOptions中的选项）。</li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;defaultFunction(String name, String description, java.util.function.Function&lt;I, O&gt; function)&lt;/font&gt;</code>：<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;name&lt;/font&gt;</code>用于在用户文本中引用该函数。<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;description&lt;/font&gt;</code>解释函数的用途，并帮助AI模型选择正确的函数以获得准确的响应。<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;function&lt;/font&gt;</code>参数是模型在必要时将执行的Java函数实例。</li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;defaultFunctions(String… functionNames)&lt;/font&gt;</code>：在应用上下文中定义的java.util.Function的Bean名称。</li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;defaultUser(String text)&lt;/font&gt;</code>、<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;defaultUser(Resource text)&lt;/font&gt;</code>、<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;defaultUser(Consumer&lt;UserSpec&gt; userSpecConsumer)&lt;/font&gt;</code>：这些方法允许你定义用户文本。<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Consumer&lt;UserSpec&gt;&lt;/font&gt;</code>支持你使用lambda来指定用户文本和任何默认参数。</li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;defaultAdvisors(Advisor… advisor)&lt;/font&gt;</code>：Advisor程序允许修改用于创建<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Prompt&lt;/font&gt;</code>的数据。<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;QuestionAnswerAdvisor&lt;/font&gt;</code>实现通过在提示词后附加与用户文本相关的上下文信息，支持<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Retrieval Augmented Generation&lt;/font&gt;</code>模式。</li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;defaultAdvisors(Consumer&lt;AdvisorSpec&gt; advisorSpecConsumer)&lt;/font&gt;</code>：此方法允许您定义一个<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Consumer&lt;/font&gt;</code>，以使用<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;AdvisorSpec&lt;/font&gt;</code>配置多个Advisor。Advisor可以修改用于创建最终<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Prompt&lt;/font&gt;</code>的数据。<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Consumer&lt;AdvisorSpec&gt;&lt;/font&gt;</code>允许您指定一个lambda来添加Advisor，例如QuestionAnswerAdvisor，它通过根据用户文本附加相关上下文信息来支持<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Retrieval Augmented Generation&lt;/font&gt;</code>。</li></ul><p>你也可以在运行时使用相应的方法（不带<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;default&lt;/font&gt;</code>前缀）来覆盖这些默认值：</p><ul><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;options(ChatOptions chatOptions)&lt;/font&gt;</code></li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;function(String name, String description, java.util.function.Function&lt;I, O&gt; function)&lt;/font&gt;</code></li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;functions(String… functionNames)&lt;/font&gt;</code></li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;user(String text)&lt;/font&gt;</code>，<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;user(Resource text)&lt;/font&gt;</code>，<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;user(Consumer&lt;UserSpec&gt; userSpecConsumer)&lt;/font&gt;</code></li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;advisors(Advisor… advisor)&lt;/font&gt;</code></li><li><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;advisors(Consumer&lt;AdvisorSpec&gt; advisorSpecConsumer)&lt;/font&gt;</code></li></ul><h1 id="顾问-Advisors"><a href="#顾问-Advisors" class="headerlink" title="顾问(Advisors)"></a>顾问(Advisors)</h1><p>Advisors API 提供了一种灵活而强大的方式，用于拦截、修改和增强Spring应用程序中的 AI 驱动交互。</p><p>在使用用户文本调用人工智能模型时，一种常见模式是在提示词中添加或补充上下文数据。</p><p>这些上下文数据可以有不同的类型。常见类型包括：</p><ul><li><strong>您自己的数据</strong>：这是AI模型未经过训练的数据。即便模型见过类似的数据，附加的上下文数据在生成响应时也具有优先性。</li><li><strong>对话历史记录</strong>：聊天模型的API是无状态的。如果你告诉AI模型你的名字，它在后续交互中不会记住这个名字。每次请求都必须发送对话历史，以确保生成响应时会考虑之前的交互。</li></ul><h2 id="ChatClient中的顾问配置"><a href="#ChatClient中的顾问配置" class="headerlink" title="ChatClient中的顾问配置"></a><font style="color:rgb(25, 30, 30);">ChatClient中</font>的顾问配置</h2><p>ChatClient流畅API 提供了一个 <code>AdvisorSpec</code> 接口，用于配置顾问。该接口提供了添加参数、一次性设置多个参数以及向链中添加一个或多个顾问的方法。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">interface AdvisorSpec &#123;</span><br><span class="line">    AdvisorSpec param(String k, Object v);</span><br><span class="line">    AdvisorSpec params(Map&lt;String, Object&gt; p);</span><br><span class="line">    AdvisorSpec advisors(Advisor... advisors);</span><br><span class="line">    AdvisorSpec advisors(List&lt;Advisor&gt; advisors);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>向链中添加顾问的顺序至关重要，因为它决定了顾问的执行顺序。每个顾问以某种方式修改提示或上下文，一个顾问所做的更改会传递给链中的下一个。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ChatClient.builder(chatModel)</span><br><span class="line">    .build()</span><br><span class="line">    .prompt()</span><br><span class="line">    .advisors(</span><br><span class="line">        MessageChatMemoryAdvisor.builder(chatMemory).build(),</span><br><span class="line">        QuestionAnswerAdvisor.builder(vectorStore).build()</span><br><span class="line">    )</span><br><span class="line">    .user(userText)</span><br><span class="line">    .call()</span><br><span class="line">    .content();</span><br></pre></td></tr></table></figure><p>在上述配置下，<code>MessageChatMemoryAdvisor</code>将首先执行，把对话历史添加到提示词中。然后，<code>QuestionAnswerAdvisor</code>会根据用户的问题和添加的对话历史进行搜索，有可能提供更相关的结果。</p><h2 id="检索增强生成"><a href="#检索增强生成" class="headerlink" title="检索增强生成"></a><font style="color:rgb(0, 0, 0);">检索增强生成</font></h2><p>向量数据库存储了 AI 模型不知道的数据。当用户问题发送到 AI 模型时，QuestionAnswerAdvisor 会为与用户问题相关的文档查询向量数据库。向量数据库的响应被追加到用户文本中，为 AI 模型生成响应提供上下文。</p><p>假设您已经将数据加载到 VectorStore 中，您可以通过向ChatClient提供QuestionAnswerAdvisor实例来执行检索增强生成（RAG）:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ChatResponse response = ChatClient.builder(chatModel)</span><br><span class="line">        .build().prompt()</span><br><span class="line">        .advisors(new QuestionAnswerAdvisor(vectorStore, SearchRequest.defaults()))</span><br><span class="line">        .user(userText)</span><br><span class="line">        .call()</span><br><span class="line">        .chatResponse();</span><br></pre></td></tr></table></figure><p>在此示例中，SearchRequest.defaults() 将在 Vector Database 中对所有文档执行相似性搜索。要限制搜索的文档类型，SearchRequest 接受一个 SQL 样式的过滤表达式，该表达式在所有 VectorStores 中都是可移植的。</p><h2 id="动态过滤表达式"><a href="#动态过滤表达式" class="headerlink" title="动态过滤表达式"></a>动态过滤表达式</h2><p>使用 FILTER_EXPRESSION 顾问上下文参数在运行时更新 SearchRequest 过滤表达式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ChatClient chatClient = ChatClient.builder(chatModel)</span><br><span class="line">    .defaultAdvisors(new QuestionAnswerAdvisor(vectorStore, SearchRequest.defaults()))</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">// 在运行时更新过滤表达式</span><br><span class="line">String content = this.chatClient.prompt()</span><br><span class="line">    .user(&quot;Please answer my question XYZ&quot;)</span><br><span class="line">    .advisors(a -&gt; a.param(QuestionAnswerAdvisor.FILTER_EXPRESSION, &quot;type == &#x27;Spring&#x27;&quot;))</span><br><span class="line">    .call()</span><br><span class="line">    .content();</span><br></pre></td></tr></table></figure><p>FILTER_EXPRESSION 参数允许开发者根据提供的表达式动态过滤搜索结果。</p><h2 id="日志记录"><a href="#日志记录" class="headerlink" title="日志记录"></a>日志记录</h2><p><code>SimpleLoggerAdvisor</code>是一个记录器顾问，它会记录<code>ChatClient</code>的<code>request</code>和<code>response</code>数据。这对于调试和监控开发者的人工智能交互很有用。</p><blockquote><p>Spring AI支持对大语言模型和向量存储交互的可观测性。</p></blockquote><p>要启用日志记录，需要在创建ChatClient时将<code>SimpleLoggerAdvisor</code>添加到顾问链中。建议将其添加到链的末尾：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ChatResponse response = ChatClient.create(chatModel).prompt()</span><br><span class="line">        .advisors(new SimpleLoggerAdvisor())</span><br><span class="line">        .user(&quot;Tell me a joke?&quot;)</span><br><span class="line">        .call()</span><br><span class="line">        .chatResponse();</span><br></pre></td></tr></table></figure><p>要查看日志，请将advisor包的日志级别设置为<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;DEBUG&lt;/font&gt;</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logging.level.org.springframework.ai.chat.client.advisor=DEBUG</span><br></pre></td></tr></table></figure><p>将此添加到您的<code>application.properties</code>或<code>application.yaml</code>文件中。</p><p>开发者可以使用以下构造函数来自定义要记录的来自<code>AdvisedRequest</code>和<code>ChatResponse</code>的数据：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SimpleLoggerAdvisor(</span><br><span class="line">    Function&lt;ChatClientRequest, String&gt; requestToString,</span><br><span class="line">    Function&lt;ChatResponse, String&gt; responseToString,</span><br><span class="line">    int order</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>举个例子，如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SimpleLoggerAdvisor customLogger = new SimpleLoggerAdvisor(</span><br><span class="line">    request -&gt; &quot;Custom request: &quot; + request.prompt().getUserMessage(),</span><br><span class="line">    response -&gt; &quot;Custom response: &quot; + response.getResult(),</span><br><span class="line">    0</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>这样开发者就能够根据自己的特定需求定制记录的信息。</p><blockquote><p>在生产环境中记录敏感信息时要谨慎。</p></blockquote><h1 id="聊天记忆-ChatMemory"><a href="#聊天记忆-ChatMemory" class="headerlink" title="聊天记忆(ChatMemory)"></a>聊天记忆(ChatMemory)</h1><p><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatMemory&lt;/font&gt;</code>接口代表聊天对话记忆的存储。它提供了向对话添加消息、从对话检索消息以及清除对话历史的方法。</p><p>目前有一个内置实现：<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;MessageWindowChatMemory&lt;/font&gt;</code>。<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;MessageWindowChatMemory&lt;/font&gt;</code>是一种聊天记忆实现方式，它会维持一个消息窗口，消息数量最多为指定的最大规模（默认值：20条消息）。当消息数量超过这一限制时，较早的消息会被移除，但系统消息会被保留。如果添加了新的系统消息，所有之前的系统消息都会从记忆中删除。这确保了对话中始终能获取最新的上下文，同时控制了记忆的使用量。</p><p><font style="color:rgb(25, 30, 30);"></font></p><p><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;MessageWindowChatMemory&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">由</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatMemoryRepository&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">抽象提供支持，该抽象为聊天对话记忆提供了存储实现。目前有多种可用的实现，包括</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;InMemoryChatMemoryRepository&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">、</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;JdbcChatMemoryRepository&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">、</font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;CassandraChatMemoryRepository&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);"> 和 </font><code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Neo4jChatMemoryRepository&lt;/font&gt;</code><font style="color:rgb(25, 30, 30);">。</font></p><h1 id="实现说明"><a href="#实现说明" class="headerlink" title="实现说明"></a><font style="color:rgb(20, 24, 24);">实现说明</font></h1><p>在<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;ChatClient&lt;/font&gt;</code>中，命令式编程模型和响应式编程模型的结合使用是该API的一个独特之处。通常，一个应用程序要么采用响应式编程，要么采用命令式编程，而不会两者兼而有之。</p><ul><li>在自定义模型实现的HTTP客户端交互时，必须同时配置RestClient和WebClient。</li></ul><blockquote><p>由于Spring Boot3.4中存在一个漏洞，必须设置“spring.http.client.factory=jdk”属性。否则，该属性会默认设为“reactor”，这会破坏某些AI工作流，如ImageModel。</p></blockquote><ul><li>流处理仅通过响应式栈支持。因此，命令式应用程序必须包含响应式栈（例如，spring-boot-starter-webflux）。</li><li>非流式处理仅通过Servlet栈提供支持。因此，响应式应用程序必须包含Servlet栈（例如spring-boot-starter-web），并需接受一些调用会是阻塞式的。</li><li>工具调用是必要的，但会导致工作流阻塞。这还会造成Micrometer观测的部分中断（例如，ChatClient跨度和工具调用跨度未连接，因此前者仍不完整）。</li><li>内置的顾问对标准调用执行阻塞操作，对流式调用执行非阻塞操作。可通过每个顾问类上的构建器配置用于顾问流式调用的Reactor调度器。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h1&gt;&lt;p&gt;本篇开始学习学习Spring Ai提供的Chat Client Api，通过它可以很轻松的与大模型进行交互。&lt;/p&gt;
&lt;h1</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>SpringAi学习之快速入门</title>
    <link href="http://aichating.xyz/2025/05/10/2025-6-spring-ai-2-quick-start/"/>
    <id>http://aichating.xyz/2025/05/10/2025-6-spring-ai-2-quick-start/</id>
    <published>2025-05-10T10:01:20.000Z</published>
    <updated>2025-05-11T12:32:18.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>本篇开始使用Spring Ai，注意Spring Ai支持Spring Boot3.4.x版本，当Spring Boot 3.5.x版本发布时，也将提供支持。</p><h1 id="Spring-Initializr"><a href="#Spring-Initializr" class="headerlink" title="Spring Initializr"></a>Spring Initializr</h1><p>前往<a href="https://start.spring.io/"><font style="color:rgb(21, 101, 192);">start.spring.io</font></a><font style="color:rgb(25, 30, 30);">，</font>选择你想要在新应用中使用的人工智能模型和向量存储。</p><h1 id="Artifact-Repositories"><a href="#Artifact-Repositories" class="headerlink" title="Artifact Repositories"></a>Artifact Repositories</h1><h2 id="Milestones-Use-Maven-Central"><a href="#Milestones-Use-Maven-Central" class="headerlink" title="Milestones - Use Maven Central"></a><font style="color:rgb(20, 24, 24);">Milestones - Use Maven Central</font></h2><p>从1.0.0-M6版本开始，发行版已在Maven中央仓库提供。无需修改您的构建文件。</p><h2 id="Snapshots-Add-Snapshot-Repositories"><a href="#Snapshots-Add-Snapshot-Repositories" class="headerlink" title="Snapshots - Add Snapshot Repositories"></a><font style="color:rgb(20, 24, 24);">Snapshots - Add Snapshot Repositories</font></h2><p>要使用Snapshot（以及1.0.0-M6里程碑之前的）版本，你需要在构建文件中添加以下快照仓库。</p><p>将以下仓库定义添加到您的Maven或Gradle构建文件中：</p><p><strong>Maven</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&lt;repositories&gt;</span><br><span class="line">  &lt;repository&gt;</span><br><span class="line">    &lt;id&gt;spring-snapshots&lt;/id&gt;</span><br><span class="line">    &lt;name&gt;Spring Snapshots&lt;/name&gt;</span><br><span class="line">    &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt;</span><br><span class="line">    &lt;releases&gt;</span><br><span class="line">      &lt;enabled&gt;false&lt;/enabled&gt;</span><br><span class="line">    &lt;/releases&gt;</span><br><span class="line">  &lt;/repository&gt;</span><br><span class="line">  &lt;repository&gt;</span><br><span class="line">    &lt;name&gt;Central Portal Snapshots&lt;/name&gt;</span><br><span class="line">    &lt;id&gt;central-portal-snapshots&lt;/id&gt;</span><br><span class="line">    &lt;url&gt;https://central.sonatype.com/repository/maven-snapshots/&lt;/url&gt;</span><br><span class="line">    &lt;releases&gt;</span><br><span class="line">      &lt;enabled&gt;false&lt;/enabled&gt;</span><br><span class="line">    &lt;/releases&gt;</span><br><span class="line">    &lt;snapshots&gt;</span><br><span class="line">      &lt;enabled&gt;true&lt;/enabled&gt;</span><br><span class="line">    &lt;/snapshots&gt;</span><br><span class="line">  &lt;/repository&gt;</span><br><span class="line">&lt;/repositories&gt;</span><br></pre></td></tr></table></figure><p><strong>Gradle</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">repositories &#123;</span><br><span class="line">  mavenCentral()</span><br><span class="line">  maven &#123; url &#x27;https://repo.spring.io/milestone&#x27; &#125;</span><br><span class="line">  maven &#123; url &#x27;https://repo.spring.io/snapshot&#x27; &#125;</span><br><span class="line">  maven &#123;</span><br><span class="line">    name = &#x27;Central Portal Snapshots&#x27;</span><br><span class="line">    url = &#x27;https://central.sonatype.com/repository/maven-snapshots/&#x27;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="依赖管理"><a href="#依赖管理" class="headerlink" title="依赖管理"></a>依赖管理</h1><p>Spring AI物料清单（BOM）声明了特定版本的Spring AI所使用的所有依赖项的推荐版本。这是一个仅包含BOM的版本，它只包含依赖项管理，不包含插件声明或对Spring或Spring Boot的直接引用。你可以使用Spring Boot父POM，或者使用Spring Boot的BOM（<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;spring-boot-dependencies&lt;/font&gt;</code>）来管理Spring Boot版本。</p><p>将BOM添加到您的项目中：</p><p><strong>Maven</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependencyManagement&gt;</span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-ai-bom&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.0.0&lt;/version&gt;</span><br><span class="line">            &lt;type&gt;pom&lt;/type&gt;</span><br><span class="line">            &lt;scope&gt;import&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line">&lt;/dependencyManagement&gt;</span><br></pre></td></tr></table></figure><p><strong>Gradle</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dependencies &#123;</span><br><span class="line">  implementation platform(&quot;org.springframework.ai:spring-ai-bom:1.0.0&quot;)</span><br><span class="line">  //用希望使用的特定模块的启动器依赖项替换以下内容</span><br><span class="line">  implementation &#x27;org.springframework.ai:spring-ai-openai&#x27;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Gradle用户也可以通过利用Gradle（5.0及以上版本）对使用Maven BOM声明依赖约束的原生支持来使用Spring AI BOM。这可以通过在Gradle构建脚本的依赖项部分添加一个“platform”依赖处理方法来实现。</p><h1 id="添加特定组件的依赖"><a href="#添加特定组件的依赖" class="headerlink" title="添加特定组件的依赖"></a>添加特定组件的依赖</h1><p>文档中的以下各节显示了您需要添加到项目构建系统所需的依赖。</p><ul><li>聊天模型</li><li>嵌入模型</li><li>图像生成模型</li><li>转录模型</li><li>文本转语音（TTS）模型</li><li>向量数据库</li></ul><h1 id="示例项目"><a href="#示例项目" class="headerlink" title="示例项目"></a><font style="color:rgb(0, 0, 0);">示例项目</font></h1><p>开发者可以在GitHub上克隆这些项目以开始。</p><ul><li>航班预订助手</li></ul><p>github.com/tzolov/playground-flight-booking</p><p>一个AI驱动的系统，可以访问条款和条件（检索增强生成，RAG），访问执行操作的工具（Java方法）（函数调用）并使用大型语言模型与用户交互。</p><ul><li>OpenAI</li></ul><p>github.com/rd-1-2022/ai-openai-helloworld</p><ul><li>Azure OpenAI</li></ul><p>github.com/rd-1-2022/ai-azure-openai-helloworld</p><p>github.com/Azure-Samples/spring-ai-azure-workshop</p><h1 id="入门项目"><a href="#入门项目" class="headerlink" title="入门项目"></a>入门项目</h1><p>新建一个名为spring-ai-fly的项目，使用Spring Boot3.5.7 + JDK21版本，然后在其POM文件中新增如下依赖信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span><br><span class="line">         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;</span><br><span class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</span><br><span class="line">    &lt;parent&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;3.5.7&lt;/version&gt;</span><br><span class="line">        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;</span><br><span class="line">    &lt;/parent&gt;</span><br><span class="line">    &lt;groupId&gt;com.gutsyzhan&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-ai-fly&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;</span><br><span class="line">    &lt;name&gt;spring-ai-fly&lt;/name&gt;</span><br><span class="line">    &lt;description&gt;spring-ai-fly&lt;/description&gt;</span><br><span class="line">    &lt;url/&gt;</span><br><span class="line">    &lt;licenses&gt;</span><br><span class="line">        &lt;license/&gt;</span><br><span class="line">    &lt;/licenses&gt;</span><br><span class="line">    &lt;developers&gt;</span><br><span class="line">        &lt;developer/&gt;</span><br><span class="line">    &lt;/developers&gt;</span><br><span class="line">    &lt;scm&gt;</span><br><span class="line">        &lt;connection/&gt;</span><br><span class="line">        &lt;developerConnection/&gt;</span><br><span class="line">        &lt;tag/&gt;</span><br><span class="line">        &lt;url/&gt;</span><br><span class="line">    &lt;/scm&gt;</span><br><span class="line">    &lt;properties&gt;</span><br><span class="line">        &lt;java.version&gt;21&lt;/java.version&gt;</span><br><span class="line">    &lt;/properties&gt;</span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</span><br><span class="line">            &lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-ai-starter-model-openai&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependencyManagement&gt;</span><br><span class="line">        &lt;dependencies&gt;</span><br><span class="line">            &lt;dependency&gt;</span><br><span class="line">                &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;spring-ai-bom&lt;/artifactId&gt;</span><br><span class="line">                &lt;version&gt;1.0.0&lt;/version&gt;</span><br><span class="line">                &lt;type&gt;pom&lt;/type&gt;</span><br><span class="line">                &lt;scope&gt;import&lt;/scope&gt;</span><br><span class="line">            &lt;/dependency&gt;</span><br><span class="line">        &lt;/dependencies&gt;</span><br><span class="line">    &lt;/dependencyManagement&gt;</span><br><span class="line"></span><br><span class="line">    &lt;build&gt;</span><br><span class="line">        &lt;plugins&gt;</span><br><span class="line">            &lt;plugin&gt;</span><br><span class="line">                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;</span><br><span class="line">            &lt;/plugin&gt;</span><br><span class="line">        &lt;/plugins&gt;</span><br><span class="line">    &lt;/build&gt;</span><br><span class="line"></span><br><span class="line">&lt;/project&gt;</span><br></pre></td></tr></table></figure><p>我们使用的模式是qwen-plus，因此需要在application.yml配置文件中新增如下配置信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  application:</span><br><span class="line">    name: spring-ai-fly</span><br><span class="line">  ai:</span><br><span class="line">    openai:</span><br><span class="line">      api-key: sk-3333333333333fc2a8948f3116</span><br><span class="line">      base-url: https://dashscope.aliyuncs.com/compatible-mode</span><br><span class="line">      chat:</span><br><span class="line">        options:</span><br><span class="line">          model: qwen-plus</span><br><span class="line">server:</span><br><span class="line">  port: 8090</span><br></pre></td></tr></table></figure><p>后面的代码将会在此项目中进行编写。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h1&gt;&lt;p&gt;本篇开始使用Spring Ai，注意Spring Ai支持Spring Boot3.4.x版本，当Spring Boot 3</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>SpringAi学习之核心概念</title>
    <link href="http://aichating.xyz/2025/05/04/2025-5-spring-ai-1-core-concepts/"/>
    <id>http://aichating.xyz/2025/05/04/2025-5-spring-ai-1-core-concepts/</id>
    <published>2025-05-04T06:01:20.000Z</published>
    <updated>2025-05-04T14:31:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>本篇开始我们进入Spring Ai的学习，建议多浏览 <a href="https://docs.spring.io/spring-ai/reference/concepts.html">官方文档</a>，加深印象，使用的Spring Ai版本为1.0.0.</p><h1 id="模型-Models"><a href="#模型-Models" class="headerlink" title="模型(Models)"></a>模型(Models)</h1><p>人工智能模型是设计用来处理和生成信息的算法，通常模仿人类的认知功能。通过从大型数据集中学习模式和洞察力，这些模型可以做出预测，生成文本、图像或其他输出，增强各行各业的各种应用。</p><p>有许多不同类型的人工智能模型，每种都适合特定的用例。虽然 ChatGPT 及其生成式人工智能能力通过文本输入和输出吸引了用户，但许多模型和公司提供了多样化的输入和输出方式。在ChatGPT出现之前，很多人就对Midjourney和Stable Diffusion等文本到图像生成模型很感兴趣。</p><p>下表根据输入和输出类型对几个模型进行了分类：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762569546858-f5ab11e6-d7a7-4a1d-889a-c5479ff313ed.png"></p><p>Spring AI目前支持处理语言、图像和音频作为输入和输出的模型。表中最后一行接受文本作为输入并输出数字，这通常被称为文本嵌入，代表了AI模型中使用的内部数据结构。Spring AI支持嵌入功能，以实现更高级的用例。</p><p>像GPT这类模型的独特之处在于其预训练特性，正如GPT（即生成式预训练Transformer）中的“P”所表明的那样。这种预训练特性将人工智能转变为一种通用的开发工具，无需使用者具备深厚的机器学习或模型训练背景。</p><h1 id="提示-Prompts"><a href="#提示-Prompts" class="headerlink" title="提示(Prompts)"></a>提示(Prompts)</h1><h2 id="提示词介绍"><a href="#提示词介绍" class="headerlink" title="提示词介绍"></a>提示词介绍</h2><p>提示词是基于语言的输入基础，用于引导人工智能模型生成特定输出。对于熟悉ChatGPT的人来说，提示词可能看起来仅仅是输入到对话框中并发送给应用程序接口的文本。然而，它所包含的远不止这些。在许多人工智能模型中，提示词的文本并非只是一个简单的字符串。</p><p>ChatGPT的API在一个提示词中包含多个文本输入，每个文本输入都被分配了一个角色。例如，有系统角色，它告诉模型应该如何表现，并为交互设定上下文。还有用户角色，这通常是用户的输入。</p><p>撰写有效的提示词既是一门艺术，也是一门科学。ChatGPT 旨在用于人类对话。这与使用 SQL 来“提问”大相径庭。人们必须像与另一个人交谈一样与人工智能模型交流。</p><p>这种交互方式极为重要，以至于“提示词工程”这一术语已发展成为一门独立学科。目前已有越来越多的技术可提高提示词的有效性。花时间精心设计提示词能显著改善输出结果。</p><p>分享提示词已经成为一种常见做法，学术界也在积极研究这一课题。要创建一个有效的提示词，其背后的逻辑可能与直觉相悖（比如与SQL形成对比），最近的一篇研究论文就说明了这一点。该论文发现，最有效的提示词之一是以“深吸一口气，一步一步来解决这个问题”这句话开头的。这应该能让你明白语言为何如此重要。我们目前还不完全清楚如何最有效地利用这类技术的早期版本（如ChatGPT 3.5），更不用说那些正在开发的新版本了。</p><h2 id="提示词模板"><a href="#提示词模板" class="headerlink" title="提示词模板"></a>提示词模板</h2><p>创建有效的提示词需要确定请求的上下文，并将请求的部分内容替换为特定于用户输入的值。这个过程使用传统的基于文本的模板引擎来创建和管理提示。Spring AI 使用 OSS库StringTemplate来实现这一目的。</p><p>例如，考虑一个简单的提示模板：</p><blockquote><p>告诉我一个关于 {content} 的 {adjective} 笑话。</p></blockquote><p>在Spring AI中，提示模板可以比作Spring MVC架构中的“视图”。会提供一个模型对象（通常是一个<code>java.util.Map</code>）来填充模板中的占位符。“渲染后的”字符串会成为提供给AI模型的提示内容。</p><p><font style="color:rgb(25, 30, 30);"></font></p><p>发送给模型的提示词在具体数据格式上存在很大差异。提示词最初只是简单的字符串，后来逐渐发展为包含多条信息，其中每条信息中的每个字符串都代表着模型的一个不同角色。</p><h1 id="嵌入-Embeddings"><a href="#嵌入-Embeddings" class="headerlink" title="嵌入(Embeddings)"></a>嵌入(Embeddings)</h1><p>嵌入是文本、图像或视频的数值表示，能够捕捉输入之间的关系。</p><p>嵌入的工作原理是将文本、图像和视频转换为浮点数数组，称为向量。这些向量旨在捕捉文本、图像和视频的含义。嵌入数组的长度称为向量的维度。</p><p>通过计算两段文本的向量表示之间的数值距离，应用程序可以确定用于生成嵌入向量的对象之间的相似度。</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762570291048-9c485764-403e-46d7-af00-74bea7088bfb.png"></p><p>作为一名探索人工智能的Java开发者，没有必要去理解这些向量表示背后复杂的数学理论或具体实现。只需对它们在人工智能系统中的作用和功能有基本了解即可，尤其是在将人工智能功能集成到你的应用程序中时。</p><p>嵌入在检索增强生成（RAG）模式等实际应用中尤为重要。它们能够将数据表示为语义空间中的点，这类似于欧几里得几何中的二维空间，但维度更高。这意味着，就像欧几里得几何中平面上的点会根据其坐标而有近有远一样，在语义空间中，点的接近程度反映了含义的相似性。关于相似主题的句子在这个多维空间中位置更接近，就像图表上彼此靠近的点一样。这种接近性有助于完成文本分类、语义搜索甚至产品推荐等任务，因为它使人工智能能够根据相关概念在这个扩展的语义图景中的“位置”来识别并归类这些概念。</p><p>你可以将这个语义空间视为一个向量。</p><h1 id="令牌-Tokens"><a href="#令牌-Tokens" class="headerlink" title="令牌(Tokens)"></a>令牌(Tokens)</h1><p>令牌是人工智能模型工作方式的基本组成部分。在输入时，模型将词语转换为令牌；在输出时，它们将令牌转换回词语。</p><p>在英语中，一个标记大约相当于一个单词的75%。作为参考，莎士比亚的全部作品约有90万字，换算成标记约为120万个。</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762570460166-fcc67280-fe08-4d92-b6b8-6fe7f285eb4f.png"></p><p>或许更重要的是，令牌即金钱。在托管人工智能模型的背景下，您的费用由使用的令牌数量决定。输入和输出都会计入总令牌数。</p><p>此外，模型受令牌限制的约束，这会限制单次API调用中处理的文本量。这个阈值通常被称为“上下文窗口”。模型不会处理任何超过此限制的文本。</p><p>例如，ChatGPT3的令牌限制为4K，而GPT4提供多种选择，如8K、16K和32K。Anthropic的Claude AI模型具有10万令牌的限制，Meta最近的研究则推出了100万令牌限制的模型。</p><p>要用GPT4总结莎士比亚的作品集，你需要制定软件工程策略来分割数据，并在模型的上下文窗口限制内呈现这些数据。Spring AI项目可以帮助你完成这项任务。</p><h1 id="结构化输出-Structed-Output"><a href="#结构化输出-Structed-Output" class="headerlink" title="结构化输出(Structed Output)"></a>结构化输出(Structed Output)</h1><p>传统上，人工智能模型的输出是以<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;java.lang.String&lt;/font&gt;</code>形式呈现的，即便你要求回复采用JSON格式。它或许是一个正确的JSON，但并非JSON数据结构，而仅仅是一个字符串。此外，在提示词中要求“输出JSON”也并非100%准确。</p><p>这种复杂性催生了一个专门领域的出现，该领域涉及创建提示词以生成预期输出，随后将生成的简单字符串转换为可用于应用程序集成的数据结构。</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762570633290-00c1a91a-8d0a-44d2-a898-47194ecd1171.png"></p><p>结构化输出转换采用精心设计的提示词，通常需要与模型进行多次交互才能实现所需的格式。</p><h1 id="将你的数据和API带给人工智能模型-Bringing-Your-Data-amp-APIs-to-the-AI-Model"><a href="#将你的数据和API带给人工智能模型-Bringing-Your-Data-amp-APIs-to-the-AI-Model" class="headerlink" title="将你的数据和API带给人工智能模型(Bringing Your Data&amp;APIs to the AI Model)"></a>将你的数据和API带给人工智能模型(Bringing Your Data&amp;APIs to the AI Model)</h1><p>如何让人工智能模型掌握它未经过训练的信息？</p><p>请注意，GPT 3.5/4.0的数据集仅更新到2021年9月。因此，对于需要该日期之后知识的问题，模型会表示自己不知道答案。一个有趣的小知识是，这个数据集约为650GB。</p><p><font style="color:rgb(25, 30, 30);"></font></p><p>有三种技术可用于定制AI模型以整合您的数据：</p><ul><li><strong><font style="color:rgb(25, 30, 30);">微调</font></strong><font style="color:rgb(25, 30, 30);">：</font>这种传统的机器学习技术包括调整模型并改变其内部权重。然而，对于机器学习专家来说，这是一个具有挑战性的过程，并且对于像GPT这样的模型，由于其规模，微调极其耗费资源。此外，有些模型可能不提供此选项<font style="color:rgb(25, 30, 30);">。</font></li><li><strong><font style="color:rgb(25, 30, 30);">提示词填充</font></strong><font style="color:rgb(25, 30, 30);">：</font>一种更实用的替代方案是将你的数据嵌入到提供给模型的提示词中。考虑到模型的令牌限制，需要采用一些技术在模型的上下文窗口内呈现相关数据。这种方法通俗地称为“填充提示词”。Spring AI库可帮助你基于“填充提示词”技术（也称为检索增强生成（RAG））实现解决方案。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762570964780-33b87162-9b66-4fc0-90db-fa5d1bdba202.png"></p><ul><li>**<font style="color:rgb(25, 30, 30);">函数调用</font>**：这种技术允许注册自定义用户函数，将大型语言模型连接到外部系统的 API。Spring AI 大大简化了你需要编写的代码，以支持函数调用。</li></ul><h1 id="检索增强生成-Retrieval-Augmented-Generation"><a href="#检索增强生成-Retrieval-Augmented-Generation" class="headerlink" title="检索增强生成(Retrieval Augmented Generation)"></a>检索增强生成(Retrieval Augmented Generation)</h1><p>一种被称为检索增强生成（RAG）的技术应运而生，旨在解决将相关数据整合到提示词中以获得AI模型准确响应这一难题。</p><p>这种方法采用批处理式编程模型，即作业从文档中读取非结构化数据，进行转换，然后写入向量数据库。从宏观层面来看，这是一个ETL（提取、转换和加载）管道。向量数据库用于RAG技术的检索部分。</p><p>在将非结构化数据加载到向量数据库的过程中，最重要的转换之一是将原始文档分割成更小的片段。将原始文档分割成更小片段的过程包含两个重要步骤：</p><ol><li>将文档分割成多个部分，同时保留内容的语义边界。例如，对于包含段落和表格的文档，应避免在段落或表格中间分割文档。对于代码，应避免在方法实现的中间分割代码。</li><li>将文档的各部分进一步拆分成大小仅为AI模型令牌限制很小比例的部分。</li></ol><p>RAG的下一阶段是处理用户输入。当AI模型需要回答用户的问题时，该问题以及所有“相似”的文档片段会被放入发送给AI模型的提示词中。这就是使用向量数据库的原因，它非常擅长找到相似的内容。</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762571204658-fe105cbe-90d5-464c-824b-95343c4e94d9.png"></p><ul><li>ETL 管道提供了有关编排从数据源提取数据并将其存储在结构化向量存储中的流程的更多信息，确保数据在传递给 AI 模型时处于最适合检索的格式。</li><li>ChatClient - RAG 解释了如何使用 QuestionAnswerAdvisor 在你的应用程序中启用 RAG 功能。</li></ul><h1 id="函数调用-Function-Calling"><a href="#函数调用-Function-Calling" class="headerlink" title="函数调用(Function Calling)"></a>函数调用(Function Calling)</h1><p>大型语言模型（LLMs）在训练后会被冻结，这导致知识陈旧，而且它们无法访问或修改外部数据。</p><p>函数调用机制解决了这些不足。它允许你注册自己的函数，将大型语言模型连接到外部系统的 API。这些系统可以代表 LLMs 提供实时数据并执行数据处理操作。</p><p>Spring AI 极大地简化了支持工具调用所需编写的代码。它会为你处理工具调用的对话。你可以将工具作为带有<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;@Tool&lt;/font&gt;</code>注解的方法提供，并在提示选项中提供该方法，以便模型可以使用它。此外，你可以在单个提示中定义和引用多个工具。</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1762571416432-cd82a329-1e1b-4061-b324-7a5a47c8a85b.png"></p><ol><li>当我们希望让模型能够使用某个工具时，我们会在聊天请求中包含该工具的定义。每个工具定义都由名称、描述和输入参数的模式组成。</li><li>当模型决定调用工具时，它会发送一个包含工具名称和根据已定义模式建模的输入参数的响应。</li><li>该应用程序负责使用工具名称来识别工具，并利用提供的输入参数执行该工具。</li><li>工具调用的结果由应用程序处理。</li><li>应用程序将工具调用结果发送回模型。</li><li>该模型将工具调用结果作为额外上下文来生成最终响应。</li></ol><p>遵循函数调用文档，以获取如何将此功能与不同人工智能模型一起使用的更多信息。</p><h1 id="评估人工智能响应-Evaluating-AI-responses"><a href="#评估人工智能响应-Evaluating-AI-responses" class="headerlink" title="评估人工智能响应(Evaluating AI responses)"></a>评估人工智能响应(Evaluating AI responses)</h1><p>有效评估人工智能系统针对用户请求所生成的输出，对于确保最终应用的准确性和实用性而言至关重要。一些新兴技术使预训练模型本身能够用于此目的。</p><p>这一评估过程包括分析生成的响应是否与用户意图及查询语境相符。评估人工智能生成响应质量时，会用到相关性、连贯性和事实准确性等指标。</p><p>一种方法是向模型呈现用户的请求和AI模型的响应，询问该响应是否与所提供的数据一致。</p><p>此外，利用向量数据库中存储的信息作为补充数据可以增强评估过程，有助于确定响应的相关性。</p><p>Spring AI项目提供了一个<code>&lt;font style=&quot;color:rgb(25, 30, 30);&quot;&gt;Evaluator&lt;/font&gt;</code>API，目前可用于获取评估模型响应的基本策略。有关更多信息，请参阅评估测试文档。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h1&gt;&lt;p&gt;本篇开始我们进入Spring Ai的学习，建议多浏览 &lt;a href=&quot;https://docs.spring.io/spr</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot+MCP实现本地工具调用实战</title>
    <link href="http://aichating.xyz/2025/04/06/2025-4-practical-implementation-of-local-tool-call-using-springboot-MCP/"/>
    <id>http://aichating.xyz/2025/04/06/2025-4-practical-implementation-of-local-tool-call-using-springboot-MCP/</id>
    <published>2025-04-06T10:03:01.000Z</published>
    <updated>2025-06-02T13:53:06.824Z</updated>
    
    <content type="html"><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>前面我们学习了MCP以及其中的三个角色，包含客户端、服务端和资源端，对应的解释如下：</p><p>（1）客户端：可理解为是Ai应用层，如聊天对话框。用户输入信息后，由客户端接口接收，再由客户端调用服务端调配资源处理；</p><p>（2）服务端：可理解为注册中心，请注意所有的工具都是注册在服务端；</p><p>（3）资源端：资源端就是大模型解析之后的用户需求的服务，即实际的处理逻辑。资源端可以和服务端部署在一起，也可以单独部署。</p><h1 id="资源端"><a href="#资源端" class="headerlink" title="资源端"></a>资源端</h1><p>第一步，新建一个名为ai-mcp-server的SpringBoot项目，注意SpringBoot版本为3.4.2，JDK版本为17。之后pom.xml文件信息如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span><br><span class="line">         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;</span><br><span class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</span><br><span class="line">    &lt;parent&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;3.4.2&lt;/version&gt;</span><br><span class="line">        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;</span><br><span class="line">    &lt;/parent&gt;</span><br><span class="line">    &lt;groupId&gt;com.gutsyzhan&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;ai-mcp-server&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;</span><br><span class="line">    &lt;name&gt;ai-mcp-server&lt;/name&gt;</span><br><span class="line">    &lt;description&gt;ai-mcp-server&lt;/description&gt;</span><br><span class="line">    &lt;properties&gt;</span><br><span class="line">        &lt;java.version&gt;17&lt;/java.version&gt;</span><br><span class="line">        &lt;spring-ai.version&gt;1.0.0-M6&lt;/spring-ai.version&gt;</span><br><span class="line">    &lt;/properties&gt;</span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-ai-mcp-server-webmvc-spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</span><br><span class="line">            &lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependencyManagement&gt;</span><br><span class="line">        &lt;dependencies&gt;</span><br><span class="line">            &lt;dependency&gt;</span><br><span class="line">                &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;spring-ai-bom&lt;/artifactId&gt;</span><br><span class="line">                &lt;version&gt;$&#123;spring-ai.version&#125;&lt;/version&gt;</span><br><span class="line">                &lt;type&gt;pom&lt;/type&gt;</span><br><span class="line">                &lt;scope&gt;import&lt;/scope&gt;</span><br><span class="line">            &lt;/dependency&gt;</span><br><span class="line">        &lt;/dependencies&gt;</span><br><span class="line">    &lt;/dependencyManagement&gt;</span><br><span class="line">    &lt;build&gt;</span><br><span class="line">        &lt;plugins&gt;</span><br><span class="line">            &lt;plugin&gt;</span><br><span class="line">                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;</span><br><span class="line">            &lt;/plugin&gt;</span><br><span class="line">        &lt;/plugins&gt;</span><br><span class="line">    &lt;/build&gt;</span><br><span class="line">&lt;/project&gt;</span><br></pre></td></tr></table></figure><p>第二步，新建一个名为service的包，我们在里面定义两个类，分别用于实现数据采集和数据生成功能。新建一个名为DataAcquisitionService的类，里面的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">@Service</span><br><span class="line">public class DataAcquisitionService &#123;</span><br><span class="line">    @Tool(description = &quot;数据采集工具，从一个源头数据源中采集数据到目标数据源&quot;)</span><br><span class="line">    public String acquisition(</span><br><span class="line">            @ToolParam(description = &quot;源头数据源&quot;)String sourceDB,</span><br><span class="line">            @ToolParam(description = &quot;目标数据源&quot;)String targetDB,</span><br><span class="line">            @ToolParam(description = &quot;源头数据表&quot;)String sourceTable,</span><br><span class="line">            @ToolParam(description = &quot;目标数据表&quot;)String targetTable,</span><br><span class="line">            @ToolParam(description = &quot;采集策略&quot;)String type</span><br><span class="line">    )&#123;</span><br><span class="line">        //采集逻辑</span><br><span class="line">        System.out.println(&quot;数据采集信息为：&quot;+&quot;\n,源头数据源=&quot; + sourceDB +</span><br><span class="line">                &quot;\n,目标数据源=&quot;+ targetDB + &quot;\n,源头数据表=&quot; + sourceTable +</span><br><span class="line">                &quot;\n,目标数据表=&quot; + targetTable + &quot;\n,采集策略=&quot; + type);</span><br><span class="line">        return &quot;数据采集成功&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里我们模拟数据采集的逻辑，从源头数据源的数据表中，根据指定的策略，将数据采集到目标数据源的表中。接着再新建一个名为DataInterfaceService的类，里面的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">@Service</span><br><span class="line">public class DataInterfaceService &#123;</span><br><span class="line">    @Tool(description = &quot;数据服务工具，用于生成一个数据接口&quot;)</span><br><span class="line">    public String produceMsg(</span><br><span class="line">            @ToolParam(description = &quot;服务名称&quot;)String interfaceName,</span><br><span class="line">            @ToolParam(description = &quot;数据源&quot;)String dataSource,</span><br><span class="line">            @ToolParam(description = &quot;查询语句&quot;)String sql,</span><br><span class="line">            @ToolParam(description = &quot;入参&quot;)String inParams,</span><br><span class="line">            @ToolParam(description = &quot;出参&quot;)String outParams</span><br><span class="line">    )&#123;</span><br><span class="line">        //生成逻辑</span><br><span class="line">        System.out.println(&quot;数据生成信息为：&quot;+&quot;\n,服务名称=&quot; + interfaceName +</span><br><span class="line">                &quot;\n,数据源=&quot;+ dataSource + &quot;\n,查询语句=&quot; + sql +</span><br><span class="line">                &quot;\n,入参=&quot; + inParams + &quot;\n,出参=&quot; + outParams);</span><br><span class="line">        return &quot;数据生成成功&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同样这里我们模拟数据生成的逻辑，定义一个服务名称，根据传入的参数和查询语句，从源数据源中查询得到出参数据。</p><h1 id="服务端"><a href="#服务端" class="headerlink" title="服务端"></a>服务端</h1><p>这里我们将服务端和资源端写在一个项目中，在applicaiton.yml配置文件中新增如下配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">server:</span><br><span class="line">  port: 8009</span><br><span class="line"># 服务端定义</span><br><span class="line">spring:</span><br><span class="line">  ai:</span><br><span class="line">    mcp:</span><br><span class="line">      server:</span><br><span class="line">        name: ai-mcp-server</span><br><span class="line">        version: 0.0.1</span><br><span class="line"># 服务方式（同步或者异步）</span><br><span class="line">        type: SYNC</span><br><span class="line"># MCP有两种通讯方式stdio（内部进程通讯）和Server-Sent Events（SSE服务器发送事件）</span><br><span class="line">        stdio: false</span><br><span class="line">        sse-message-endpoint: /mcp/message</span><br><span class="line">        enabled: true</span><br><span class="line"># 变化通知</span><br><span class="line">        resource-change-notification: true</span><br><span class="line">        tool-change-notification: true</span><br><span class="line">        prompt-change-notification: true</span><br></pre></td></tr></table></figure><p>当然，如果使用的是MCP的内部进程通讯方式，需要添加如下两行配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spring.main.banner-mode=off</span><br><span class="line">logging.file.name=D:/logs/server.log</span><br></pre></td></tr></table></figure><p>定义一个名为CustomServer的类，里面的代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@Component</span><br><span class="line">public class CustomServer &#123;</span><br><span class="line">    @Bean</span><br><span class="line">    public ToolCallbackProvider myTools(DataAcquisitionService dataAcquisitionService,</span><br><span class="line">                                        DataInterfaceService dataInterfaceService)&#123;</span><br><span class="line">        return MethodToolCallbackProvider.builder().toolObjects(dataAcquisitionService</span><br><span class="line">        ,dataInterfaceService).build();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此处就是将工具注册进来，方便后续客户端调用。</p><h1 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h1><p>客户端笔者建议另起一个新的项目来写，第一步，新建一个名为ai-mcp-client的SpringBoot项目，注意SpringBoot版本为3.4.2，JDK版本为17。之后pom.xml文件信息如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span><br><span class="line">         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;</span><br><span class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</span><br><span class="line">    &lt;parent&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;3.4.2&lt;/version&gt;</span><br><span class="line">        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;</span><br><span class="line">    &lt;/parent&gt;</span><br><span class="line">    &lt;groupId&gt;com.gutsyzhan&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;ai-mcp-client&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;</span><br><span class="line">    &lt;name&gt;ai-mcp-client&lt;/name&gt;</span><br><span class="line">    &lt;description&gt;ai-mcp-client&lt;/description&gt;</span><br><span class="line">    &lt;properties&gt;</span><br><span class="line">        &lt;java.version&gt;17&lt;/java.version&gt;</span><br><span class="line">        &lt;spring-ai.version&gt;1.0.0-M6&lt;/spring-ai.version&gt;</span><br><span class="line">    &lt;/properties&gt;</span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-ai-mcp-client-spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-ai-ollama-spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</span><br><span class="line">            &lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependencyManagement&gt;</span><br><span class="line">        &lt;dependencies&gt;</span><br><span class="line">            &lt;dependency&gt;</span><br><span class="line">                &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;spring-ai-bom&lt;/artifactId&gt;</span><br><span class="line">                &lt;version&gt;$&#123;spring-ai.version&#125;&lt;/version&gt;</span><br><span class="line">                &lt;type&gt;pom&lt;/type&gt;</span><br><span class="line">                &lt;scope&gt;import&lt;/scope&gt;</span><br><span class="line">            &lt;/dependency&gt;</span><br><span class="line">        &lt;/dependencies&gt;</span><br><span class="line">    &lt;/dependencyManagement&gt;</span><br><span class="line">    &lt;build&gt;</span><br><span class="line">        &lt;plugins&gt;</span><br><span class="line">            &lt;plugin&gt;</span><br><span class="line">                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;</span><br><span class="line">            &lt;/plugin&gt;</span><br><span class="line">        &lt;/plugins&gt;</span><br><span class="line">    &lt;/build&gt;</span><br><span class="line">&lt;/project&gt;</span><br></pre></td></tr></table></figure><p>第二步，修改application.yml配置文件中的内容为如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  application:</span><br><span class="line">    name: ai-mcp-client</span><br><span class="line">  main:</span><br><span class="line">    web-application-type: none</span><br><span class="line">  ai:</span><br><span class="line">    ollama:</span><br><span class="line">      base-url: http://127.0.0.1:11434</span><br><span class="line">      chat:</span><br><span class="line">        options:</span><br><span class="line">          model: qwen3:1.7b</span><br><span class="line">          temperature: 0.7</span><br><span class="line">    mcp:</span><br><span class="line">      client:</span><br><span class="line">        sse:</span><br><span class="line">          connections:</span><br><span class="line">            server1:</span><br><span class="line">              url: http://127.0.0.1:8009</span><br><span class="line">server:</span><br><span class="line">  port: 8010</span><br><span class="line"># ai.user.input表示用户的需求</span><br><span class="line">ai:</span><br><span class="line">  user:</span><br><span class="line">    input: 第一步，将prod数据源中的t_order表中的数据全量采集到test数据源的t_order表中，第二步再生成一个数据接口，用于获取所有的用户，从prod数据源中查询全量的用户数据，入参为default，出参为用户名和时间</span><br></pre></td></tr></table></figure><p>第三步，新建一个名为client的包，并在里面定义一个名为CustomClient的类，里面的代码如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">@Component</span><br><span class="line">public class CustomClient &#123;</span><br><span class="line">    @Value(&quot;$&#123;ai.user.input&#125;&quot;)</span><br><span class="line">    private String userInput;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    public CommandLineRunner solveQuestion(ChatClient.Builder chatBuilder,</span><br><span class="line">                                           ToolCallbackProvider tools,</span><br><span class="line">                                           ConfigurableApplicationContext context)&#123;</span><br><span class="line">        return (args -&gt; &#123;</span><br><span class="line">            ChatClient chatClient = chatBuilder.defaultTools(tools).build();</span><br><span class="line">            System.out.println(&quot;\n&gt;&gt;&gt; 问题为：&quot; + userInput);</span><br><span class="line">            System.out.println(&quot;\n&gt;&gt;&gt; 参考方法为：&quot; + chatClient.prompt(userInput).call().content());</span><br><span class="line">            context.close();</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到这里我们将用户输入的信息直接写在了配置文件中，通过@Value注解进行获取。项目在启动时，会将其传入给服务端，服务端将用户输入和注册的工具列表一起传给大模型。大模型会根据需求来进行工具匹配，匹配到对应工具之后，再看参数是否对应的上，如果对应的上，则执行具体的逻辑，如果匹配不上，则不执行对应逻辑。</p><p>第四步，先启动服务端项目，再启动客户端，可以发现此时客户端输出如下信息：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748784400499-53f95aa5-f7fe-46de-82a2-65b2293f7cd9.png"></p><p>接着再去看服务端，可以看到客户端也输出如下信息：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748784375939-34eb7325-6568-4774-9db1-94bd14f50cbd.png"></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>本篇通过一个实战项目学习了如何使用SpringBoot和MCP实现本地工具调用。请注意，如果开发者存在多个工具进行编排的需求，如何保证工具调用的顺序呢？实际上我们只需在问题描述中，写清楚你每一步需要做什么，然后大模型就会找到对应的工具类，并按照顺序进行调用，所不同的是，这种编排动作是在输入内容中完成的。</p><p>看到这里你可能会有疑问，MCP方式和注入Dify配置工作流这种方式有什么区别？我们知道MCP它是大模型上下文协议，提供了一种大模型调用本地工具，使用本地文件的一种规范，开发者可以使用这种方式将本地逻辑发布为工具，以满足用户对需求不明的诉求，如果大模型找不到满足要求的工具，则会给出一个合适的回复，这样用户也能接受。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h1&gt;&lt;p&gt;前面我们学习了MCP以及其中的三个角色，包含客户端、服务端和资源端，对应的解释如下：&lt;/p&gt;
&lt;p&gt;（1）客户端：可理解为是</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>聊一聊最近很火的MCP协议</title>
    <link href="http://aichating.xyz/2025/03/01/2025-3-let&#39;s-talk-about-the-recently-popular-MCP-protocol/"/>
    <id>http://aichating.xyz/2025/03/01/2025-3-let&#39;s-talk-about-the-recently-popular-MCP-protocol/</id>
    <published>2025-03-01T11:05:08.000Z</published>
    <updated>2025-06-02T13:50:06.832Z</updated>
    
    <content type="html"><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>笔者最近在用Dify调用工具，但是发现效果非常不好，而且内部都是封装好的，不知道它是如何调用工具的。而现在公司恰好有些需求是要求让大模型直接调用本地文件，目前只能将文件上传上去，但是大模型的数据通常都是截止到某个时间点的，即训练的数据集始终是落后且固定的，无法实时获取数据。</p><p>当然我们可以使用联网搜索，也可以使用知识库，接口等方式将自己的数据上传给大模型，但是感觉使用起来还是差点意思，无法做到架构的统一化。鉴于此，MCP协议诞生了。</p><h1 id="什么是MCP"><a href="#什么是MCP" class="headerlink" title="什么是MCP"></a>什么是MCP</h1><p><a href="https://modelcontextprotocol.io/">MCP</a>全称（Model Context Protocol），即模型上下文协议，是美国一家Ai初创公司Anthropic于2024年11月推出的一种开放协议，旨在标准化大模型（LLM）与外部数据源、工具的交互方式。Anthropic<font style="color:rgb(63, 63, 63);">也是大语言模型Claude的母公司。</font></p><p><font style="color:rgb(63, 63, 63);"></font></p><p><font style="color:rgb(63, 63, 63);">MCP的主要目的在于解决当前AI模型因数据孤岛限制而无法充分发挥潜力的难题，MCP可以使AI应用能够在安全控制下，访问及操作本地和远程数据，为AI应用提供了连接万物的接口。</font></p><p><font style="color:rgb(63, 63, 63);"></font></p><p><font style="color:rgb(63, 63, 63);">即MCP可直接在AI与数据（包括本地数据和互联网数据）之间架起一座桥梁，通过MCP服务器和MCP客户端，开发者只需遵守这套协议，就能实现“万物互联”。有了MCP，可以和数据和文件系统、开发工具、Web和浏览器自动化、生产力和通信、各种社区生态能力全部集成，实现强大的协作工作能力，大模型+MCP+生态工具的价值将变得不可估量。</font></p><p><font style="color:rgb(63, 63, 63);">举个例子，现在有一个图书管理系统，当你使用MCP进行改造后，不论是ChatGPT还是Claude，都能使用同一套指令实现图书的增删改查，而不用为每个Ai单独开发对应的接口。</font></p><h1 id="MCP与Function-Calling的对比"><a href="#MCP与Function-Calling的对比" class="headerlink" title="MCP与Function Calling的对比"></a><font style="color:rgb(63, 63, 63);">MCP与Function Calling的对比</font></h1><p>我们知道，<font style="color:rgb(63, 63, 63);">Function Calling是AI模型调用函数的机制，而MCP是一个标准协议，它使AI模型与API无缝交互。AI Agent是一个自主运行的智能系统，利用Function Callling和MCP来分析和执行任务，实现特定目标。</font></p><p>下面这张图便是MCP与<font style="color:rgb(63, 63, 63);">Function Calling的对比：</font></p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748836799555-0d6fb5f9-1e23-4010-aa6a-58898b182383.png"></p><h1 id="数据安全"><a href="#数据安全" class="headerlink" title="数据安全"></a>数据安全</h1><p>前<font style="color:rgb(63, 63, 63);">MCP通过标准化的数据访问接口，减少了与数据直接接触，降低了数据泄露风险，使AI应用能够在安全控制下，访问及操作本地和远程数据，为AI应用提供了连接万物的接口。</font></p><p><font style="color:rgb(63, 63, 63);"></font></p><p>实际上，MCP服务器内置了安全机制，确保只有经过验证的请求才能访问特定资源，相当于又加了一把安全锁。且MCP还支持多种加密算法，以确保数据在传输过程中的安全性。</p><h1 id="MCP的核心原理"><a href="#MCP的核心原理" class="headerlink" title="MCP的核心原理"></a>MCP的核心原理</h1><p>MCP协议采用了独特的架构设计，将大模型与资源之间的通信划分为三个部分，即客户端、服务端和资源端。</p><p>客户端负责将请求发送给MCP服务器，而服务器则将这些请求转发给对应的资源端。这种分层设计使得MCP协议能够很好的实现权限控制，确保只有经过授权的用户才能访问特定的资源。</p><h2 id="MCP的基本工作流程"><a href="#MCP的基本工作流程" class="headerlink" title="MCP的基本工作流程"></a>MCP的基本工作流程</h2><p>MCP的基本工作流程如下：</p><p>（1）<strong>初始化连接请求</strong>：客户端向服务器发送连接请求，建立通信通道；</p><p>（2）<strong>发送请求</strong>：客户端根据需求来构建请求信息，并发送给服务器；</p><p>（3）<strong>处理请求</strong>：服务器在接收到请求之后，解析请求内容，并执行对应的操作，如查询数据库，读取文件等；</p><p>（4）<strong>返回结果</strong>：服务器将处理结果封装为响应消息，发送给客户端；</p><p>（5）<strong>断开连接</strong>：任务完成后，客户端可以主动关闭连接或者等待服务器超时关闭。</p><p>上述流程对应的示意图如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748852069115-ad037623-c85e-4f35-8f3b-d69761e677c0.png"></p><h2 id="MCP客户端工作流程"><a href="#MCP客户端工作流程" class="headerlink" title="MCP客户端工作流程"></a>MCP客户端工作流程</h2><p>下面是MCP客户端的工作流程，如下所示：</p><p>（1）MCP客户端首先从MCP服务器获取可用的工具列表；</p><p>（2）将用户的查询连同工具描述，通过Function Calling一起发送给LLM大模型；</p><p>（3）LLM大模型根据需求来决定是否使用工具以及使用哪些工具；</p><p>（4）如果需要使用工具，MCP客户端会通过MCP服务器执行对应的工具调用；</p><p>（5）工具调用的结果会发送给LLM大模型；</p><p>（6）最后将响应展示给用户。</p><h2 id="MCP服务器主要作用"><a href="#MCP服务器主要作用" class="headerlink" title="MCP服务器主要作用"></a>MCP服务器主要作用</h2><p>下面是MCP服务器提供的主要作用，如下所示：</p><p>（1）资源：类似文件的数据，可被客户端读取，如API响应或者文件内容；</p><p>（2）工具：可以被LLM调用的函数，注意这些需要得到用户的准许；</p><p>（3）提示：预先编写的模板，以帮助用户完成特定的任务。</p><p>这些作用使得MCP服务器为Ai应用提供丰富的上下文信息和操作能力，<font style="color:rgb(63, 63, 63);">从而增强LLM的实用性和灵活性。</font></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font style="color:rgb(63, 63, 63);">小结</font></h1><p>本篇我们学习了MCP以及其中的三个角色，包含客户端、服务端和资源端，对应的解释如下：</p><p><font style="color:rgb(63, 63, 63);">（1）客户端：可理解为是Ai应用层，如聊天对话框。用户输入信息后，由客户端接口接收，再由客户端调用服务端调配资源处理；</font></p><p><font style="color:rgb(63, 63, 63);">（2）服务端：可理解为注册中心，请注意所有的工具都是注册在服务端；</font></p><p><font style="color:rgb(63, 63, 63);">（3）资源端：资源端就是大模型解析之后的用户需求的服务，即实际的处理逻辑。资源端可以和服务端部署在一起，也可以单独部署。</font></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h1&gt;&lt;p&gt;笔者最近在用Dify调用工具，但是发现效果非常不好，而且内部都是封装好的，不知道它是如何调用工具的。而现在公司恰好有些需求是</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>如何在本地搭建LLM并使用</title>
    <link href="http://aichating.xyz/2025/02/23/2025-2-how-to-set-up-LLM-locally-and-use-it/"/>
    <id>http://aichating.xyz/2025/02/23/2025-2-how-to-set-up-LLM-locally-and-use-it/</id>
    <published>2025-02-23T09:03:01.000Z</published>
    <updated>2025-06-02T13:38:45.943Z</updated>
    
    <content type="html"><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>本篇来学习如何在Windows上安装属于开发者自己的大模型，主要以Ollama为例进行介绍。<font style="color:rgb(31, 28, 28);">Ollama 是一款优秀的开源工具，让开发者可以在本地轻松运行和管理各种大型语言模型（LLMs）。</font></p><h1 id="Ollama介绍"><a href="#Ollama介绍" class="headerlink" title="Ollama介绍"></a><font style="color:rgb(31, 28, 28);">Ollama介绍</font></h1><p><font style="color:rgb(31, 28, 28);">Ollama 是一个简化大型语言模型（LLM）部署和使用的工具。它具有以下特点：</font></p><ul><li><strong><font style="color:rgb(31, 28, 28);">本地运行：</font></strong><font style="color:rgb(31, 28, 28);"> 模型完全在您的本地计算机上运行，无需联网，保护您的隐私和数据安全。</font></li><li><strong><font style="color:rgb(31, 28, 28);">简单易用：</font></strong><font style="color:rgb(31, 28, 28);"> 通过简单的命令行指令，即可下载、运行和管理各种 LLM。</font></li><li><strong><font style="color:rgb(31, 28, 28);">模型丰富：</font></strong><font style="color:rgb(31, 28, 28);"> 支持 Llama 2、Deepseek、Mistral、Gemma 等多种流行的开源模型。</font></li><li><strong><font style="color:rgb(31, 28, 28);">跨平台：</font></strong><font style="color:rgb(31, 28, 28);"> 支持 macOS、Windows 和 Linux 系统。</font></li><li><strong><font style="color:rgb(31, 28, 28);">开放API</font></strong><font style="color:rgb(31, 28, 28);">：支持与OpenAI兼容的接口，可以和其他工具集成。</font></li></ul><h1 id="安装Ollama"><a href="#安装Ollama" class="headerlink" title="安装Ollama"></a>安装Ollama</h1><h2 id="Windows平台安装"><a href="#Windows平台安装" class="headerlink" title="Windows平台安装"></a>Windows平台安装</h2><p>点击 <a href="https://ollama.com/download/windows">Ollama官网</a>，选择合适的版本：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748754290798-f9444014-1e84-4005-8c5d-7a97561bf78a.png"></p><p>之后笔者将其下载到F盘，但是笔者希望将Ollama安装到E盘的指定目录下，此时可以是以如下方式进行安装目录自定义：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748754358509-03341080-ad1f-420e-b985-26629358fa81.png"></p><p>执行该命令，之后就会将Ollama安装到自定义目录下。</p><h2 id="MacOS平台安装"><a href="#MacOS平台安装" class="headerlink" title="MacOS平台安装"></a>MacOS平台安装</h2><p>点击 <a href="https://ollama.com/download/windows">Ollama官网</a>，选择合适的版本：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748754550878-4814adc7-2fbb-4642-923c-c240b14ad66d.png"></p><p>当然也可以到它们对应的github网站上获取：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748754653227-1ce7bc13-d216-4393-a2d6-6cccab154e22.png"></p><h2 id="Linux平台安装"><a href="#Linux平台安装" class="headerlink" title="Linux平台安装"></a>Linux平台安装</h2><p>点击 <a href="https://ollama.com/download/windows">Ollama官网</a>，选择合适的版本：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748754696620-4c655491-2ad5-4dbf-90fa-7eb0f46da0de.png"></p><p>可以看到这里没有提供直接的下载地址，而是使用命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -fsSL https://ollama.com/install.sh | sh</span><br></pre></td></tr></table></figure><p>实际上就是下载并执行，不过由于网络波动，笔者还是建议先下载该脚本：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget  https://ollama.com/install.sh</span><br></pre></td></tr></table></figure><p>之后修改Ollama的安装目录，安装成功后查看一下版本：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">D:\Application\ollama&gt;ollama -v</span><br><span class="line">ollama version is 0.9.0</span><br></pre></td></tr></table></figure><h1 id="安装对应模型"><a href="#安装对应模型" class="headerlink" title="安装对应模型"></a>安装对应模型</h1><h2 id="自定义模型安装路径"><a href="#自定义模型安装路径" class="headerlink" title="自定义模型安装路径"></a>自定义模型安装路径</h2><p>首先，停止运行Ollama，接着打开系统环境变量，在里面新增一个名为OLLAMA_MODELS的变量名，值为笔者打算存放模型的路径E:\OllamaModels\models，完整参数如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748759155519-289c1d6d-6020-43f4-8712-e6c330d6d02d.png"></p><p>之后需要重新启动Ollama，这样才能保证自定义路径已经生效。</p><h2 id="安装对应模型-1"><a href="#安装对应模型-1" class="headerlink" title="安装对应模型"></a>安装对应模型</h2><p>点击Ollama官网中的Models模块，可以看到这里面列举了很多常用的模型：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748756777532-ab60fb01-2f9e-4101-96e7-30d2ed0aa90e.png"></p><p>笔者这里选择deepseek-r1模型，同时选择了deepseek-r1:1.5b这一分支：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748756799935-9be8fd81-822a-497a-ba05-ba451c65c3fa.png"></p><p>之后在控制台执行如下命令来运行对应模型：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama run deepseek-r1:1.5b</span><br></pre></td></tr></table></figure><p>安装成功后，出现Send a message则表明已经安装成功：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748757570697-633a9788-ce57-4cc1-87eb-4a696983ad6f.png"></p><p>此时可以进入到之前自定义的模型存储路径：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748762695789-9f93cd40-c719-4155-9072-f12b1f343153.png"></p><p>也可以使用如下命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">E:\Application\Ollama&gt;ollama list</span><br><span class="line">NAME                ID              SIZE      MODIFIED</span><br><span class="line">deepseek-r1:1.5b    e0979632db5a    1.1 GB    29 minutes ago</span><br><span class="line">qwen3:1.7b          8f68893c685c    1.4 GB    47 minutes ago</span><br></pre></td></tr></table></figure><p>可以看到这里展示了笔者已经安装成功的2个模型。</p><h1 id="可视化调用"><a href="#可视化调用" class="headerlink" title="可视化调用"></a>可视化调用</h1><p>尽管模型启动后，可以使用终端进行交互，但是界面不美观，而且不易于管理，因此笔者建议使用可视化工具进行调用，这里选择CheeryStudio。</p><h2 id="为什么选择CheeryStudio"><a href="#为什么选择CheeryStudio" class="headerlink" title="为什么选择CheeryStudio"></a>为什么选择CheeryStudio</h2><p>之所以选择使用CheeryStudio中使用Ollama，是因为它具有如下四个特点：</p><ul><li><strong><font style="color:rgb(31, 28, 28);">无需云服务：</font></strong><font style="color:rgb(31, 28, 28);"> 不再受限于云端 API 的配额和费用，尽情体验本地 LLM 的强大功能。</font></li><li><strong><font style="color:rgb(31, 28, 28);">数据隐私：</font></strong><font style="color:rgb(31, 28, 28);"> 您的所有对话数据都保留在本地，无需担心隐私泄露。</font></li><li><strong><font style="color:rgb(31, 28, 28);">离线可用：</font></strong><font style="color:rgb(31, 28, 28);"> 即使在没有网络连接的情况下，也能继续与 LLM 进行交互。</font></li><li><strong><font style="color:rgb(31, 28, 28);">定制化：</font></strong><font style="color:rgb(31, 28, 28);"> 可以根据您的需求，选择和配置最适合您的 LLM</font></li></ul><h2 id="CheeryStudio的安装"><a href="#CheeryStudio的安装" class="headerlink" title="CheeryStudio的安装"></a>CheeryStudio的安装</h2><p>点击 <a href="https://www.cherry-ai.com/download">cherry官网</a>，选择对应的版本进行下载：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748763120280-d3f33eb7-6e99-477e-b702-5cc0f0b9829d.png"></p><p>请注意，在使用CheeryStudio与Ollama模型交互期间，需要保证Ollama处于运行状态。</p><h2 id="配置Ollama模型"><a href="#配置Ollama模型" class="headerlink" title="配置Ollama模型"></a>配置Ollama模型</h2><p>第一步，运行Ollama模型，然后打开CheeryStudio。</p><p>第二步，打开CheeryStudio中的设置，在设置页面选择模型服务，然后点击列表中的Ollama：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748763502435-557260cc-6d32-4732-ae5b-2182c2ff1133.png"></p><p>第三步，配置Ollama服务商。<font style="color:rgb(31, 28, 28);">在服务商列表中找到刚刚添加的 Ollama，并进行详细配置：</font></p><ol><li><strong><font style="color:rgb(31, 28, 28);">启用状态：</font></strong><ul><li><font style="color:rgb(31, 28, 28);">确保 Ollama 服务商最右侧的开关已打开，表示已启用。</font></li></ul></li><li><strong><font style="color:rgb(31, 28, 28);">API 密钥：</font></strong><ul><li><font style="color:rgb(31, 28, 28);">Ollama 默认</font><strong><font style="color:rgb(31, 28, 28);">不需要</font></strong><font style="color:rgb(31, 28, 28);"> API 密钥。您可以将此字段留空，或者填写任意内容。</font></li></ul></li><li><strong><font style="color:rgb(31, 28, 28);">API 地址：</font></strong></li></ol><p><font style="color:rgb(31, 28, 28);">填写 Ollama 提供的本地 API 地址。通常情况下，地址为：</font></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:11434/</span><br></pre></td></tr></table></figure><p><font style="color:rgb(31, 28, 28);">如果修改了端口，请自行更改。</font></p><ol start="4"><li><strong><font style="color:rgb(31, 28, 28);">模型管理：</font></strong><ul><li><font style="color:rgb(31, 28, 28);">点击“+ 添加”按钮，手动添加您在 Ollama 中已经下载的模型名称。</font></li><li><font style="color:rgb(31, 28, 28);">比如您已经通过</font><code>&lt;font style=&quot;color:rgb(31, 28, 28);&quot;&gt;ollama run llama3.2&lt;/font&gt;</code><font style="color:rgb(31, 28, 28);">下载了</font><code>&lt;font style=&quot;color:rgb(31, 28, 28);&quot;&gt;llama3.2&lt;/font&gt;</code><font style="color:rgb(31, 28, 28);">模型, 那么此处可以填入</font><code>&lt;font style=&quot;color:rgb(31, 28, 28);&quot;&gt;llama3.2&lt;/font&gt;</code></li><li><font style="color:rgb(31, 28, 28);">点击“管理”按钮，可以对已添加的模型进行编辑或删除。</font></li></ul></li></ol><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748763716251-3e9e3913-d5fe-4e99-9315-fdadd0570c9b.png"></p><p>第四步，使用大模型。上述配置完成后，回到<font style="color:rgb(31, 28, 28);">CherryStudio的聊天界面中，选择Ollama服务商和您已下载的模型，开始与本地 LLM 进行对话：</font></p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748763790250-f05096bd-ab50-42d8-9881-91429a579425.png"></p><p>这样我们就实现了在本地部署LLM大模型，同时通过可视化界面与大模型进行交互。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h1&gt;&lt;p&gt;本篇来学习如何在Windows上安装属于开发者自己的大模型，主要以Ollama为例进行介绍。&lt;font style=&quot;col</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>聊一聊常用的3种实时技术</title>
    <link href="http://aichating.xyz/2025/01/11/2025-1-let&#39;s-talk-about-three-commonly-used-real-time-technologies/"/>
    <id>http://aichating.xyz/2025/01/11/2025-1-let&#39;s-talk-about-three-commonly-used-real-time-technologies/</id>
    <published>2025-01-11T10:03:01.000Z</published>
    <updated>2025-06-02T13:32:51.761Z</updated>
    
    <content type="html"><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>我们知道，早期网站只展示静态内容，但是现在我们更希望实时更新、即时聊天、通知推送和动态仪表盘等功能，因此就有必要学习目前常用的3种实时技术了。</p><p>常用的有SSE、WebSocket和Long Polling这三种，下面将分别进行介绍：</p><p>（1）SSE（Server-Send Events）：轻量级单向数据流；</p><p>（2）WebSocket：全双工双向通信；</p><p>（3）Long Polling（长轮询）：传统过渡方案。</p><p>假设现在我们有如下三个业务场景，它们都需要实现数据实时更新：</p><ul><li>股票交易仪表盘；</li><li>即时聊天平台；</li><li>实时新闻推送。</li></ul><p>面对这些需求，我们该如何选择合适的方案呢？接下来我们将从实战、架构、性能和扩展性角度来进行分析。</p><h1 id="Long-Polling（长轮询）"><a href="#Long-Polling（长轮询）" class="headerlink" title="Long Polling（长轮询）"></a>Long Polling（长轮询）</h1><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>长轮询的原理就是客户端持续地询问服务器，有点类似于吃饭排队时，站在店门口，每隔几分钟询问是否轮到你吃饭了么，可见效率非常低下。</p><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p>（1）实现简单，标准的REST；（2）兼容性最好。</p><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><p>（1）高延迟；（2）浪费大量资源，存在大量的空请求；（3）扩展性差。</p><h2 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h2><p>当系统无法使用WebSocket或者SSE，且需要支持对老旧浏览器或者代理时使用，一般在大型企业的遗留系统中使用。</p><h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><h3 id="后端代码"><a href="#后端代码" class="headerlink" title="后端代码"></a>后端代码</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">@CrossOrigin</span><br><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/api/longpoll&quot;)</span><br><span class="line">public class LongPollingController &#123;</span><br><span class="line">    //使用队列存储待推送的消息</span><br><span class="line">    private static final BlockingQueue&lt;String&gt; messageQueue = </span><br><span class="line">                                                         new LinkedBlockingQueue&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 长轮询端点</span><br><span class="line">      * @param timeout 超时时间（毫秒）</span><br><span class="line">     * @return 消息内容或者超时时间</span><br><span class="line">     */</span><br><span class="line">    @GetMapping(&quot;/poll&quot;)</span><br><span class="line">    public ResponseEntity&lt;String&gt; longPoll(</span><br><span class="line">            @RequestParam(defaultValue = &quot;30000&quot;)long timeout</span><br><span class="line">    )&#123;</span><br><span class="line">        try&#123;</span><br><span class="line">            //等待消息,最多等待指定的超时时间</span><br><span class="line">            String message = messageQueue.poll(timeout, TimeUnit.MILLISECONDS);</span><br><span class="line">            if(!StringUtils.isEmpty(message))&#123;</span><br><span class="line">                return ResponseEntity.ok(message);</span><br><span class="line">            &#125;else&#123;</span><br><span class="line">                //超时返回空响应</span><br><span class="line">                return ResponseEntity.ok(&quot;timeout&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;catch (InterruptedException e)&#123;</span><br><span class="line">            Thread.currentThread().interrupt();</span><br><span class="line">            return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR)</span><br><span class="line">                    .body(&quot;服务器内部发生错误&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 发送消息</span><br><span class="line">     * @param message 待发送的消息</span><br><span class="line">     * @return 发送结果</span><br><span class="line">     */</span><br><span class="line">    @PostMapping(&quot;/send&quot;)</span><br><span class="line">    public ResponseEntity&lt;String&gt; sendMessage(@RequestBody String message)&#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            messageQueue.offer(message);</span><br><span class="line">            return ResponseEntity.ok(&quot;消息发送成功&quot;);</span><br><span class="line">        &#125;catch (Exception e)&#123;</span><br><span class="line">            return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR)</span><br><span class="line">                    .body(&quot;消息发送失败&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="前端代码"><a href="#前端代码" class="headerlink" title="前端代码"></a>前端代码</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html lang=&quot;en&quot;&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">    &lt;meta charset=&quot;UTF-8&quot;&gt;</span><br><span class="line">    &lt;title&gt;长轮询(LongPolling)消息推送&lt;/title&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;长轮询(LongPolling)消息推送&lt;/h1&gt;</span><br><span class="line">&lt;div id=&quot;messages&quot;&gt;</span><br><span class="line"></span><br><span class="line">&lt;/div&gt;</span><br><span class="line">&lt;script&gt;</span><br><span class="line">    class LongPollingClient&#123;</span><br><span class="line">        constructor() &#123;</span><br><span class="line">            this.isPolling = false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        /**</span><br><span class="line">         * 开始长轮询</span><br><span class="line">         */</span><br><span class="line">        startPolling()&#123;</span><br><span class="line">            if(this.isPolling)&#123;</span><br><span class="line">                return;</span><br><span class="line">            &#125;</span><br><span class="line">            this.isPolling = true;</span><br><span class="line">            this.poll();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        /**</span><br><span class="line">         * 停止长轮询</span><br><span class="line">         */</span><br><span class="line">        stopPolling()&#123;</span><br><span class="line">            this.isPolling = false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        /**</span><br><span class="line">         * 执行轮询请求</span><br><span class="line">         */</span><br><span class="line">        async poll()&#123;</span><br><span class="line">            while (this.isPolling)&#123;</span><br><span class="line">                try&#123;</span><br><span class="line">                    const response = await fetch(&#x27;http://127.0.0.1:8080/api/longpoll/poll?timeout=30000&#x27;);</span><br><span class="line">                    const message = await response.text();</span><br><span class="line">                    if(message &amp;&amp; message !== &#x27;timeout&#x27;)&#123;</span><br><span class="line">                        console.log(&quot;收到消息：&quot;,message);</span><br><span class="line">                        this.handleMessage(message);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;catch (error)&#123;</span><br><span class="line">                    console.error(&quot;轮询错误：&quot;,error);</span><br><span class="line">                    //发生错误时，等待一段时间后重试</span><br><span class="line">                    await this.sleep(5000);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        /**</span><br><span class="line">         * 处理接收到的消息</span><br><span class="line">         */</span><br><span class="line">        handleMessage(message)&#123;</span><br><span class="line">            //将消息显示在页面上</span><br><span class="line">            document.getElementById(&#x27;messages&#x27;).innerHTML += &#x27;&lt;div&gt;&#x27; + message +&#x27;&lt;/div&gt;&#x27;;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        /**</span><br><span class="line">         * 延迟函数</span><br><span class="line">         */</span><br><span class="line">        sleep(ms)&#123;</span><br><span class="line">            return new Promise(resolve =&gt; setTimeout(resolve,ms));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    //客户端调用</span><br><span class="line">    const client = new LongPollingClient();</span><br><span class="line">    client.startPolling();</span><br><span class="line">&lt;/script&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure><h3 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h3><p>先运行后端项目，再打开前端页面，之后打开Postman，我们发起一个请求：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748863973489-ad638e4a-49f8-42b6-b113-89f193259a3a.png"></p><p>可以看到已经显示消息发送成功，接着我们查看一下前端页面，可以看到页面已经出现了对应信息：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748864051203-2272b3fa-7140-4fd2-b383-dae4ad9fca0d.png"></p><h1 id="SSE（Server-Send-Events）"><a href="#SSE（Server-Send-Events）" class="headerlink" title="SSE（Server-Send Events）"></a>SSE（Server-Send Events）</h1><h2 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h2><p>SSE的原理如下，即当客户端建立连接后，“持续监听中…..”，之后服务器随时推送消息，不断的消息发送给前端，双方一直保持连接。<strong>请注意，SSE仅支持服务器到客户端的单向通信，比较适合实时数据流。</strong></p><h2 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h2><p>（1）轻量（基于HTTP /1.1）；（2）兼容大多数代理；（3）自动重连机制。</p><h2 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h2><p>（1）单向通信；（2）部分环境支持有限；（3）控制粒度较粗。</p><h2 id="适用场景-1"><a href="#适用场景-1" class="headerlink" title="适用场景"></a>适用场景</h2><p>当需要简单高效的服务器到客户端更新，如<font style="color:rgb(63, 63, 63);">股票行情、实时比分、状态仪表盘、监控系统等。</font></p><h2 id="实战-1"><a href="#实战-1" class="headerlink" title="实战"></a>实战</h2><h3 id="后端代码-1"><a href="#后端代码-1" class="headerlink" title="后端代码"></a>后端代码</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">@CrossOrigin</span><br><span class="line">@RestController</span><br><span class="line">@RequestMapping(&quot;/api/sse&quot;)</span><br><span class="line">public class SSEController &#123;</span><br><span class="line">    /**</span><br><span class="line">     * 创建SSE连接端点</span><br><span class="line">     * @return SseEmitter对象，用于发送服务器推送事件</span><br><span class="line">     */</span><br><span class="line">    @GetMapping(&quot;/connect&quot;)</span><br><span class="line">    public SseEmitter connect()&#123;</span><br><span class="line">        // 创建SseEmitter对象，设置超时时间为30分钟</span><br><span class="line">        SseEmitter emitter = new SseEmitter(30 * 60 * 1000L);</span><br><span class="line">        try&#123;</span><br><span class="line">            //发送连接成功消息</span><br><span class="line">            emitter.send(SseEmitter.event()</span><br><span class="line">                    .name(&quot;connect&quot;)</span><br><span class="line">                    .data(&quot;SSE连接建立成功&quot;));</span><br><span class="line">        &#125;catch (IOException e)&#123;</span><br><span class="line">            emitter.completeWithError(e);</span><br><span class="line">        &#125;</span><br><span class="line">        //模拟定时推送消息</span><br><span class="line">        ScheduledExecutorService executor = Executors.newScheduledThreadPool(1);</span><br><span class="line">        executor.scheduleAtFixedRate(()-&gt;&#123;</span><br><span class="line">            try&#123;</span><br><span class="line">                //每5秒推送一下当前时间</span><br><span class="line">                emitter.send(SseEmitter.event()</span><br><span class="line">                        .name(&quot;message&quot;)</span><br><span class="line">                        .data(&quot;当前数字为：&quot; + LocalDateTime.now()));</span><br><span class="line">            &#125;catch (IOException e)&#123;</span><br><span class="line">                emitter.complete();</span><br><span class="line">                executor.shutdown();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,0,5, TimeUnit.SECONDS);</span><br><span class="line">        return emitter;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="前端代码-1"><a href="#前端代码-1" class="headerlink" title="前端代码"></a>前端代码</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html lang=&quot;en&quot;&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">    &lt;meta charset=&quot;UTF-8&quot;&gt;</span><br><span class="line">    &lt;title&gt;SSE消息推送&lt;/title&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;SSE消息推送&lt;/h1&gt;</span><br><span class="line">&lt;div id=&quot;messages&quot;&gt;</span><br><span class="line"></span><br><span class="line">&lt;/div&gt;</span><br><span class="line">&lt;script&gt;</span><br><span class="line">    // 创建EventSource对象连接SSE端点</span><br><span class="line">    const eventSource = new EventSource(&quot;http://127.0.0.1:8080/api/sse/connect&quot;);</span><br><span class="line">    //监听连接事件</span><br><span class="line">    eventSource.addEventListener(&#x27;connect&#x27;,function (event)&#123;</span><br><span class="line">        console.log(&#x27;连接状态：&#x27;,event.data);</span><br><span class="line">    &#125;);</span><br><span class="line">    //监听消息事件</span><br><span class="line">    eventSource.addEventListener(&#x27;message&#x27;,function (event)&#123;</span><br><span class="line">        console.log(&#x27;收到消息：&#x27;,event.data);</span><br><span class="line">        //将消息显示在页面上</span><br><span class="line">        document.getElementById(&#x27;messages&#x27;).innerHTML += &#x27;&lt;div&gt;&#x27; + event.data +&#x27;&lt;/div&gt;&#x27;;</span><br><span class="line">    &#125;);</span><br><span class="line">    //监听错误事件</span><br><span class="line">    eventSource.onerror = function (event) &#123;</span><br><span class="line">        console.error(&#x27;SSE连接错误：&#x27;,event);</span><br><span class="line">    &#125;;</span><br><span class="line">&lt;/script&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure><h3 id="运行结果-1"><a href="#运行结果-1" class="headerlink" title="运行结果"></a>运行结果</h3><p>先运行后端项目，再打开前端页面，可以看到页面每隔5秒钟显示当前时间：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748864484753-11519e37-c823-4e2f-9429-697244398310.png"></p><h1 id="WebSocket"><a href="#WebSocket" class="headerlink" title="WebSocket"></a>WebSocket</h1><h2 id="原理-2"><a href="#原理-2" class="headerlink" title="原理"></a>原理</h2><p>WebSocket的原理就是建立双向通道，实现实时对话，类似于对讲机的全双工通信模式。</p><h2 id="优点-2"><a href="#优点-2" class="headerlink" title="优点"></a>优点</h2><p>（1）双向通信；（2）低延迟；（3）可通过消息中间件扩展。</p><h2 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h2><p>（1）代理兼容性差；（2）扩展复杂度高；（3）需要维持长连接。</p><h2 id="适用场景-2"><a href="#适用场景-2" class="headerlink" title="适用场景"></a>适用场景</h2><p>适用于聊天室、游戏、协作应用等需要实现双向交互的场景。</p><h2 id="实战-2"><a href="#实战-2" class="headerlink" title="实战"></a>实战</h2><h3 id="后端代码-2"><a href="#后端代码-2" class="headerlink" title="后端代码"></a>后端代码</h3><p>其中的MyWebSocketHandler类代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">@Component</span><br><span class="line">public class MyWebSocketHandler extends TextWebSocketHandler &#123;</span><br><span class="line">    //存储所有活跃的WebSocket会话</span><br><span class="line">    private static final Set&lt;WebSocketSession&gt; sessions = Collections.synchronizedSet(new HashSet&lt;&gt;());</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 建立连接后调用</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public void afterConnectionEstablished(WebSocketSession session) throws Exception &#123;</span><br><span class="line">        sessions.add(session);</span><br><span class="line">        System.out.println(&quot;WebSocket连接建立：&quot; + session.getId());</span><br><span class="line">        //向新连接的客户端发送欢迎消息</span><br><span class="line">        session.sendMessage(new TextMessage(&quot;欢迎使用WebSocket！&quot;));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 收到客户端发来的消息时调用</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    protected void handleTextMessage(WebSocketSession session, TextMessage message) throws Exception &#123;</span><br><span class="line">        String payload = message.getPayload();</span><br><span class="line">        System.out.println(&quot;收到消息，消息内容为：&quot; + payload);</span><br><span class="line"></span><br><span class="line">        //广播消息给所有连接的客户端</span><br><span class="line">        broadcastMessage(&quot;服务器回复的消息为：&quot; + payload);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 连接关闭后调用</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    public void afterConnectionClosed(WebSocketSession session, CloseStatus status) throws Exception &#123;</span><br><span class="line">        sessions.remove(session);</span><br><span class="line">        System.out.println(&quot;WebSocket连接关闭：&quot; + session.getId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 广播消息给所有连接的客户端</span><br><span class="line">     */</span><br><span class="line">    private static void broadcastMessage(String message)&#123;</span><br><span class="line">        synchronized (sessions)&#123;</span><br><span class="line">            sessions.removeIf(session -&gt; &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    if(session.isOpen())&#123;</span><br><span class="line">                        session.sendMessage(new TextMessage(message));</span><br><span class="line">                        //保留该会话</span><br><span class="line">                        return false;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;catch (Exception e)&#123;</span><br><span class="line">                    System.err.println(&quot;消息发送失败：&quot; + e.getMessage());</span><br><span class="line">                &#125;</span><br><span class="line">                //移除无效会话</span><br><span class="line">                return true;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再来一个MyWebSocketHandler类，其中的代码如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">@EnableWebSocket</span><br><span class="line">public class WebSocketConfig implements WebSocketConfigurer &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public void registerWebSocketHandlers(WebSocketHandlerRegistry registry) &#123;</span><br><span class="line">        //注册websocket处理器，并允许跨域访问</span><br><span class="line">        registry.addHandler(new MyWebSocketHandler(),&quot;/websocket&quot;)</span><br><span class="line">                .setAllowedOrigins(&quot;*&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="前端代码-2"><a href="#前端代码-2" class="headerlink" title="前端代码"></a>前端代码</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html lang=&quot;en&quot;&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">    &lt;meta charset=&quot;UTF-8&quot;&gt;</span><br><span class="line">    &lt;title&gt;WebSocket消息推送&lt;/title&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;WebSocket消息推送&lt;/h1&gt;</span><br><span class="line">&lt;input type=&quot;text&quot; id=&quot;messageInput&quot; placeholder=&quot;请输入需要发送的消息...&quot;&gt;</span><br><span class="line">&lt;button type=&quot;submit&quot; onclick=&quot;messageSend()&quot; &gt;提交&lt;/button&gt;</span><br><span class="line">&lt;div id=&quot;messages&quot;&gt;</span><br><span class="line"></span><br><span class="line">&lt;/div&gt;</span><br><span class="line">&lt;script&gt;</span><br><span class="line">    // 创建WebSocket连接</span><br><span class="line">    const socket = new WebSocket(&quot;ws://127.0.0.1:8080/websocket&quot;);</span><br><span class="line">    //连接打开时的处理逻辑</span><br><span class="line">    socket.onopen = function (event) &#123;</span><br><span class="line">        console.log(&quot;WebSocket连接已经建立&quot;);</span><br><span class="line">        //发送消息给服务端</span><br><span class="line">        socket.send(&quot;测试一下WebSocket！&quot;)</span><br><span class="line">    &#125;;</span><br><span class="line">    //客户端接收到消息时的处理逻辑</span><br><span class="line">    socket.onmessage = function (event) &#123;</span><br><span class="line">        console.log(&quot;收到消息：&quot; + event.data);</span><br><span class="line">        //将消息显示在页面上</span><br><span class="line">        document.getElementById(&#x27;messages&#x27;).innerHTML += &#x27;&lt;div&gt;&#x27; + event.data +&#x27;&lt;/div&gt;&#x27;;</span><br><span class="line">    &#125;</span><br><span class="line">    //连接关闭时调用</span><br><span class="line">    socket.onclose = function (event) &#123;</span><br><span class="line">        console.log(&quot;WebSocket连接已关闭&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    //错误处理逻辑</span><br><span class="line">    socket.onerror = function (error) &#123;</span><br><span class="line">        console.error(&quot;WebSocket错误：&quot; + error);</span><br><span class="line">    &#125;</span><br><span class="line">    //界面发送消息的逻辑</span><br><span class="line">    function messageSend() &#123;</span><br><span class="line">        const input = document.getElementById(&#x27;messageInput&#x27;);</span><br><span class="line">        if(socket.readyState === WebSocket.OPEN)&#123;</span><br><span class="line">            socket.send(input.value);</span><br><span class="line">            input.value = &#x27;&#x27;;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&lt;/script&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure><h3 id="运行结果-2"><a href="#运行结果-2" class="headerlink" title="运行结果"></a>运行结果</h3><p>先运行后端项目，再打开前端页面，可以看到初始界面如下所示：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748864928738-970ba5b3-c73d-4888-ae85-49ac430b3e88.png"></p><p>之后我们尝试在输入框内输入“测试一下WebSocket”：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748864961420-e3a961c7-2b03-4a1e-b6df-a9ce1ae7bb13.png"></p><p>然后点击提交按钮，可以看到界面信息如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748864979893-3b9b38f0-e027-4bd8-ab05-8a9732333c96.png"></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>通过前面的分析，我们就可以对上述三个场景需要的方案进行选项了：</p><ul><li>股票交易仪表盘：SSE</li><li>即时聊天平台：WebSocket</li><li>实时新闻推送(历史遗留系统)：Long Polling</li></ul><p>当然技术选型需要因地制宜，结合实际情况和场景来选择合适的方案。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h1&gt;&lt;p&gt;我们知道，早期网站只展示静态内容，但是现在我们更希望实时更新、即时聊天、通知推送和动态仪表盘等功能，因此就有必要学习目前常用</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>MySQL同步ES的6种方式</title>
    <link href="http://aichating.xyz/2024/12/21/2024-11-6-ways-to-synchronize-es-with-mysql/"/>
    <id>http://aichating.xyz/2024/12/21/2024-11-6-ways-to-synchronize-es-with-mysql/</id>
    <published>2024-12-21T10:23:04.000Z</published>
    <updated>2025-06-02T13:19:54.916Z</updated>
    
    <content type="html"><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>我们知道，在分布式系统日益发展的今天，<font style="color:rgb(63, 63, 63);">MySQL与Elasticsearch的协同已成为解决高并发查询与复杂检索的标配组合。但是，如何实现两者间数据的高效同步，已成为架构设计中不可忽视的问题。笔者结合实际工作经验和一些参考文章，给出常用的6种可行的同步方式，以供在后续架构设计中作参考。</font></p><h1 id="小批量数据同步方式"><a href="#小批量数据同步方式" class="headerlink" title="小批量数据同步方式"></a><font style="color:rgb(63, 63, 63);">小批量数据同步方式</font></h1><h2 id="同步双写"><a href="#同步双写" class="headerlink" title="同步双写"></a><font style="color:rgb(63, 63, 63);">同步双写</font></h2><p>【适用场景】对数据实时性要求较高，且业务逻辑较为简单的场景，如支付记录同步等。</p><p>【实现方式】在代码中同时写入MySQL和ES。</p><p>【示例代码】以下是同步双写的示例代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@Transactional  </span><br><span class="line">public void createRecord(TRecord trecord) &#123;  </span><br><span class="line">    // 写入MySQL  </span><br><span class="line">    trecordMapper.insert(trecord);  </span><br><span class="line">    // 同步写入ES  </span><br><span class="line">    IndexRequest request = new IndexRequest(&quot;records&quot;)  </span><br><span class="line">        .id(trecord.getId())  </span><br><span class="line">        .source(JSON.toJSONString(trecord), XContentType.JSON);  </span><br><span class="line">    client.index(request, RequestOptions.DEFAULT);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>【缺点】</p><p>（1）代码侵入：需要在所有涉及写入操作的地方都添加ES写入逻辑；</p><p>（2）性能降低：双写会导致事务时间变长，降低TPS；</p><p>（3）数据一致性难以得到保证：<font style="color:rgb(63, 63, 63);">如果ES写入失败，而MySQL写入成功，需要引入补偿机制。</font></p><h2 id="异步双写"><a href="#异步双写" class="headerlink" title="异步双写"></a><font style="color:rgb(63, 63, 63);">异步双写</font></h2><p>【适用场景】对数据实时性要求不高，且业务逻辑较为简单的场景，如订单创建成功后状态修改，以供用户查询等。</p><p>【实现方式】使用MQ来进行解耦和实现异步双写。</p><p>【示意流程】以下是异步双写的流程：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748308847462-1f11a8d8-7262-4039-96a6-918164ee5a0c.png"></p><p>【示例代码】以下是异步双写的示例代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">//生产者(业务服务)</span><br><span class="line">public void updateOrder(Order order) &#123;  </span><br><span class="line">    orderMapper.update(order);  </span><br><span class="line">    kafkaTemplate.send(&quot;order-update&quot;, order.getId());  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line">//消费者(消费服务)</span><br><span class="line">@KafkaListener(topics = &quot;order-update&quot;)  </span><br><span class="line">public void syncToES(String orderId) &#123;  </span><br><span class="line">    Order order = orderMapper.selectById(orderId);  </span><br><span class="line">    esClient.index(order);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>【优点】</p><p>（1）大幅提升吞吐量：通过MQ实现削峰填谷；</p><p>（2）故障隔离：ES宕机不影响业务正常进行</p><p>【缺点】</p><p>（1）存在消息堆积：突发流量可能会导致消费延迟；</p><p>（2）消费顺序难以保证：必须通过分区来保证同一分区数据消费的顺序性。</p><h2 id="Canal监听Binlog日志"><a href="#Canal监听Binlog日志" class="headerlink" title="Canal监听Binlog日志"></a>Canal监听Binlog日志</h2><p>【适用场景】对数据实时性要求较高，且业务逻辑较为复杂的场景，如商品上架后实时搜索等。</p><p>【实现方式】使用MQ + Canal + ES来实现。</p><p>【示意流程】以下是Canal监听Binlog日志的流程：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748311466891-3581176a-f774-4034-a6cc-d5a6c597e8f0.png"></p><p>在Canal中有一些关键配置，这个用于配置MySQL地址以及mq的主题：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># canal.properties  </span><br><span class="line">canal.instance.master.address=127.0.0.1:3306  </span><br><span class="line">canal.mq.topic=canal.es.sync</span><br></pre></td></tr></table></figure><p>【注意事项】</p><p>（1）需要实现幂等消费：可通过id等唯一键来实现；</p><p>（2）可能存在数据漂移：需要<font style="color:rgb(63, 63, 63);">处理DDL变更（开发者可通过Schema Registry来管理映射）。</font></p><h2 id="Logstash定时拉取"><a href="#Logstash定时拉取" class="headerlink" title="Logstash定时拉取"></a><font style="color:rgb(63, 63, 63);">Logstash定时拉取</font></h2><p>【适用场景】对数据实时性要求不高，延迟较高，如用户行为T+1分析等。</p><p>【示例配置】以下是Logstash定时拉取的示例配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  jdbc &#123;</span><br><span class="line">    jdbc_driver=&gt;&quot;com.mysql.jdbc.Driver&quot;</span><br><span class="line">    jdbc_url=&gt;&quot;jdbc:mysql://127.0.0.1:3306/user_log_db&quot;</span><br><span class="line">    schedule=&gt;&quot;*/5 * * * *&quot;# 每5分钟执行  </span><br><span class="line">    statement=&gt;&quot;SELECT * FROM user_log WHERE create_time &gt; :sql_last_value&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    hosts=&gt;[&quot;es-host:9200&quot;]</span><br><span class="line">    index=&gt;&quot;user_logs&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>【优点】</p><p>（1）代码零入侵：代码零入侵，非常适合历史数据的迁移；</p><p>（2）配置灵活：可通过配置文件来指定配置参数。</p><p>【缺点】</p><p>（1）分钟级别延迟：无法实现实时搜索；</p><p>（2）全表扫码压力大：数据同步是全量的，需要优化<font style="color:rgb(63, 63, 63);">增量字段索引</font>。</p><h1 id="大数据量同步方式"><a href="#大数据量同步方式" class="headerlink" title="大数据量同步方式"></a>大数据量同步方式</h1><h2 id="DataX批量同步"><a href="#DataX批量同步" class="headerlink" title="DataX批量同步"></a>DataX批量同步</h2><p>【适用场景】将历史数据从MySQL迁移至ES中，大数据同步优先考虑此种方式。</p><p>【示例配置】以下是DataX批量同步数据的示例配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;  </span><br><span class="line">&quot;job&quot;:&#123;</span><br><span class="line">    &quot;content&quot;:[&#123;</span><br><span class="line">      &quot;reader&quot;:&#123;</span><br><span class="line">        &quot;name&quot;:&quot;mysqlreader&quot;,</span><br><span class="line">        &quot;parameter&quot;:&#123;&quot;splitPk&quot;:&quot;id&quot;,&quot;querySql&quot;:&quot;SELECT * FROM orders&quot;&#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;writer&quot;:&#123;</span><br><span class="line">        &quot;name&quot;:&quot;elasticsearchwriter&quot;,</span><br><span class="line">        &quot;parameter&quot;:&#123;&quot;endpoint&quot;:&quot;http://es-host:9200&quot;,&quot;index&quot;:&quot;orders&quot;&#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>【调优配置】</p><p>（1）<font style="color:rgb(63, 63, 63);">调整Channel数：为提升并发，需要调整Channel数，建议与分片数对齐；</font></p><p><font style="color:rgb(63, 63, 63);">（2）使用limit：为避免发生OOM，需要使用limit关键字进行分页处理。</font></p><h2 id="Flink流处理"><a href="#Flink流处理" class="headerlink" title="Flink流处理"></a><font style="color:rgb(63, 63, 63);">Flink流处理</font></h2><p>【适用场景】对于<font style="color:rgb(63, 63, 63);">复杂的ETL场景，或者</font>商品价格或者数量发生变化时，需要<font style="color:rgb(63, 63, 63);">关联用户画像，计算实时推荐评分时，推荐使用该方式</font>。</p><p>【示例配置】以下是Flink流处理的示例配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();  </span><br><span class="line">env.addSource(new CanalSource())  </span><br><span class="line">   .map(record -&gt; parseToPriceEvent(record))  </span><br><span class="line">   .keyBy(event -&gt; event.getProductId())  </span><br><span class="line">   .connect(userProfileBroadcastStream)  </span><br><span class="line">   .process(new PriceRecommendationProcess())  </span><br><span class="line">   .addSink(new ElasticsearchSink());</span><br></pre></td></tr></table></figure><p>【调优配置】</p><p>（1）<font style="color:rgb(63, 63, 63);">状态管理：通过WaterMark机制，精准处理乱序事件；</font></p><p><font style="color:rgb(63, 63, 63);">（2）维表关联：通过Broadcast State实现实时画像关联。</font></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a><font style="color:rgb(63, 63, 63);">小结</font></h1><p>下面通过一张表来展示上述6种方式的区别，后续在架构设计和开发过程中可以根据各种方式的特点来选择合适的方式：</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/12555354/1748313159832-ed4e3299-6e3e-4f37-9b7c-ce73f4a08897.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h1&gt;&lt;p&gt;我们知道，在分布式系统日益发展的今天，&lt;font style=&quot;color:rgb(63, 63, 63);&quot;&gt;MySQL与</summary>
      
    
    
    
    <category term="springboot" scheme="http://aichating.xyz/categories/springboot/"/>
    
    
    <category term="springboot" scheme="http://aichating.xyz/tags/springboot/"/>
    
  </entry>
  
</feed>
